"""
Module phÃ¢n loáº¡i sá»­ dá»¥ng K-Nearest Neighbors vá»›i FAISS.
"""
import faiss
import numpy as np
import os
import pickle
from typing import List, Dict, Tuple, Any
from collections import Counter


class KNNClassifier:
    """Class phÃ¢n loáº¡i KNN sá»­ dá»¥ng FAISS."""
    
    def __init__(self, embedding_dim: int):
        """
        Khá»Ÿi táº¡o KNN Classifier.
        
        Args:
            embedding_dim: Sá»‘ chiá»u cá»§a embeddings
        """
        self.embedding_dim = embedding_dim
        self.index = faiss.IndexFlatIP(embedding_dim)  # Inner product
        self.train_metadata = None
    
    def fit(self, 
            train_embeddings: np.ndarray, 
            train_metadata: List[Dict[str, Any]]) -> None:
        """
        Huáº¥n luyá»‡n classifier vá»›i dá»¯ liá»‡u train.
        
        Args:
            train_embeddings: Embeddings cá»§a dá»¯ liá»‡u train
            train_metadata: Metadata cá»§a dá»¯ liá»‡u train
        """
        self.train_metadata = train_metadata
        self.index.add(train_embeddings.astype('float32'))
        print(f"FAISS index Ä‘Ã£ táº¡o vá»›i {self.index.ntotal} vectors")
    
    def save_index(self, cache_suffix: str = "") -> str:
        """
        ğŸ†• LÆ°u FAISS index vÃ  metadata vÃ o cache.
        
        Args:
            cache_suffix: Suffix cho tÃªn file cache
            
        Returns:
            ÄÆ°á»ng dáº«n file cache Ä‘Ã£ lÆ°u
        """
        # Táº¡o thÆ° má»¥c cache náº¿u chÆ°a cÃ³
        cache_dir = os.path.join('cache', 'faiss_index')
        os.makedirs(cache_dir, exist_ok=True)
        
        # TÃªn file cache
        index_file = os.path.join(cache_dir, f"faiss_index{cache_suffix}.faiss")
        metadata_file = os.path.join(cache_dir, f"faiss_metadata{cache_suffix}.pkl")
        
        print(f"FAISS SAVE: {cache_suffix} index with {self.index.ntotal} vectors")
        
        # LÆ°u FAISS index
        faiss.write_index(self.index, index_file)
        
        # LÆ°u metadata
        with open(metadata_file, 'wb') as f:
            pickle.dump(self.train_metadata, f)
        
        return index_file
    
    def load_index(self, cache_suffix: str = "") -> bool:
        """
        ğŸ†• Load FAISS index vÃ  metadata tá»« cache.
        
        Args:
            cache_suffix: Suffix cho tÃªn file cache
            
        Returns:
            True náº¿u load thÃ nh cÃ´ng, False náº¿u khÃ´ng
        """
        # TÃªn file cache
        cache_dir = os.path.join('cache', 'faiss_index')
        index_file = os.path.join(cache_dir, f"faiss_index{cache_suffix}.faiss")
        metadata_file = os.path.join(cache_dir, f"faiss_metadata{cache_suffix}.pkl")
        
        # Kiá»ƒm tra file tá»“n táº¡i
        if not os.path.exists(index_file) or not os.path.exists(metadata_file):
            print(f"FAISS LOAD: {cache_suffix} cache not found")
            return False
        
        try:
            # Load FAISS index
            self.index = faiss.read_index(index_file)
            
            # Load metadata
            with open(metadata_file, 'rb') as f:
                self.train_metadata = pickle.load(f)
            
            print(f"FAISS LOAD: {cache_suffix} index with {self.index.ntotal} vectors")
            return True
            
        except Exception as e:
            print(f"FAISS LOAD: Error loading {cache_suffix} index - {e}")
            return False
    
    def predict(self, 
                query_embedding: np.ndarray, 
                k: int = 1) -> Tuple[str, List[Dict[str, Any]]]:
        """
        PhÃ¢n loáº¡i má»™t query sá»­ dá»¥ng k-nearest neighbors.
        
        Args:
            query_embedding: Embedding cá»§a query
            k: Sá»‘ lÆ°á»£ng neighbors
            
        Returns:
            Tuple chá»©a prediction vÃ  thÃ´ng tin neighbors
        """
        # Debug: Kiá»ƒm tra kÃ­ch thÆ°á»›c embedding
        print(f"Debug: Query embedding shape: {query_embedding.shape}")
        print(f"Debug: FAISS index dimension: {self.index.d}")
        print(f"Debug: Query embedding dtype: {query_embedding.dtype}")
        
        # Äáº£m báº£o kÃ­ch thÆ°á»›c Ä‘Ãºng
        if query_embedding.shape[1] != self.index.d:
            raise ValueError(
                f"Embedding dimension mismatch! "
                f"Query: {query_embedding.shape[1]}, "
                f"Index: {self.index.d}"
            )
        
        # TÃ¬m kiáº¿m trong FAISS index
        scores, indices = self.index.search(query_embedding, k)
        
        # Láº¥y predictions tá»« top-k neighbors
        predictions = []
        neighbor_info = []
        
        for i in range(k):
            neighbor_idx = indices[0][i]
            neighbor_score = scores[0][i]
            neighbor_data = self.train_metadata[neighbor_idx]
            
            predictions.append(neighbor_data['label'])
            neighbor_info.append({
                'score': float(neighbor_score),
                'label': neighbor_data['label'],
                'message': self._truncate_message(neighbor_data['message'])
            })
        
        # Majority vote cho prediction cuá»‘i cÃ¹ng
        final_prediction = Counter(predictions).most_common(1)[0][0]
        
        return final_prediction, neighbor_info
    
    def _truncate_message(self, message: str, max_length: int = 100) -> str:
        """
        Cáº¯t ngáº¯n message Ä‘á»ƒ hiá»ƒn thá»‹.
        
        Args:
            message: Tin nháº¯n gá»‘c
            max_length: Äá»™ dÃ i tá»‘i Ä‘a
            
        Returns:
            Tin nháº¯n Ä‘Ã£ cáº¯t ngáº¯n
        """
        if len(message) > max_length:
            return message[:max_length] + "..."
        return message
