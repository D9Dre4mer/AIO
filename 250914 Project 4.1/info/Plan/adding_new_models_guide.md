# H∆∞·ªõng d·∫´n th√™m Model m·ªõi v√†o d·ª± √°n

## T·ªïng quan

D·ª± √°n s·ª≠ d·ª•ng ki·∫øn tr√∫c **Model-Centric Pipeline** - m·ªói model t·ª± qu·∫£n l√Ω to√†n b·ªô pipeline x·ª≠ l√Ω d·ªØ li·ªáu c·ªßa m√¨nh. ƒê·ªÉ th√™m model m·ªõi, b·∫°n c·∫ßn t·∫°o 4 th√†nh ph·∫ßn ch√≠nh.

## C·∫•u tr√∫c Model-Centric Pipeline

```
Text Input ‚Üí Preprocessor ‚Üí Vectorizer ‚Üí Feature Fuser ‚Üí Estimator ‚Üí Predictions
```

- **Preprocessor**: Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n (stopwords, lemmatization, rare words)
- **Vectorizer**: Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector (BoW, TF-IDF, Embeddings)
- **Feature Fuser**: K·∫øt h·ª£p nhi·ªÅu lo·∫°i ƒë·∫∑c tr∆∞ng (TF-IDF + Embeddings + features ph·ª•)
- **Estimator**: Thu·∫≠t to√°n h·ªçc m√°y ch√≠nh

## B∆∞·ªõc 1: T·∫°o Model Class

### 1.1 T·∫°o file model m·ªõi

T·∫°o file m·ªõi trong `models/classification/` v·ªõi t√™n `{model_name}_model.py`

**V√≠ d·ª•:** `models/classification/random_forest_model.py`

### 1.2 C·∫•u tr√∫c Model Class

```python
"""
Random Forest Model v·ªõi Model-Centric Pipeline
"""

import numpy as np
from typing import Dict, Any, Union
from scipy import sparse
from sklearn.ensemble import RandomForestClassifier
from ..base.base_model import BaseModel


class RandomForestModel(BaseModel):
    """Random Forest Model v·ªõi pipeline t√≠ch h·ª£p"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # Kh·ªüi t·∫°o estimator
        self.model = RandomForestClassifier(**self.model_params)
        
        # Pipeline components (s·∫Ω ƒë∆∞·ª£c build trong build_pipeline)
        self.preprocessor = None
        self.vectorizer = None
        self.feature_fuser = None
        self.calibrator = None
        self.thresholds = None
    
    def build_pipeline(self, config: Dict[str, Any]) -> None:
        """Build pipeline d·ª±a tr√™n config"""
        from ..utils.text_preprocessor import TextPreprocessor
        from ..utils.vectorizer_provider import VectorizerProvider
        from ..utils.feature_fusion import FeatureFusion
        
        # 1. Build preprocessor
        preprocessor_config = config.get('preprocessor', {})
        self.preprocessor = TextPreprocessor(**preprocessor_config)
        
        # 2. Build vectorizer
        vectorizer_config = config.get('vectorizer', {})
        self.vectorizer = VectorizerProvider(**vectorizer_config)
        
        # 3. Build feature fuser (optional)
        if config.get('use_fusion', False):
            fusion_config = config.get('fusion', {})
            self.feature_fuser = FeatureFusion(**fusion_config)
    
    def fit_pipeline(self, X_text: list, y: np.ndarray) -> None:
        """Fit to√†n b·ªô pipeline tr√™n d·ªØ li·ªáu text"""
        # 1. Fit preprocessor
        self.preprocessor.fit(X_text, y)
        
        # 2. Transform text qua preprocessor
        X_processed = self.preprocessor.transform(X_text)
        
        # 3. Fit vectorizer
        self.vectorizer.fit(X_processed)
        
        # 4. Transform qua vectorizer
        X_vectorized = self.vectorizer.transform(X_processed)
        
        # 5. Apply feature fusion n·∫øu c√≥
        if self.feature_fuser:
            self.feature_fuser.fit(X_vectorized, y)
            X_final = self.feature_fuser.transform(X_vectorized)
        else:
            X_final = X_vectorized
        
        # 6. Fit estimator
        self.model.fit(X_final, y)
        self.is_fitted = True
    
    def transform_pipeline(self, X_text: list) -> Union[np.ndarray, sparse.csr_matrix]:
        """Transform text qua to√†n b·ªô pipeline"""
        if not self.is_fitted:
            raise ValueError("Model must be fitted before transform")
        
        # 1. Preprocess
        X_processed = self.preprocessor.transform(X_text)
        
        # 2. Vectorize
        X_vectorized = self.vectorizer.transform(X_processed)
        
        # 3. Feature fusion n·∫øu c√≥
        if self.feature_fuser:
            X_final = self.feature_fuser.transform(X_vectorized)
        else:
            X_final = X_vectorized
        
        return X_final
    
    def fit(self, X: Union[np.ndarray, sparse.csr_matrix], y: np.ndarray) -> 'RandomForestModel':
        """Fit model (cho compatibility v·ªõi sklearn)"""
        self.model.fit(X, y)
        self.is_fitted = True
        return self
    
    def predict(self, X: Union[np.ndarray, sparse.csr_matrix]) -> np.ndarray:
        """Predict classes"""
        if not self.is_fitted:
            raise ValueError("Model must be fitted before predict")
        return self.model.predict(X)
    
    def predict_proba(self, X: Union[np.ndarray, sparse.csr_matrix]) -> np.ndarray:
        """Predict class probabilities"""
        if not self.is_fitted:
            raise ValueError("Model must be fitted before predict_proba")
        return self.model.predict_proba(X)
    
    def get_feature_importance(self) -> np.ndarray:
        """Get feature importance"""
        if not self.is_fitted:
            raise ValueError("Model must be fitted before get_feature_importance")
        return self.model.feature_importances_
```

## B∆∞·ªõc 2: ƒêƒÉng k√Ω Model trong Registry

### 2.1 C·∫≠p nh·∫≠t `models/register_models.py`

```python
# Th√™m import
from .classification.random_forest_model import RandomForestModel

# Th√™m v√†o h√†m register_all_models()
def register_all_models(registry):
    # ... existing models ...
    
    # Register Random Forest
    registry.register_model(
        'random_forest',
        RandomForestModel,
        {
            'category': 'classification',
            'task_type': 'supervised',
            'data_type': 'numerical',
            'description': 'Random Forest v·ªõi Model-Centric Pipeline',
            'parameters': ['n_estimators', 'max_depth', 'max_features', 'class_weight'],
            'supports_sparse': True,
            'supports_gpu': True,  # n·∫øu d√πng cuML
            'supports_proba': True,
            'supports_shap': True,
            'default_vectorizers': ['tfidf', 'fusion'],
            'supports_fusion': True,
            'has_feature_importance': True
        }
    )
```

## B∆∞·ªõc 3: T·∫°o Config m·∫∑c ƒë·ªãnh

### 3.1 Th√™m v√†o `config.py`

```python
# Random Forest default config
RANDOM_FOREST_DEFAULT_CONFIG = {
    'preprocessor': {
        'remove_stopwords': True,
        'lemmatization': False,
        'rare_words_threshold': 2
    },
    'vectorizer': {
        'type': 'tfidf',
        'max_features': 10000,
        'ngram_range': (1, 2)
    },
    'fusion': {
        'use_embeddings': True,
        'use_additional_features': True
    },
    'estimator': {
        'n_estimators': 100,
        'max_depth': 10,
        'class_weight': 'balanced'
    }
}
```

## B∆∞·ªõc 4: T√≠ch h·ª£p v√†o Streamlit UI

### 4.1 C·∫≠p nh·∫≠t `app.py` - Step 3

```python
def render_step3_wireframe():
    """Model Configuration & Preprocessing"""
    
    st.markdown("### ü§ñ Step 3: Model Configuration & Preprocessing")
    
    # Model selector
    st.markdown("#### Ch·ªçn Model")
    available_models = ['random_forest', 'ada_boost', 'gbdt', 'xgboost', 'lightgbm']
    
    selected_models = []
    for model_name in available_models:
        if st.checkbox(f"‚úÖ {model_name.replace('_', ' ').title()}", key=f"model_{model_name}"):
            selected_models.append(model_name)
    
    # Hi·ªÉn th·ªã config cho t·ª´ng model ƒë√£ ch·ªçn
    for model_name in selected_models:
        with st.expander(f"‚öôÔ∏è C·∫•u h√¨nh {model_name.replace('_', ' ').title()}"):
            render_model_config(model_name)

def render_model_config(model_name: str):
    """Render config panel cho model c·ª• th·ªÉ"""
    
    # Preprocessing options
    st.markdown("**üîß Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu:**")
    col1, col2 = st.columns(2)
    
    with col1:
        remove_stopwords = st.checkbox("Lo·∫°i b·ªè stopwords", value=True, key=f"{model_name}_stopwords")
        lemmatization = st.checkbox("Lemmatization", key=f"{model_name}_lemma")
    
    with col2:
        rare_words_threshold = st.number_input("Ng∆∞·ª°ng t·ª´ hi·∫øm", min_value=1, value=2, key=f"{model_name}_rare")
    
    # Vectorizer options
    st.markdown("**üìä Vectorizer:**")
    vectorizer_type = st.selectbox(
        "Lo·∫°i vectorizer",
        ['tfidf', 'embeddings', 'fusion'],
        key=f"{model_name}_vectorizer"
    )
    
    # Hyperparameters
    st.markdown("**üéõÔ∏è Hyperparameters:**")
    if model_name == 'random_forest':
        n_estimators = st.slider("n_estimators", 10, 500, 100, key=f"{model_name}_n_est")
        max_depth = st.slider("max_depth", 3, 20, 10, key=f"{model_name}_max_depth")
```

## B∆∞·ªõc 5: Test Model m·ªõi

### 5.1 T·∫°o test script

```python
# test_new_model.py
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.utils.model_factory import model_factory
from models.utils.model_registry import ModelRegistry

def test_new_model():
    # Kh·ªüi t·∫°o registry
    registry = ModelRegistry()
    from models.register_models import register_all_models
    register_all_models(registry)
    
    # Kh·ªüi t·∫°o factory
    model_factory.registry = registry
    
    # T·∫°o model
    model = model_factory.create_model('random_forest')
    
    # Test config
    config = {
        'preprocessor': {'remove_stopwords': True},
        'vectorizer': {'type': 'tfidf'},
        'use_fusion': False
    }
    
    # Build pipeline
    model.build_pipeline(config)
    
    # Test data
    X_text = ["This is a test document", "Another test document"]
    y = [0, 1]
    
    # Fit pipeline
    model.fit_pipeline(X_text, y)
    
    # Predict
    predictions = model.predict_pipeline(["New test document"])
    print(f"Predictions: {predictions}")

if __name__ == "__main__":
    test_new_model()
```

## B∆∞·ªõc 6: C·∫≠p nh·∫≠t Documentation

### 6.1 Th√™m v√†o `models/README.md`

```markdown
## Random Forest Model

### M√¥ t·∫£
Random Forest v·ªõi Model-Centric Pipeline, h·ªó tr·ª£ GPU qua cuML.

### C·∫•u h√¨nh m·∫∑c ƒë·ªãnh
- Preprocessor: stopwords removal, rare words filtering
- Vectorizer: TF-IDF v·ªõi n-gram (1,2)
- Feature Fusion: TF-IDF + Embeddings + additional features
- Estimator: RandomForestClassifier v·ªõi class_weight='balanced'

### S·ª≠ d·ª•ng
```python
from models.utils.model_factory import model_factory

# T·∫°o model
model = model_factory.create_model('random_forest')

# C·∫•u h√¨nh
config = {
    'preprocessor': {'remove_stopwords': True},
    'vectorizer': {'type': 'tfidf'},
    'use_fusion': True
}

# Build v√† fit
model.build_pipeline(config)
model.fit_pipeline(X_text, y)

# Predict
predictions = model.predict_pipeline(X_test_text)
```

## Checklist ho√†n th√†nh

- [ ] T·∫°o model class trong `models/classification/`
- [ ] Implement ƒë·∫ßy ƒë·ªß pipeline methods
- [ ] ƒêƒÉng k√Ω model trong `register_models.py`
- [ ] Th√™m config m·∫∑c ƒë·ªãnh v√†o `config.py`
- [ ] C·∫≠p nh·∫≠t Streamlit UI (Step 3)
- [ ] T·∫°o test script
- [ ] C·∫≠p nh·∫≠t documentation
- [ ] Test v·ªõi 300k samples t·ª´ arXiv

## L∆∞u √Ω quan tr·ªçng

1. **Memory optimization**: V·ªõi 300k samples, c·∫ßn ch√∫ √Ω memory usage
2. **GPU support**: Th√™m cuML support n·∫øu c√≥ GPU
3. **Caching**: S·ª≠ d·ª•ng `st.cache_resource` cho model training
4. **Error handling**: X·ª≠ l√Ω l·ªói gracefully trong UI
5. **Progress tracking**: Hi·ªÉn th·ªã progress khi train model l·ªõn

## V√≠ d·ª• Model ph·ª©c t·∫°p h∆°n

ƒê·ªÉ th√™m model ph·ª©c t·∫°p nh∆∞ XGBoost v·ªõi GPU:

```python
class XGBoostModel(BaseModel):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # GPU detection
        import torch
        self.device = 'gpu' if torch.cuda.is_available() else 'cpu'
        
        # XGBoost v·ªõi GPU flags
        xgb_params = self.model_params.copy()
        if self.device == 'gpu':
            xgb_params.update({
                'tree_method': 'gpu_hist',
                'predictor': 'gpu_predictor'
            })
        
        self.model = XGBClassifier(**xgb_params)
```

ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o model m·ªõi t√≠ch h·ª£p ho√†n to√†n v·ªõi ki·∫øn tr√∫c Model-Centric Pipeline v√† Streamlit UI hi·ªán c√≥.
