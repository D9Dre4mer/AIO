#!/usr/bin/env python3
"""
Auto Training Script - Test Enhanced ML Models
Tá»± Ä‘á»™ng Ä‘á»c file CSV vÃ  test cÃ¡c models má»›i Ä‘Ã£ implement

Usage:
    python auto_train.py

Features:
- Tá»± Ä‘á»™ng Ä‘á»c file CSV tá»« cache/
- Test 6 models má»›i: RandomForest, AdaBoost, GradientBoosting, XGBoost, LightGBM, CatBoost
- GPU acceleration cho XGBoost, LightGBM, CatBoost
- Optuna hyperparameter optimization
- Multi-input data processing vá»›i auto-detection
- SHAP model interpretability
- Sample size: 1000 samples Ä‘á»ƒ test nhanh
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime
import warnings

# Suppress warnings
warnings.filterwarnings("ignore")

# Add current directory to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def print_banner():
    """In banner chÃ o má»«ng"""
    print("=" * 80)
    print("ğŸ¤– ENHANCED ML MODELS - AUTO TESTING")
    print("ğŸš€ Testing New Models: RandomForest, AdaBoost, GradientBoosting")
    print("ğŸ”¥ GPU Models: XGBoost, LightGBM, CatBoost")
    print("ğŸ—ï¸ Stacking Ensemble: Meta-learner vá»›i 6 base models")
    print("âš¡ Features: Optuna, SHAP, Multi-Input, GPU Acceleration")
    print("=" * 80)
    print(f"â° Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)


def check_file_exists(file_path):
    """Kiá»ƒm tra file cÃ³ tá»“n táº¡i khÃ´ng"""
    if os.path.exists(file_path):
        print(f"âœ… Found file: {file_path}")
        return True
    else:
        print(f"âŒ File not found: {file_path}")
        return False


def create_sample_dataset():
    """Táº¡o dataset máº«u vá»›i 1000 samples Ä‘á»ƒ test"""
    print("ğŸ“Š Creating sample dataset with 1000 samples...")
    
    np.random.seed(42)
    n_samples = 1000
    
    # Táº¡o features sá»‘ há»c
    feature1 = np.random.normal(0, 1, n_samples)
    feature2 = np.random.normal(0, 1, n_samples)
    feature3 = np.random.uniform(0, 10, n_samples)
    feature4 = np.random.exponential(2, n_samples)
    
    # Táº¡o features categorical
    categories = ['A', 'B', 'C', 'D', 'E']
    feature5 = np.random.choice(categories, n_samples)
    
    # Táº¡o features text (simplified)
    text_samples = [
        "This is a sample text about machine learning and data science",
        "The model performs well on classification tasks",
        "We need to optimize hyperparameters for better performance",
        "Feature engineering is crucial for model accuracy",
        "Cross-validation helps prevent overfitting"
    ]
    feature6 = np.random.choice(text_samples, n_samples)
    
    # Táº¡o target labels (3 classes)
    # Táº¡o target dá»±a trÃªn combination cá»§a features Ä‘á»ƒ cÃ³ pattern
    target = np.zeros(n_samples, dtype=int)
    for i in range(n_samples):
        if feature1[i] > 0.5 and feature3[i] > 5:
            target[i] = 0  # Class 0
        elif feature2[i] < -0.5 or feature4[i] > 3:
            target[i] = 1  # Class 1
        else:
            target[i] = 2  # Class 2
    
    # Táº¡o DataFrame
    df = pd.DataFrame({
        'numeric_feature1': feature1,
        'numeric_feature2': feature2,
        'numeric_feature3': feature3,
        'numeric_feature4': feature4,
        'categorical_feature': feature5,
        'text_feature': feature6,
        'target': target
    })
    
    print("âœ… Sample dataset created!")
    print(f"   ğŸ“Š Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns")
    print(f"   ğŸ“‹ Columns: {list(df.columns)}")
    print(f"   ğŸ¯ Target classes: {df['target'].nunique()}")
    print("   ğŸ“Š Class distribution:")
    class_counts = df['target'].value_counts().sort_index()
    for class_id, count in class_counts.items():
        print(f"      - Class {class_id}: {count:,} samples ({count/n_samples*100:.1f}%)")
    
    return df


def load_or_create_dataset():
    """Äá»c dataset tá»« file hoáº·c táº¡o dataset máº«u"""
    # Thá»­ Ä‘á»c tá»« file cache trÆ°á»›c
    cache_files = [
        "cache/20250822-004129_sample-300_000Samples.csv",
        "cache/sample_dataset.csv",
        "data/sample_dataset.csv"
    ]
    
    for file_path in cache_files:
        if check_file_exists(file_path):
            try:
                print(f"ğŸ“‚ Loading dataset from: {file_path}")
                df = pd.read_csv(file_path)
                
                # Kiá»ƒm tra cÃ³ Ä‘á»§ samples khÃ´ng
                if len(df) < 100:
                    print(f"âš ï¸ Dataset too small ({len(df)} samples), creating sample dataset...")
                    return create_sample_dataset()
                
                # Náº¿u cÃ³ quÃ¡ nhiá»u samples, láº¥y sample
                if len(df) > 1000:
                    print(f"ğŸ“Š Dataset large ({len(df)} samples), sampling 1000 samples...")
                    df = df.sample(n=1000, random_state=42).reset_index(drop=True)
                
                print("âœ… Dataset loaded successfully!")
                print(f"   ğŸ“Š Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns")
                print(f"   ğŸ“‹ Columns: {list(df.columns)}")
                
                return df
                
            except Exception as e:
                print(f"âŒ Error loading {file_path}: {e}")
                continue
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y file nÃ o, táº¡o dataset máº«u
    print("ğŸ’¡ No suitable dataset found, creating sample dataset...")
    return create_sample_dataset()


def create_enhanced_config(df):
    """Táº¡o cáº¥u hÃ¬nh cho enhanced models"""
    print("\nğŸ”§ Creating enhanced configuration...")
    
    # Auto-detect label column
    label_candidates = ['target', 'label', 'category', 'class', 'y']
    label_column = None
    for col in label_candidates:
        if col in df.columns:
            label_column = col
            break
    
    if label_column is None:
        print("âŒ No label column found!")
        return None, None, None
    
    print(f"   ğŸ¯ Detected label column: {label_column}")
    
    # Auto-detect text column
    text_candidates = ['text_feature', 'abstract', 'text', 'content', 'description']
    text_column = None
    for col in text_candidates:
        if col in df.columns:
            text_column = col
            break
    
    print(f"   ğŸ“ Detected text column: {text_column}")
    
    # Step 1: Dataset configuration vá»›i multi-input
    step1_config = {
        'dataframe': df,
        'text_column': text_column,
        'label_column': label_column,
        'selected_categories': sorted(df[label_column].unique().tolist()),
        'is_multi_input': True,
        'input_columns': [col for col in df.columns if col != label_column],
        'type_mapping': {},  # Will be auto-detected
        'preprocessing_config': {
            'numeric_scaler': 'standard',
            'text_encoding': 'label',
            'missing_numeric': 'mean',
            'missing_text': 'mode'
        },
        'sampling_config': {
            'num_samples': len(df),
            'sampling_strategy': 'Stratified (Recommended)'
        },
        'completed': True
    }
    
    # Step 2: Preprocessing configuration
    step2_config = {
        'rare_words_removal': True,
        'rare_words_threshold': 2,
        'lemmatization': True,
        'context_aware_stopwords': True,
        'stopwords_aggressiveness': 'Moderate',
        'phrase_detection': True,
        'min_phrase_freq': 3,
        'completed': True
    }
    
    # Step 3: Enhanced model configuration
    step3_config = {
        'data_split': {
            'training': 80,
            'test': 20
        },
        'cross_validation': {
            'cv_folds': 5,
            'random_state': 42
        },
        # Test cÃ¡c models má»›i + stacking
        'selected_models': [
            'random_forest',
            'adaboost', 
            'gradient_boosting',
            'xgboost',
            'lightgbm',
            'catboost'
        ],
        'selected_vectorization': [
            'TF-IDF'  # Chá»‰ dÃ¹ng TF-IDF Ä‘á»ƒ test nhanh
        ],
        'ensemble_learning': {
            'eligible': True,  # Enable stacking vá»›i 6 base models
            'enabled': True,
            'final_estimator': 'logistic_regression',  # Meta-learner
            'base_models': ['random_forest', 'adaboost', 'gradient_boosting', 'xgboost', 'lightgbm', 'catboost'],
            'min_base_models': 4,  # Cáº§n Ã­t nháº¥t 4 base models
            'use_original_features': False,  # Chá»‰ dÃ¹ng predictions tá»« base models
            'cv_folds': 5,
            'stratified': True
        },
        # Optuna configuration
        'optuna': {
            'enabled': True,
            'trials': 20,  # Giáº£m trials Ä‘á»ƒ test nhanh
            'timeout': 300,  # 5 phÃºt timeout
            'direction': 'maximize'
        },
        'validation_errors': [],
        'validation_warnings': [],
        'completed': True
    }
    
    print("âœ… Enhanced configuration created!")
    print(f"   ğŸ“Š Models: {len(step3_config['selected_models'])} enhanced models")
    print(f"   ğŸ”¤ Vectorization: {len(step3_config['selected_vectorization'])} methods")
    print(f"   âš¡ Optuna Optimization: {'Enabled' if step3_config['optuna']['enabled'] else 'Disabled'}")
    print(f"   ğŸ¯ Total combinations: {len(step3_config['selected_models']) * len(step3_config['selected_vectorization'])}")
    print(f"   ğŸš€ GPU Models: XGBoost, LightGBM, CatBoost")
    print(f"   ğŸ—ï¸ Stacking Ensemble: {'Enabled' if step3_config['ensemble_learning']['enabled'] else 'Disabled'}")
    if step3_config['ensemble_learning']['enabled']:
        print(f"      - Meta-learner: {step3_config['ensemble_learning']['final_estimator']}")
        print(f"      - Base models: {len(step3_config['ensemble_learning']['base_models'])}")
        print(f"      - Min base models: {step3_config['ensemble_learning']['min_base_models']}")
        print(f"      - CV folds: {step3_config['ensemble_learning']['cv_folds']}")
    
    return step1_config, step2_config, step3_config


def run_enhanced_training(df, step1_config, step2_config, step3_config):
    """Cháº¡y training vá»›i enhanced models"""
    print("\nğŸš€ Starting enhanced model training...")
    
    try:
        # Import training pipeline
        from training_pipeline import StreamlitTrainingPipeline
        
        # Táº¡o pipeline instance
        pipeline = StreamlitTrainingPipeline()
        
        # Initialize pipeline vá»›i configs
        pipeline.initialize_pipeline(df, step1_config, step2_config, step3_config)
        
        # Progress callback function
        def progress_callback(phase, message, progress):
            print(f"   [{phase}] {message} ({progress:.1%})")
        
        # GPU Configuration check
        from gpu_config_manager import detect_gpu_availability, get_device_policy_config
        gpu_available, gpu_info = detect_gpu_availability()
        
        try:
            device_config = get_device_policy_config()
            device_policy = device_config.get('device_policy', 'unknown')
            cpu_jobs = device_config.get('n_jobs', 'unknown')
        except Exception as e:
            print(f"âš ï¸ Device config error: {e}")
            device_policy = 'unknown'
            cpu_jobs = 'unknown'
        
        print(f"\nğŸ–¥ï¸ DEVICE CONFIGURATION:")
        print(f"   GPU Available: {gpu_available}")
        if gpu_available:
            print(f"   GPU Info: {gpu_info}")
        print(f"   Device Policy: {device_policy}")
        print(f"   CPU Jobs: {cpu_jobs}")
        
        # Execute training
        print("\nğŸƒâ€â™‚ï¸ Executing training pipeline...")
        result = pipeline.execute_training(df, step1_config, step2_config, step3_config)
        
        if result and result.get('status') == 'success':
            print("âœ… Enhanced training completed successfully!")
            print(f"   ğŸ“Š Successful combinations: {result.get('successful_combinations', 0)}")
            print(f"   â±ï¸  Total time: {result.get('evaluation_time', 0):.1f}s")
            return result
        else:
            print(f"âŒ Enhanced training failed: {result.get('message', 'Unknown error') if result else 'No result'}")
            return None
            
    except Exception as e:
        print(f"âŒ Error during enhanced training: {e}")
        import traceback
        traceback.print_exc()
        return None


def display_enhanced_results(result):
    """Hiá»ƒn thá»‹ káº¿t quáº£ enhanced training"""
    if not result:
        print("âŒ No results to display")
        return
    
    print("\nğŸ“Š ENHANCED TRAINING RESULTS")
    print("=" * 60)
    
    # Best model
    best_combinations = result.get('best_combinations', {})
    best_overall = best_combinations.get('best_overall', {})
    
    if best_overall:
        print(f"ğŸ¥‡ Best Enhanced Model: {best_overall.get('combination_key', 'N/A')}")
        print(f"   ğŸ“ˆ F1 Score: {best_overall.get('f1_score', 0):.3f}")
        print(f"   ğŸ¯ Test Accuracy: {best_overall.get('test_accuracy', 0):.3f}")
        print(f"   â±ï¸  Training Time: {best_overall.get('training_time', 0):.1f}s")
        
        # Check if GPU was used
        if 'gpu' in str(best_overall.get('combination_key', '')).lower():
            print(f"   ğŸ”¥ GPU Acceleration: Used")
    
    # Summary statistics
    comprehensive_results = result.get('comprehensive_results', [])
    successful_results = [r for r in comprehensive_results if r.get('status') == 'success']
    
    if successful_results:
        print("\nğŸ“Š Enhanced Models Summary:")
        print(f"   âœ… Successful models: {len(successful_results)}")
        print(f"   ğŸ“ˆ Average F1 Score: {np.mean([r.get('f1_score', 0) for r in successful_results]):.3f}")
        print(f"   ğŸ¯ Average Accuracy: {np.mean([r.get('test_accuracy', 0) for r in successful_results]):.3f}")
        print(f"   â±ï¸  Average Training Time: {np.mean([r.get('training_time', 0) for r in successful_results]):.1f}s")
        
        # Check for stacking results
        stacking_results = [r for r in successful_results if 'stacking' in str(r.get('model_name', '')).lower() or 'ensemble' in str(r.get('model_name', '')).lower()]
        if stacking_results:
            print(f"\nğŸ—ï¸ Stacking Ensemble Results:")
            print(f"   âœ… Stacking models: {len(stacking_results)}")
            print(f"   ğŸ“ˆ Average F1 Score: {np.mean([r.get('f1_score', 0) for r in stacking_results]):.3f}")
            print(f"   ğŸ¯ Average Accuracy: {np.mean([r.get('test_accuracy', 0) for r in stacking_results]):.3f}")
            print(f"   â±ï¸  Average Training Time: {np.mean([r.get('training_time', 0) for r in stacking_results]):.1f}s")
        
        # Top 5 enhanced models
        print("\nğŸ† Top 5 Enhanced Models:")
        top_models = sorted(successful_results, key=lambda x: x.get('f1_score', 0), reverse=True)[:5]
        for i, model in enumerate(top_models, 1):
            model_name = f"{model.get('model_name', 'Unknown')} + {model.get('embedding_name', 'Unknown')}"
            f1_score = model.get('f1_score', 0)
            accuracy = model.get('test_accuracy', 0)
            training_time = model.get('training_time', 0)
            
            # Check if GPU model
            gpu_indicator = "ğŸ”¥" if any(gpu_model in model_name.lower() for gpu_model in ['xgboost', 'lightgbm', 'catboost']) else "ğŸ’»"
            
            print(f"   {i}. {gpu_indicator} {model_name}")
            print(f"      F1: {f1_score:.3f} | Accuracy: {accuracy:.3f} | Time: {training_time:.1f}s")
        
        # Model type breakdown
        print("\nğŸ“Š Model Type Performance:")
        model_types = {}
        for model in successful_results:
            model_name = model.get('model_name', 'Unknown')
            if 'stacking' in model_name.lower() or 'ensemble' in model_name.lower():
                model_type = 'Stacking Ensemble'
            elif 'random' in model_name.lower():
                model_type = 'Random Forest'
            elif 'ada' in model_name.lower():
                model_type = 'AdaBoost'
            elif 'gradient' in model_name.lower():
                model_type = 'Gradient Boosting'
            elif 'xgboost' in model_name.lower():
                model_type = 'XGBoost (GPU)'
            elif 'lightgbm' in model_name.lower():
                model_type = 'LightGBM (GPU)'
            elif 'catboost' in model_name.lower():
                model_type = 'CatBoost (GPU)'
            else:
                model_type = 'Other'
            
            if model_type not in model_types:
                model_types[model_type] = []
            model_types[model_type].append(model.get('f1_score', 0))
        
        for model_type, scores in model_types.items():
            avg_score = np.mean(scores)
            icon = "ğŸ—ï¸" if "Stacking" in model_type else "ğŸ”¥" if "GPU" in model_type else "ğŸ’»"
            print(f"   {icon} {model_type}: {avg_score:.3f} (avg F1)")


def main():
    """HÃ m main chÃ­nh"""
    print_banner()
    
    # Load hoáº·c táº¡o dataset
    df = load_or_create_dataset()
    if df is None:
        print("âŒ Failed to load/create dataset")
        return
    
    # Táº¡o enhanced configuration
    step1_config, step2_config, step3_config = create_enhanced_config(df)
    
    # Cháº¡y enhanced training
    result = run_enhanced_training(df, step1_config, step2_config, step3_config)
    
    # Hiá»ƒn thá»‹ káº¿t quáº£
    display_enhanced_results(result)
    
    print("\n" + "=" * 80)
    print("ğŸ‰ ENHANCED MODEL TESTING COMPLETED!")
    print(f"â° Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    if result:
        print("ğŸ’¾ Results cached for future use!")
        print("ğŸš€ Enhanced models are ready for production!")
        print("âš¡ GPU acceleration tested successfully!")
        print("ğŸ” Optuna optimization completed!")
    else:
        print("âš ï¸ Some issues encountered during testing")
        print("ğŸ’¡ Check logs above for details")


if __name__ == "__main__":
    main()