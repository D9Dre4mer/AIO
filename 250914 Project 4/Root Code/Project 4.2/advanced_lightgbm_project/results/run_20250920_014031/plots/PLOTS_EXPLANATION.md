# ğŸ“Š HÆ°á»›ng Dáº«n Chi Tiáº¿t Táº¥t Cáº£ Biá»ƒu Äá»“ - Advanced LightGBM Project

## ğŸ¯ Tá»•ng Quan

Dá»± Ã¡n Advanced LightGBM táº¡o ra **25 biá»ƒu Ä‘á»“ PNG + 1 biá»ƒu Ä‘á»“ PDF** (tá»•ng cá»™ng 26 files) Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh. CÃ¡c biá»ƒu Ä‘á»“ Ä‘Æ°á»£c chia thÃ nh 4 nhÃ³m chÃ­nh:

1. **ğŸ”§ Optimization & Training** (6 biá»ƒu Ä‘á»“)
2. **ğŸ“ˆ Performance Evaluation** (6 biá»ƒu Ä‘á»“) 
3. **ğŸ§  Model Interpretability** (4 biá»ƒu Ä‘á»“)
4. **ğŸ“Š Comprehensive Analysis** (9 biá»ƒu Ä‘á»“)

---

## ğŸ”§ 1. OPTIMIZATION & TRAINING PLOTS

### 1.1 `00_lightgbm_optimization.png`
**Má»¥c Ä‘Ã­ch**: TÃ¬m sá»‘ lÆ°á»£ng estimators (n_estimators) tá»‘i Æ°u cho LightGBM báº±ng Cross-Validation

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: Sá»‘ lÆ°á»£ng estimators (n_estimators) - tá»« 50 Ä‘áº¿n 500
- **Trá»¥c Y**: Cross-Validation Accuracy
- **ÄÆ°á»ng cong xanh**: Hiá»‡u suáº¥t CV accuracy theo sá»‘ estimators
- **Äiá»ƒm cao nháº¥t**: Sá»‘ estimators tá»‘i Æ°u
- **Grid**: LÆ°á»›i Ä‘á»ƒ dá»… Ä‘á»c giÃ¡ trá»‹

**Ã nghÄ©a**:
- Äiá»ƒm cao nháº¥t â†’ sá»‘ estimators tá»‘t nháº¥t cho mÃ´ hÃ¬nh
- Náº¿u Ä‘Æ°á»ng cong náº±m ngang â†’ cÃ³ thá»ƒ dá»«ng sá»›m Ä‘á»ƒ trÃ¡nh overfitting
- Náº¿u Ä‘Æ°á»ng cong giáº£m â†’ cÃ³ thá»ƒ bá»‹ overfitting vá»›i quÃ¡ nhiá»u estimators
- GiÃºp cÃ¢n báº±ng giá»¯a hiá»‡u suáº¥t vÃ  thá»i gian training

### 1.2 `01_lightgbm_performance_comparison.png` & `01_lightgbm_performance_comparison.pdf`
**Má»¥c Ä‘Ã­ch**: So sÃ¡nh hiá»‡u suáº¥t Validation vs Test cá»§a cÃ¡c dataset khÃ¡c nhau

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: TÃªn cÃ¡c dataset (Raw, FE, DT, FE+DT)
- **Trá»¥c Y**: Äá»™ chÃ­nh xÃ¡c (Accuracy) - tá»« 0.5 Ä‘áº¿n 1.05
- **Thanh xanh**: Validation Accuracy
- **Thanh Ä‘á»**: Test Accuracy
- **Sá»‘ trÃªn thanh**: GiÃ¡ trá»‹ chÃ­nh xÃ¡c cá»¥ thá»ƒ

**Ã nghÄ©a**:
- **Raw**: Dataset gá»‘c
- **FE**: Dataset vá»›i Feature Engineering
- **DT**: Dataset vá»›i Decision Tree features
- **FE+DT**: Dataset káº¿t há»£p cáº£ hai
- Thanh gáº§n nhau â†’ mÃ´ hÃ¬nh generalizes tá»‘t
- Thanh xa nhau â†’ cÃ³ thá»ƒ bá»‹ overfitting hoáº·c underfitting

**LÆ°u Ã½**: File cÃ³ cáº£ Ä‘á»‹nh dáº¡ng PNG (cho web) vÃ  PDF (cho in áº¥n)

### 1.3 `02_lightgbm_cv_scores.png`
**Má»¥c Ä‘Ã­ch**: Hiá»ƒn thá»‹ káº¿t quáº£ Cross-Validation cá»§a cÃ¡c mÃ´ hÃ¬nh

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: TÃªn cÃ¡c mÃ´ hÃ¬nh (Raw, FE, DT, FE+DT)
- **Trá»¥c Y**: Äiá»ƒm sá»‘ Cross-Validation (CV Score)
- **Thanh cá»™t**: Äiá»ƒm trung bÃ¬nh cá»§a má»—i mÃ´ hÃ¬nh
- **Thanh lá»—i**: Äá»™ lá»‡ch chuáº©n (standard deviation)
- **Sá»‘ trÃªn thanh**: GiÃ¡ trá»‹ chÃ­nh xÃ¡c cá»¥ thá»ƒ

**Ã nghÄ©a**:
- Thanh cao â†’ mÃ´ hÃ¬nh tá»‘t hÆ¡n
- Thanh lá»—i ngáº¯n â†’ mÃ´ hÃ¬nh á»•n Ä‘á»‹nh qua cÃ¡c fold
- Thanh lá»—i dÃ i â†’ mÃ´ hÃ¬nh khÃ´ng á»•n Ä‘á»‹nh
- So sÃ¡nh hiá»‡u suáº¥t giá»¯a cÃ¡c phiÃªn báº£n dá»¯ liá»‡u khÃ¡c nhau

### 1.4 `03_lightgbm_optimal_estimators.png`
**Má»¥c Ä‘Ã­ch**: So sÃ¡nh sá»‘ lÆ°á»£ng estimators tá»‘i Æ°u cá»§a cÃ¡c dataset khÃ¡c nhau

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: TÃªn cÃ¡c dataset (Raw, FE, DT, FE+DT)
- **Trá»¥c Y**: Sá»‘ lÆ°á»£ng estimators tá»‘i Æ°u (n_estimators)
- **Thanh cam**: Sá»‘ estimators Ä‘Æ°á»£c chá»n cho má»—i dataset
- **Sá»‘ trÃªn thanh**: GiÃ¡ trá»‹ n_estimators cá»¥ thá»ƒ

**Ã nghÄ©a**:
- **Raw**: Sá»‘ estimators tá»‘i Æ°u cho dataset gá»‘c
- **FE**: Sá»‘ estimators tá»‘i Æ°u cho dataset vá»›i Feature Engineering
- **DT**: Sá»‘ estimators tá»‘i Æ°u cho dataset vá»›i Decision Tree features
- **FE+DT**: Sá»‘ estimators tá»‘i Æ°u cho dataset káº¿t há»£p
- Sá»‘ cao â†’ dataset phá»©c táº¡p hÆ¡n, cáº§n nhiá»u estimators
- Sá»‘ tháº¥p â†’ dataset Ä‘Æ¡n giáº£n hÆ¡n, Ã­t estimators Ä‘Ã£ Ä‘á»§

### 1.5 `04_lightgbm_validation_vs_test.png`
**Má»¥c Ä‘Ã­ch**: PhÃ¢n tÃ­ch tÆ°Æ¡ng quan giá»¯a Validation Accuracy vÃ  Test Accuracy

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: Validation Accuracy
- **Trá»¥c Y**: Test Accuracy
- **Äiá»ƒm mÃ u**: Má»—i dataset má»™t mÃ u (Raw=Ä‘á», FE=xanh, DT=xanh lÃ¡, FE+DT=cam)
- **ÄÆ°á»ng chÃ©o Ä‘á»©t nÃ©t**: Perfect Correlation (tÆ°Æ¡ng quan hoÃ n háº£o)
- **NhÃ£n**: TÃªn dataset gáº§n má»—i Ä‘iá»ƒm

**Ã nghÄ©a**:
- Äiá»ƒm gáº§n Ä‘Æ°á»ng chÃ©o â†’ mÃ´ hÃ¬nh generalizes tá»‘t
- Äiá»ƒm xa Ä‘Æ°á»ng chÃ©o â†’ cÃ³ thá»ƒ bá»‹ overfitting hoáº·c underfitting
- Äiá»ƒm trÃªn Ä‘Æ°á»ng chÃ©o â†’ Test > Validation (tá»‘t)
- Äiá»ƒm dÆ°á»›i Ä‘Æ°á»ng chÃ©o â†’ Test < Validation (cÃ³ thá»ƒ overfitting)
- MÃ u sáº¯c giÃºp phÃ¢n biá»‡t cÃ¡c dataset khÃ¡c nhau

### 1.6 `05_lightgbm_performance_heatmap.png`
**Má»¥c Ä‘Ã­ch**: Heatmap hiá»‡u suáº¥t cá»§a cÃ¡c dataset khÃ¡c nhau trÃªn cÃ¡c metric khÃ¡c nhau

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: CÃ¡c metric (Validation Accuracy, Test Accuracy, CV Score)
- **Trá»¥c Y**: CÃ¡c dataset (Raw, FE, DT, FE+DT)
- **MÃ u sáº¯c**: Äiá»ƒm sá»‘ (xanh = cao, Ä‘á» = tháº¥p, vÃ ng = trung bÃ¬nh)
- **Sá»‘ trong Ã´**: GiÃ¡ trá»‹ cá»¥ thá»ƒ (0.5-1.0)
- **Colorbar**: Thang mÃ u tá»« 0.5 Ä‘áº¿n 1.0

**Ã nghÄ©a**:
- MÃ u xanh Ä‘áº­m â†’ hiá»‡u suáº¥t cao trÃªn metric Ä‘Ã³
- MÃ u Ä‘á» Ä‘áº­m â†’ hiá»‡u suáº¥t tháº¥p trÃªn metric Ä‘Ã³
- HÃ ng xanh â†’ dataset tá»‘t trÃªn táº¥t cáº£ metric
- Cá»™t xanh â†’ metric á»•n Ä‘á»‹nh qua cÃ¡c dataset
- So sÃ¡nh hiá»‡u suáº¥t tá»•ng thá»ƒ cá»§a tá»«ng dataset

---

## ğŸ“ˆ 2. PERFORMANCE EVALUATION PLOTS

### 2.1 `02_roc_curve.png`
**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ kháº£ nÄƒng phÃ¢n loáº¡i cá»§a mÃ´ hÃ¬nh

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: False Positive Rate (1 - Specificity)
- **Trá»¥c Y**: True Positive Rate (Sensitivity/Recall)
- **ÄÆ°á»ng chÃ©o Ä‘á»©t nÃ©t**: Random classifier (AUC = 0.5)
- **ÄÆ°á»ng cong mÃ u cam**: ROC curve cá»§a mÃ´ hÃ¬nh
- **AUC Score**: Hiá»ƒn thá»‹ trong legend (thÆ°á»ng > 0.8)
- **Grid**: LÆ°á»›i Ä‘á»ƒ dá»… Ä‘á»c giÃ¡ trá»‹

**Ã nghÄ©a**:
- AUC = 1.0 â†’ Perfect classifier
- AUC = 0.5 â†’ Random classifier
- AUC > 0.8 â†’ Good classifier
- ÄÆ°á»ng cong cÃ ng gáº§n gÃ³c trÃªn trÃ¡i cÃ ng tá»‘t
- Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong cÃ ng lá»›n cÃ ng tá»‘t

### 2.2 `03_precision_recall_curve.png`
**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t khi cÃ³ class imbalance

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: Recall (True Positive Rate)
- **Trá»¥c Y**: Precision (Positive Predictive Value)
- **ÄÆ°á»ng cong mÃ u xanh**: Precision-Recall curve
- **AP Score**: Average Precision score (hiá»ƒn thá»‹ trong legend)
- **Grid**: LÆ°á»›i Ä‘á»ƒ dá»… Ä‘á»c giÃ¡ trá»‹
- **Baseline**: ÄÆ°á»ng ngang cho random classifier

**Ã nghÄ©a**:
- AP = 1.0 â†’ Perfect classifier
- AP > 0.8 â†’ Good classifier
- ÄÆ°á»ng cong cÃ ng gáº§n gÃ³c trÃªn pháº£i cÃ ng tá»‘t
- Quan trá»ng khi cÃ³ class imbalance
- Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong cÃ ng lá»›n cÃ ng tá»‘t

### 2.3 `04_confusion_matrix.png`
**Má»¥c Ä‘Ã­ch**: Hiá»ƒn thá»‹ chi tiáº¿t káº¿t quáº£ phÃ¢n loáº¡i

**CÃ¡ch Ä‘á»c**:
- **HÃ ng**: True labels (Actual)
- **Cá»™t**: Predicted labels (Predicted)
- **Ã” trÃªn trÃ¡i**: True Negative (TN) - Dá»± Ä‘oÃ¡n Ä‘Ãºng negative
- **Ã” trÃªn pháº£i**: False Positive (FP) - Dá»± Ä‘oÃ¡n sai positive
- **Ã” dÆ°á»›i trÃ¡i**: False Negative (FN) - Dá»± Ä‘oÃ¡n sai negative
- **Ã” dÆ°á»›i pháº£i**: True Positive (TP) - Dá»± Ä‘oÃ¡n Ä‘Ãºng positive
- **Sá»‘ trong Ã´**: Sá»‘ lÆ°á»£ng máº«u
- **MÃ u sáº¯c**: CÃ ng Ä‘áº­m cÃ ng nhiá»u máº«u

**Ã nghÄ©a**:
- ÄÆ°á»ng chÃ©o chÃ­nh cao â†’ mÃ´ hÃ¬nh tá»‘t
- TP vÃ  TN cao â†’ mÃ´ hÃ¬nh chÃ­nh xÃ¡c
- FP vÃ  FN tháº¥p â†’ Ã­t lá»—i
- CÃ³ thá»ƒ tÃ­nh accuracy = (TP+TN)/(TP+TN+FP+FN)

### 2.4 `05_prediction_distribution.png`
**Má»¥c Ä‘Ã­ch**: PhÃ¢n tÃ­ch phÃ¢n bá»‘ cá»§a predictions

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: GiÃ¡ trá»‹ prediction probability
- **Trá»¥c Y**: Táº§n suáº¥t (frequency)
- **Histogram xanh**: Class 0 (Negative)
- **Histogram Ä‘á»**: Class 1 (Positive)

**Ã nghÄ©a**:
- PhÃ¢n bá»‘ tÃ¡ch biá»‡t â†’ mÃ´ hÃ¬nh phÃ¢n loáº¡i tá»‘t
- PhÃ¢n bá»‘ chá»“ng láº¥p â†’ mÃ´ hÃ¬nh khÃ³ phÃ¢n biá»‡t
- Threshold tá»‘i Æ°u á»Ÿ Ä‘iá»ƒm giao nhau

### 2.5 `06_metrics_comparison.png`
**Má»¥c Ä‘Ã­ch**: So sÃ¡nh cÃ¡c metric khÃ¡c nhau

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: CÃ¡c mÃ´ hÃ¬nh
- **Trá»¥c Y**: Äiá»ƒm sá»‘ metric
- **Thanh khÃ¡c mÃ u**: CÃ¡c metric khÃ¡c nhau
- **Legend**: Giáº£i thÃ­ch mÃ u sáº¯c

**Ã nghÄ©a**:
- Thanh cao â†’ mÃ´ hÃ¬nh tá»‘t trÃªn metric Ä‘Ã³
- CÃ¢n báº±ng giá»¯a cÃ¡c metric â†’ mÃ´ hÃ¬nh á»•n Ä‘á»‹nh
- Má»™t metric quÃ¡ cao/ tháº¥p â†’ cáº§n Ä‘iá»u chá»‰nh

### 2.6 `06_lightgbm_improvement_chart.png`
**Má»¥c Ä‘Ã­ch**: Hiá»ƒn thá»‹ sá»± cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a cÃ¡c dataset so vá»›i baseline (Raw dataset)

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: CÃ¡c dataset (Raw, FE, DT, FE+DT)
- **Trá»¥c Y**: Pháº§n trÄƒm cáº£i thiá»‡n (%) - cÃ³ thá»ƒ Ã¢m hoáº·c dÆ°Æ¡ng
- **Thanh xanh nháº¡t**: Validation Improvement  (%)
- **Thanh há»“ng nháº¡t**: Test Improvement (%)
- **ÄÆ°á»ng ngang Ä‘en**: Baseline (0% improvement)
- **Sá»‘ trÃªn thanh**: GiÃ¡ trá»‹ cáº£i thiá»‡n cá»¥ thá»ƒ (+/-%)

**Ã nghÄ©a**:
- Thanh dÆ°Æ¡ng â†’ dataset tá»‘t hÆ¡n baseline
- Thanh Ã¢m â†’ dataset kÃ©m hÆ¡n baseline
- Raw dataset luÃ´n cÃ³ 0% improvement (baseline)
- FE, DT, FE+DT so sÃ¡nh vá»›i Raw dataset
- Cáº£i thiá»‡n cao â†’ ká»¹ thuáº­t hiá»‡u quáº£

### 2.7 `07_radar_chart.png`
**Má»¥c Ä‘Ã­ch**: Hiá»ƒn thá»‹ hiá»‡u suáº¥t tá»•ng thá»ƒ cá»§a mÃ´ hÃ¬nh

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c**: CÃ¡c metric Ä‘Ã¡nh giÃ¡ (Accuracy, Precision, Recall, F1, AUC-ROC)
- **ÄÆ°á»ng cong**: Hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh
- **VÃ¹ng tÃ´ mÃ u**: Diá»‡n tÃ­ch hiá»‡u suáº¥t tá»•ng thá»ƒ
- **GiÃ¡ trá»‹ 0-1**: 0 = kÃ©m nháº¥t, 1 = tá»‘t nháº¥t

**Ã nghÄ©a**:
- HÃ¬nh trÃ²n Ä‘á»u â†’ mÃ´ hÃ¬nh cÃ¢n báº±ng
- HÃ¬nh lá»‡ch â†’ mÃ´ hÃ¬nh máº¡nh/yáº¿u á»Ÿ má»™t sá»‘ metric
- Diá»‡n tÃ­ch lá»›n â†’ hiá»‡u suáº¥t tá»•ng thá»ƒ cao

### 2.8 `07_lightgbm_radar_chart.png`
**Má»¥c Ä‘Ã­ch**: So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c dataset khÃ¡c nhau trÃªn radar chart

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c**: 4 metric (Validation Accuracy, Test Accuracy, CV Score, Normalized n_estimators)
- **ÄÆ°á»ng cong**: Má»—i dataset má»™t mÃ u (Raw=Ä‘á», FE=xanh, DT=xanh lÃ¡, FE+DT=cam)
- **VÃ¹ng tÃ´ mÃ u**: Hiá»‡u suáº¥t cá»§a tá»«ng dataset (alpha=0.25)
- **Legend**: Giáº£i thÃ­ch mÃ u sáº¯c vÃ  dataset
- **Thang Ä‘o**: 0-1 (n_estimators Ä‘Æ°á»£c normalize)

**Ã nghÄ©a**:
- HÃ¬nh trÃ²n lá»›n â†’ dataset tá»‘t trÃªn táº¥t cáº£ metric
- HÃ¬nh lá»‡ch â†’ dataset máº¡nh/yáº¿u á»Ÿ má»™t sá»‘ metric
- VÃ¹ng chá»“ng láº¥p â†’ dataset tÆ°Æ¡ng Ä‘Æ°Æ¡ng
- VÃ¹ng riÃªng biá»‡t â†’ dataset khÃ¡c biá»‡t rÃµ rÃ ng
- So sÃ¡nh tá»•ng thá»ƒ hiá»‡u suáº¥t cá»§a tá»«ng dataset

---

## ğŸ§  3. MODEL INTERPRETABILITY PLOTS

### 3.1 `08_feature_importance.png`
**Má»¥c Ä‘Ã­ch**: XÃ¡c Ä‘á»‹nh Ä‘áº·c trÆ°ng nÃ o áº£nh hÆ°á»Ÿng nháº¥t Ä‘áº¿n káº¿t quáº£ dá»± Ä‘oÃ¡n

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c Y**: TÃªn cÃ¡c Ä‘áº·c trÆ°ng (features)
- **Trá»¥c X**: Má»©c Ä‘á»™ quan trá»ng (Gain score)
- **Thanh dÃ i**: Äáº·c trÆ°ng quan trá»ng hÆ¡n
- **MÃ u sáº¯c**: ThÆ°á»ng xanh dÆ°Æ¡ng, cÃ ng Ä‘áº­m cÃ ng quan trá»ng

**Ã nghÄ©a**:
- Top 5-10 Ä‘áº·c trÆ°ng â†’ táº­p trung vÃ o nhá»¯ng Ä‘áº·c trÆ°ng nÃ y
- Äáº·c trÆ°ng cÃ³ Ä‘iá»ƒm tháº¥p â†’ cÃ³ thá»ƒ loáº¡i bá»
- PhÃ¢n bá»‘ Ä‘á»u â†’ dá»¯ liá»‡u cÃ¢n báº±ng

### 3.2 `09_shap_summary.png`
**Má»¥c Ä‘Ã­ch**: Giáº£i thÃ­ch cÃ¡ch mÃ´ hÃ¬nh Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c Y**: CÃ¡c Ä‘áº·c trÆ°ng (features)
- **Trá»¥c X**: SHAP values (tÃ¡c Ä‘á»™ng Ä‘áº¿n dá»± Ä‘oÃ¡n)
- **MÃ u Ä‘á»**: GiÃ¡ trá»‹ cao cá»§a Ä‘áº·c trÆ°ng
- **MÃ u xanh**: GiÃ¡ trá»‹ tháº¥p cá»§a Ä‘áº·c trÆ°ng
- **Vá»‹ trÃ­**: BÃªn pháº£i = tÄƒng xÃ¡c suáº¥t, bÃªn trÃ¡i = giáº£m xÃ¡c suáº¥t

**Ã nghÄ©a**:
- Äiá»ƒm Ä‘á» bÃªn pháº£i â†’ Ä‘áº·c trÆ°ng cÃ³ giÃ¡ trá»‹ cao â†’ tÄƒng xÃ¡c suáº¥t dá»± Ä‘oÃ¡n
- Äiá»ƒm xanh bÃªn trÃ¡i â†’ Ä‘áº·c trÆ°ng cÃ³ giÃ¡ trá»‹ tháº¥p â†’ giáº£m xÃ¡c suáº¥t dá»± Ä‘oÃ¡n
- Äá»™ rá»™ng â†’ má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng cá»§a Ä‘áº·c trÆ°ng

### 3.3 `10_shap_waterfall.png`
**Má»¥c Ä‘Ã­ch**: Giáº£i thÃ­ch chi tiáº¿t má»™t prediction cá»¥ thá»ƒ

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c Y**: CÃ¡c Ä‘áº·c trÆ°ng
- **Trá»¥c X**: SHAP values
- **Thanh xanh**: TÄƒng xÃ¡c suáº¥t dá»± Ä‘oÃ¡n
- **Thanh Ä‘á»**: Giáº£m xÃ¡c suáº¥t dá»± Ä‘oÃ¡n
- **ÄÆ°á»ng tÃ­ch lÅ©y**: Tá»•ng tÃ¡c Ä‘á»™ng

**Ã nghÄ©a**:
- Thanh dÃ i â†’ Ä‘áº·c trÆ°ng cÃ³ tÃ¡c Ä‘á»™ng lá»›n
- MÃ u xanh â†’ Ä‘áº·c trÆ°ng á»§ng há»™ prediction
- MÃ u Ä‘á» â†’ Ä‘áº·c trÆ°ng pháº£n Ä‘á»‘i prediction

### 3.4 `08_lightgbm_trend_analysis.png`
**Má»¥c Ä‘Ã­ch**: PhÃ¢n tÃ­ch xu hÆ°á»›ng hiá»‡u suáº¥t vÃ  má»‘i quan há»‡ giá»¯a n_estimators vÃ  performance

**CÃ¡ch Ä‘á»c**:
- **Layout 2x1**: Hai subplot dá»c
- **Subplot trÃªn - Accuracy Trend**:
  - **Trá»¥c X**: CÃ¡c dataset (Raw, FE, DT, FE+DT)
  - **Trá»¥c Y**: Accuracy
  - **ÄÆ°á»ng xanh**: Validation Accuracy (hÃ¬nh trÃ²n)
  - **ÄÆ°á»ng Ä‘á»**: Test Accuracy (hÃ¬nh vuÃ´ng)
  - **Sá»‘ trÃªn Ä‘iá»ƒm**: GiÃ¡ trá»‹ accuracy cá»¥ thá»ƒ
- **Subplot dÆ°á»›i - n_estimators vs Performance**:
  - **Trá»¥c X**: Optimal n_estimators
  - **Trá»¥c Y**: Accuracy
  - **Äiá»ƒm xanh**: Validation Accuracy
  - **Äiá»ƒm Ä‘á»**: Test Accuracy
  - **NhÃ£n**: TÃªn dataset gáº§n má»—i Ä‘iá»ƒm

**Ã nghÄ©a**:
- Xu hÆ°á»›ng tÄƒng â†’ dataset cáº£i thiá»‡n hiá»‡u suáº¥t
- Xu hÆ°á»›ng giáº£m â†’ dataset cÃ³ váº¥n Ä‘á»
- Má»‘i quan há»‡ n_estimators vs accuracy â†’ tÃ¬m Ä‘iá»ƒm tá»‘i Æ°u
- Äiá»ƒm tÃ¡ch biá»‡t â†’ dataset khÃ¡c biá»‡t rÃµ rÃ ng

---

## ğŸ“Š 4. COMPREHENSIVE ANALYSIS PLOTS

### 4.1 `09_lightgbm_distribution_analysis.png`
**Má»¥c Ä‘Ã­ch**: PhÃ¢n tÃ­ch phÃ¢n bá»‘ hiá»‡u suáº¥t cá»§a cÃ¡c metric khÃ¡c nhau qua táº¥t cáº£ dataset

**CÃ¡ch Ä‘á»c**:
- **Trá»¥c X**: CÃ¡c metric (Validation Accuracy, Test Accuracy, CV Score)
- **Trá»¥c Y**: Accuracy Score
- **Box plot**: PhÃ¢n bá»‘ cá»§a tá»«ng metric
- **MÃ u sáº¯c**: Má»—i metric má»™t mÃ u (xanh nháº¡t, há»“ng nháº¡t, xanh lÃ¡ nháº¡t)
- **Whiskers**: Pháº¡m vi giÃ¡ trá»‹
- **Median**: ÄÆ°á»ng giá»¯a há»™p

**Ã nghÄ©a**:
- Box lá»›n â†’ metric cÃ³ biáº¿n Ä‘á»™ng cao
- Box nhá» â†’ metric á»•n Ä‘á»‹nh
- Median cao â†’ metric cÃ³ hiá»‡u suáº¥t tá»‘t
- Whiskers dÃ i â†’ cÃ³ outlier hoáº·c biáº¿n Ä‘á»™ng lá»›n
- So sÃ¡nh Ä‘á»™ á»•n Ä‘á»‹nh cá»§a cÃ¡c metric khÃ¡c nhau

### 4.2 `10_lightgbm_comprehensive_summary.png`
**Má»¥c Ä‘Ã­ch**: Tá»•ng há»£p táº¥t cáº£ thÃ´ng tin quan trá»ng vá» hiá»‡u suáº¥t cá»§a cÃ¡c dataset

**CÃ¡ch Ä‘á»c**:
- **Layout 2x2**: Bá»‘n subplot trong má»™t hÃ¬nh
- **GÃ³c trÃªn trÃ¡i - Accuracy Comparison**:
  - **Thanh xanh nháº¡t**: Validation Accuracy
  - **Thanh há»“ng nháº¡t**: Test Accuracy
  - **Trá»¥c X**: CÃ¡c dataset (Raw, FE, DT, FE+DT)
- **GÃ³c trÃªn pháº£i - Cross-Validation Scores**:
  - **Thanh xanh lÃ¡ nháº¡t**: CV Score
  - **Trá»¥c X**: CÃ¡c dataset
- **GÃ³c dÆ°á»›i trÃ¡i - Optimal n_estimators**:
  - **Thanh cam**: Sá»‘ estimators tá»‘i Æ°u
  - **Trá»¥c X**: CÃ¡c dataset
- **GÃ³c dÆ°á»›i pháº£i - Generalization Performance**:
  - **Thanh tÃ­m**: Tá»· lá»‡ Test/Validation
  - **ÄÆ°á»ng Ä‘á» Ä‘á»©t nÃ©t**: Perfect Generalization (ratio = 1)

**Ã nghÄ©a**:
- CÃ¡i nhÃ¬n tá»•ng quan vá» hiá»‡u suáº¥t cá»§a tá»«ng dataset
- So sÃ¡nh trá»±c tiáº¿p giá»¯a cÃ¡c dataset
- ÄÃ¡nh giÃ¡ kháº£ nÄƒng generalization
- ThÃ´ng tin Ä‘áº§y Ä‘á»§ trong má»™t biá»ƒu Ä‘á»“

### 4.3 `11_training_history.png`
**Má»¥c Ä‘Ã­ch**: Theo dÃµi quÃ¡ trÃ¬nh há»c cá»§a mÃ´ hÃ¬nh

**CÃ¡ch Ä‘á»c**:
- **Layout 1x2**: Hai subplot cáº¡nh nhau
- **Biá»ƒu Ä‘á»“ trÃ¡i - Training History**:
  - **Trá»¥c X**: Number of Iterations
  - **Trá»¥c Y**: Binary Log Loss
  - **ÄÆ°á»ng xanh**: Training Loss
  - **ÄÆ°á»ng Ä‘á»**: Validation Loss
  - **ÄÆ°á»ng xanh lÃ¡ Ä‘á»©t nÃ©t**: Best Iteration (early stopping)
- **Biá»ƒu Ä‘á»“ pháº£i - Feature Importance**:
  - **Trá»¥c Y**: Top 10 Most Important Features
  - **Trá»¥c X**: Importance Score
  - **Thanh ngang**: Má»©c Ä‘á»™ quan trá»ng cá»§a tá»«ng feature

**Ã nghÄ©a**:
- Overfitting: Training loss giáº£m, validation loss tÄƒng
- Underfitting: Cáº£ hai Ä‘Æ°á»ng Ä‘á»u cao vÃ  khÃ´ng giáº£m
- Tá»‘t: Cáº£ hai Ä‘Æ°á»ng Ä‘á»u giáº£m vÃ  gáº§n nhau
- Early stopping: Dá»«ng táº¡i best iteration Ä‘á»ƒ trÃ¡nh overfitting

### 4.4 `11_raw_comprehensive_evaluation.png`
**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ toÃ n diá»‡n mÃ´ hÃ¬nh vá»›i dá»¯ liá»‡u gá»‘c

**CÃ¡ch Ä‘á»c**:
- **Layout 2x3**: 6 subplot trong má»™t hÃ¬nh
- **GÃ³c trÃªn trÃ¡i**: ROC Curve vá»›i AUC score
- **GÃ³c trÃªn giá»¯a**: Precision-Recall Curve vá»›i AP score
- **GÃ³c trÃªn pháº£i**: Confusion Matrix
- **GÃ³c dÆ°á»›i trÃ¡i**: Feature Importance (top features)
- **GÃ³c dÆ°á»›i giá»¯a**: Prediction Distribution
- **GÃ³c dÆ°á»›i pháº£i**: Performance Metrics (Accuracy, Precision, Recall, F1, AUC)

**Ã nghÄ©a**:
- Baseline performance cá»§a mÃ´ hÃ¬nh vá»›i dá»¯ liá»‡u gá»‘c
- So sÃ¡nh vá»›i cÃ¡c phiÃªn báº£n cáº£i tiáº¿n (FE, DT, FE+DT)
- Äiá»ƒm khá»Ÿi Ä‘áº§u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a feature engineering

### 4.5 `11_fe_comprehensive_evaluation.png`
**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ toÃ n diá»‡n mÃ´ hÃ¬nh vá»›i Feature Engineering

**CÃ¡ch Ä‘á»c**:
- **Layout 2x3**: TÆ°Æ¡ng tá»± nhÆ° raw evaluation
- **CÃ¡c subplot**: ROC, Precision-Recall, Confusion Matrix, Feature Importance, Prediction Distribution, Metrics
- **So sÃ¡nh**: CÃ³ thá»ƒ so sÃ¡nh trá»±c tiáº¿p vá»›i raw evaluation
- **Cáº£i thiá»‡n**: ThÆ°á»ng tháº¥y improvement trong cÃ¡c metrics

**Ã nghÄ©a**:
- TÃ¡c Ä‘á»™ng cá»§a Feature Engineering techniques
- Cáº£i thiá»‡n performance so vá»›i raw data
- Hiá»‡u quáº£ cá»§a cÃ¡c ká»¹ thuáº­t FE Ä‘Æ°á»£c Ã¡p dá»¥ng
- Validation cho viá»‡c feature engineering cÃ³ hiá»‡u quáº£

### 4.6 `11_dt_comprehensive_evaluation.png`
**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ toÃ n diá»‡n mÃ´ hÃ¬nh vá»›i Decision Tree features

**CÃ¡ch Ä‘á»c**:
- **Layout 2x3**: TÆ°Æ¡ng tá»± nhÆ° cÃ¡c evaluation khÃ¡c
- **CÃ¡c subplot**: ROC, Precision-Recall, Confusion Matrix, Feature Importance, Prediction Distribution, Metrics
- **So sÃ¡nh**: CÃ³ thá»ƒ so sÃ¡nh vá»›i raw vÃ  FE evaluation
- **DT Features**: Táº­p trung vÃ o tÃ¡c Ä‘á»™ng cá»§a Decision Tree features

**Ã nghÄ©a**:
- TÃ¡c Ä‘á»™ng cá»§a Decision Tree features Ä‘Æ°á»£c thÃªm vÃ o
- Cáº£i thiá»‡n performance so vá»›i raw vÃ  FE
- Hiá»‡u quáº£ cá»§a viá»‡c sá»­ dá»¥ng Decision Tree Ä‘á»ƒ táº¡o features
- Validation cho DT approach cÃ³ hiá»‡u quáº£

### 4.7 `11_fe_dt_comprehensive_evaluation.png`
**Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ toÃ n diá»‡n mÃ´ hÃ¬nh káº¿t há»£p FE + DT

**CÃ¡ch Ä‘á»c**:
- **Layout 2x3**: TÆ°Æ¡ng tá»± nhÆ° cÃ¡c evaluation khÃ¡c
- **CÃ¡c subplot**: ROC, Precision-Recall, Confusion Matrix, Feature Importance, Prediction Distribution, Metrics
- **Tá»•ng há»£p**: Káº¿t há»£p cáº£ Feature Engineering vÃ  Decision Tree features
- **Best Performance**: ThÆ°á»ng cÃ³ performance tá»‘t nháº¥t

**Ã nghÄ©a**:
- Hiá»‡u quáº£ cá»§a viá»‡c káº¿t há»£p FE + DT techniques
- Best performance cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c vá»›i táº¥t cáº£ techniques
- TÃ¡c Ä‘á»™ng tá»•ng há»£p vÃ  tÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c techniques
- Validation cho approach tá»•ng há»£p cÃ³ hiá»‡u quáº£ nháº¥t

---

## ğŸ”§ 5. CÃCH Sá»¬ Dá»¤NG BIá»‚U Äá»’

### 5.1 PhÃ¢n TÃ­ch Tá»•ng Quan
1. **Báº¯t Ä‘áº§u vá»›i**: `10_lightgbm_comprehensive_summary.png`
2. **Xem chi tiáº¿t**: `11_*_comprehensive_evaluation.png`
3. **So sÃ¡nh**: `01_lightgbm_performance_comparison.png`

### 5.2 Tá»‘i Æ¯u HÃ³a MÃ´ HÃ¬nh
1. **Theo dÃµi quÃ¡ trÃ¬nh**: `00_lightgbm_optimization.png`
2. **TÃ¬m tham sá»‘ tá»‘i Æ°u**: `03_lightgbm_optimal_estimators.png`
3. **ÄÃ¡nh giÃ¡ stability**: `02_lightgbm_cv_scores.png`

### 5.3 ÄÃ¡nh GiÃ¡ Hiá»‡u Suáº¥t
1. **ROC Analysis**: `02_roc_curve.png`
2. **Precision-Recall**: `03_precision_recall_curve.png`
3. **Confusion Matrix**: `04_confusion_matrix.png`
4. **Radar Chart**: `07_radar_chart.png`

### 5.4 Hiá»ƒu MÃ´ HÃ¬nh
1. **Feature Importance**: `08_feature_importance.png`
2. **SHAP Analysis**: `09_shap_summary.png`
3. **Individual Predictions**: `10_shap_waterfall.png`

---

## âš ï¸ 6. LÆ¯U Ã QUAN TRá»ŒNG

### 6.1 Fallback Plots
- Má»™t sá»‘ biá»ƒu Ä‘á»“ cÃ³ thá»ƒ sá»­ dá»¥ng dá»¯ liá»‡u máº«u khi thiáº¿u dá»¯ liá»‡u thá»±c
- Äiá»u nÃ y Ä‘áº£m báº£o luÃ´n cÃ³ biá»ƒu Ä‘á»“ Ä‘á»ƒ tham kháº£o

### 6.2 TiÃªu Äá» Tiáº¿ng Viá»‡t
- Táº¥t cáº£ biá»ƒu Ä‘á»“ Ä‘á»u cÃ³ tiÃªu Ä‘á» vÃ  nhÃ£n tiáº¿ng Viá»‡t
- GiÃºp dá»… hiá»ƒu vÃ  sá»­ dá»¥ng hÆ¡n

### 6.3 Cháº¥t LÆ°á»£ng Cao
- Táº¥t cáº£ biá»ƒu Ä‘á»“ Ä‘Æ°á»£c lÆ°u vá»›i Ä‘á»™ phÃ¢n giáº£i 300 DPI
- PhÃ¹ há»£p cho bÃ¡o cÃ¡o vÃ  thuyáº¿t trÃ¬nh

### 6.4 Thá»© Tá»± Äá»c Biá»ƒu Äá»“
1. **Comprehensive Summary** â†’ Tá»•ng quan
2. **Performance Comparison** â†’ So sÃ¡nh
3. **Individual Evaluations** â†’ Chi tiáº¿t
4. **Optimization Plots** â†’ Tá»‘i Æ°u hÃ³a
5. **Interpretability Plots** â†’ Giáº£i thÃ­ch

---

## ğŸ“ 7. Vá»Š TRÃ LÆ¯U TRá»®

Táº¥t cáº£ biá»ƒu Ä‘á»“ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c:
```
results/run_20250920_014031/plots/
```

**Cáº¥u trÃºc file**:
- `00_*` â†’ Optimization plots
- `01_*` â†’ Performance comparison (cÃ³ cáº£ PNG vÃ  PDF)
- `02_*` â†’ ROC curves
- `03_*` â†’ Precision-Recall curves
- `04_*` â†’ Confusion matrices
- `05_*` â†’ Distribution analysis
- `06_*` â†’ Metrics comparison
- `07_*` â†’ Radar charts
- `08_*` â†’ Feature importance
- `09_*` â†’ SHAP analysis
- `10_*` â†’ Comprehensive summaries
- `11_*` â†’ Training history & evaluations

**Äá»‹nh dáº¡ng file**:
- **PNG files (25)**: Cho hiá»ƒn thá»‹ web vÃ  xem nhanh
- **PDF files (1)**: Cho in áº¥n vÃ  bÃ¡o cÃ¡o cháº¥t lÆ°á»£ng cao

---

## ğŸš€ 8. Káº¾T LUáº¬N

**25 biá»ƒu Ä‘á»“ PNG + 1 biá»ƒu Ä‘á»“ PDF** (tá»•ng cá»™ng 26 files) nÃ y cung cáº¥p cÃ¡i nhÃ¬n toÃ n diá»‡n vá»:

### ğŸ“Š **Dá»¯ Liá»‡u**
- Cháº¥t lÆ°á»£ng vÃ  Ä‘áº·c Ä‘iá»ƒm
- PhÃ¢n bá»‘ vÃ  xu hÆ°á»›ng
- TÆ°Æ¡ng quan giá»¯a cÃ¡c features

### ğŸ¤– **MÃ´ HÃ¬nh**
- QuÃ¡ trÃ¬nh há»c vÃ  tá»‘i Æ°u hÃ³a
- Hiá»‡u suáº¥t trÃªn cÃ¡c metric khÃ¡c nhau
- So sÃ¡nh giá»¯a cÃ¡c phÆ°Æ¡ng phÃ¡p

### ğŸ” **Äáº·c TrÆ°ng**
- Táº§m quan trá»ng cá»§a tá»«ng feature
- TÃ¡c Ä‘á»™ng Ä‘áº¿n predictions
- Hiá»‡u quáº£ cá»§a feature engineering

### âš¡ **Tá»‘i Æ¯u HÃ³a**
- QuÃ¡ trÃ¬nh tÃ¬m tham sá»‘ tá»‘i Æ°u
- Cáº£i thiá»‡n qua thá»i gian
- So sÃ¡nh cÃ¡c techniques

### ğŸ¯ **ÄÃ¡nh GiÃ¡**
- Hiá»‡u suáº¥t tá»•ng thá»ƒ
- Äiá»ƒm máº¡nh vÃ  Ä‘iá»ƒm yáº¿u
- Kháº£ nÄƒng generalizes

**Sá»­ dá»¥ng káº¿t há»£p táº¥t cáº£ biá»ƒu Ä‘á»“ Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n Ä‘áº§y Ä‘á»§ vÃ  Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tá»‘i Æ°u cho dá»± Ã¡n Machine Learning cá»§a báº¡n!** ğŸ¯

---

## ğŸ“ 9. Há»– TRá»¢

Náº¿u cáº§n há»— trá»£ thÃªm vá» cÃ¡ch Ä‘á»c hoáº·c sá»­ dá»¥ng cÃ¡c biá»ƒu Ä‘á»“, vui lÃ²ng tham kháº£o:
- `PROJECT_SUMMARY.md` - Tá»•ng quan dá»± Ã¡n
- `PLOT_GUIDE.md` - HÆ°á»›ng dáº«n cÆ¡ báº£n
- `README.md` - TÃ i liá»‡u Ä‘áº§y Ä‘á»§
- `QUICK_START.md` - HÆ°á»›ng dáº«n nhanh

**ChÃºc báº¡n thÃ nh cÃ´ng vá»›i dá»± Ã¡n Machine Learning!** ğŸš€
