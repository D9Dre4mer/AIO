# Machine Learning Pipeline - HÆ°á»›ng dáº«n tá»•ng quan

## ğŸ“‹ Tá»•ng quan há»‡ thá»‘ng

ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng machine learning pipeline hoÃ n chá»‰nh vá»›i giao diá»‡n Streamlit, há»— trá»£:

- **ğŸ“Š Data Processing**: Upload, preview, preprocessing
- **ğŸ¤– Model Training**: Multiple algorithms vá»›i optimization
- **ğŸ“ˆ Analysis**: SHAP, confusion matrix, model comparison
- **ğŸ’¾ Caching**: Intelligent caching system
- **ğŸ¨ UI/UX**: Modern, responsive interface

## ğŸš€ Quick Start Guide

### 1. Khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng
```bash
# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng conda
conda activate PJ3.1

# Cháº¡y Streamlit app
streamlit run app.py
```

### 2. Workflow cÆ¡ báº£n
1. **Step 1**: Upload dataset
2. **Step 2**: Chá»n columns vÃ  preprocessing
3. **Step 3**: Cáº¥u hÃ¬nh models vÃ  optimization
4. **Step 4**: Training vá»›i data split tÃ¹y chá»‰nh
5. **Step 5**: Analysis vÃ  visualization

## ğŸ“Š Step 1: Dataset Upload

### Supported Formats
- **CSV**: Comma-separated values
- **Excel**: .xlsx, .xls files
- **JSON**: JSON format

### Features
- **Auto-detection**: Tá»± Ä‘á»™ng detect data types
- **Preview**: Xem trÆ°á»›c data
- **Validation**: Kiá»ƒm tra data quality
- **Info display**: Thá»‘ng kÃª cÆ¡ báº£n

### Tips
- Äáº£m báº£o data clean vÃ  cÃ³ header
- Kiá»ƒm tra missing values
- Xem preview trÆ°á»›c khi tiáº¿p tá»¥c

## ğŸ”§ Step 2: Data Configuration

### Tab Options

#### Text Data Tab
- **Abstract Column**: Chá»n cá»™t chá»©a text
- **Categories Column**: Chá»n cá»™t label
- **Vectorization Methods**: TF-IDF, BoW, Word2Vec
- **Preprocessing**: Text cleaning, stopwords removal

#### Multi Input Tab
- **Input Columns**: Chá»n features
- **Label Column**: Chá»n target variable
- **Numeric Scaling**: StandardScaler, MinMaxScaler, RobustScaler
- **Remove Duplicates**: TÃ¹y chá»n xÃ³a duplicates

### Default Settings
- **Label Column**: Cá»™t cuá»‘i cÃ¹ng
- **Input Columns**: Táº¥t cáº£ cá»™t cÃ²n láº¡i
- **Scaling**: StandardScaler
- **Duplicates**: Giá»¯ nguyÃªn (khÃ´ng xÃ³a)

## ğŸ¤– Step 3: Model Configuration

### Optimization Methods

#### Optuna Optimization
- **Models**: Chá»n models Ä‘á»ƒ optimize
- **Trials**: Sá»‘ láº§n thá»­ (máº·c Ä‘á»‹nh: 50)
- **Default**: Táº¥t cáº£ models Ä‘Æ°á»£c chá»n

#### Ensemble Learning
- **Voting**: Hard/Soft voting
- **Stacking**: Meta-learner stacking
- **Default**: Táº¥t cáº£ models Ä‘Æ°á»£c chá»n

### Available Models
- **Tree-based**: Random Forest, XGBoost, LightGBM, CatBoost
- **Linear**: Logistic Regression, SVM, Linear SVC
- **Ensemble**: AdaBoost, Gradient Boosting
- **Traditional**: KNN, Decision Tree, Naive Bayes

## ğŸš€ Step 4: Training Execution

### Data Split Configuration
- **Train Ratio**: 50-90% (máº·c Ä‘á»‹nh: 80%)
- **Validation Ratio**: 5-30% (máº·c Ä‘á»‹nh: 10%)
- **Test Ratio**: 5-30% (máº·c Ä‘á»‹nh: 10%)
- **Auto-validation**: Cáº£nh bÃ¡o náº¿u tá»•ng â‰  100%

### Training Process
1. **Data Splitting**: 3-way split (train/val/test)
2. **Scaling**: Apply selected scalers
3. **Model Training**: Train vá»›i Optuna optimization
4. **Evaluation**: Test trÃªn test set
5. **Caching**: LÆ°u models vÃ  metrics

### Cache System
- **Intelligent Caching**: Tá»± Ä‘á»™ng detect changes
- **Model Storage**: LÆ°u trained models
- **Metrics Storage**: LÆ°u performance metrics
- **SHAP Samples**: LÆ°u samples cho SHAP analysis

## ğŸ“ˆ Step 5: Analysis & Visualization

### SHAP Analysis
- **Purpose**: Giáº£i thÃ­ch model predictions
- **Models**: Tree-based models only
- **Plots**: Summary, Bar, Dependence, Waterfall
- **Sample Size**: 100-10000 samples

### Confusion Matrix
- **Purpose**: ÄÃ¡nh giÃ¡ classification performance
- **Normalization**: None, True, Pred, All
- **Threshold**: Adjustable cho binary classification
- **Report**: Classification report chi tiáº¿t

### Model Comparison
- **Purpose**: So sÃ¡nh táº¥t cáº£ models
- **Metrics**: Accuracy, F1, Precision, Recall
- **Ranking**: Sort theo performance
- **Export**: CSV download

## ğŸ’¾ Cache System

### Cache Structure
```
cache/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model_name/
â”‚   â”‚   â”œâ”€â”€ dataset_id/
â”‚   â”‚   â”‚   â”œâ”€â”€ config_hash/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ model.joblib
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.json
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ shap_sample.pkl
â”œâ”€â”€ training_results/
â””â”€â”€ embeddings/
```

### Cache Benefits
- **Speed**: KhÃ´ng cáº§n retrain models
- **Consistency**: Káº¿t quáº£ reproducible
- **Storage**: Efficient storage format
- **Integration**: Seamless vá»›i Step 5

## ğŸ¨ UI/UX Features

### Responsive Design
- **Mobile-friendly**: Responsive layout
- **Modern UI**: Clean, professional interface
- **Dark/Light**: Theme support
- **Navigation**: Step-by-step workflow

### User Experience
- **Progress Tracking**: Visual progress indicators
- **Error Handling**: Clear error messages
- **Help Text**: Tooltips vÃ  guidance
- **Session Management**: Auto-save progress

## âš™ï¸ Configuration Files

### config.py
```python
# SHAP Configuration
SHAP_ENABLE = True
SHAP_SAMPLE_SIZE = 1000
SHAP_OUTPUT_DIR = "info/Result/"

# Cache Configuration
CACHE_DIR = "cache"
CACHE_ENABLE = True
```

### Cache Manager
- **Automatic**: Tá»± Ä‘á»™ng manage cache
- **Validation**: Kiá»ƒm tra cache integrity
- **Cleanup**: Remove old/broken cache
- **Integration**: Seamless vá»›i training

## ğŸ”§ Troubleshooting

### Common Issues

#### "No cached models found"
- **Cause**: ChÆ°a hoÃ n thÃ nh Step 4
- **Solution**: Complete Step 4 training

#### "Training failed: Unknown error"
- **Cause**: Model training error
- **Solution**: Check data quality, try different models

#### "SHAP analysis failed"
- **Cause**: Model khÃ´ng tÆ°Æ¡ng thÃ­ch
- **Solution**: Use tree-based models (Random Forest, XGBoost)

#### "Memory error"
- **Cause**: Dataset quÃ¡ lá»›n
- **Solution**: Reduce sample size, use smaller models

### Performance Tips
1. **Data Size**: Giá»›i háº¡n dataset size cho testing
2. **Sample Size**: Giáº£m SHAP sample size náº¿u cháº­m
3. **Model Selection**: Chá»n models phÃ¹ há»£p vá»›i data
4. **Cache Usage**: Sá»­ dá»¥ng cache Ä‘á»ƒ trÃ¡nh retrain

## ğŸ“š Advanced Usage

### Custom Models
- ThÃªm models má»›i trong `models/` directory
- Implement `BaseModel` interface
- Register trong `register_models.py`

### Custom Metrics
- ThÃªm metrics má»›i trong `models/base/metrics.py`
- Implement metric calculation
- Integrate vá»›i training pipeline

### Custom Preprocessing
- ThÃªm preprocessing methods
- Implement trong `data_loader.py`
- Add UI controls trong Step 2

## ğŸ¯ Best Practices

### Data Preparation
1. **Clean Data**: Remove missing values, outliers
2. **Feature Engineering**: Create meaningful features
3. **Data Validation**: Check data quality
4. **Sample Size**: Adequate sample size cho training

### Model Selection
1. **Start Simple**: Begin vá»›i simple models
2. **Compare Models**: Test multiple algorithms
3. **Cross-validation**: Use proper validation
4. **Ensemble**: Consider ensemble methods

### Performance Optimization
1. **Cache Usage**: Leverage caching system
2. **Sample Size**: Optimize SHAP sample size
3. **Model Complexity**: Balance accuracy vs speed
4. **Resource Management**: Monitor memory usage

## ğŸ“– Documentation

### File Structure
```
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ cache_manager.py       # Cache management
â”œâ”€â”€ data_loader.py         # Data loading utilities
â”œâ”€â”€ models/               # Model implementations
â”œâ”€â”€ wizard_ui/            # UI components
â”œâ”€â”€ info/                 # Documentation
â””â”€â”€ cache/                # Cache storage
```

### Key Components
- **Session Manager**: Manages user session
- **Model Factory**: Creates model instances
- **Cache Manager**: Handles caching
- **Visualization**: SHAP vÃ  plotting utilities

## ğŸ‰ Conclusion

Há»‡ thá»‘ng nÃ y cung cáº¥p:
- **Complete Pipeline**: End-to-end ML workflow
- **User-friendly**: Intuitive interface
- **Powerful Analysis**: SHAP, confusion matrix, comparison
- **Efficient Caching**: Smart caching system
- **Extensible**: Easy to add new features

Sá»­ dá»¥ng há»‡ thá»‘ng Ä‘á»ƒ build vÃ  analyze machine learning models má»™t cÃ¡ch hiá»‡u quáº£!
