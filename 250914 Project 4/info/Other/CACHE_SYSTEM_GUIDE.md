# Cache System - H∆∞·ªõng d·∫´n chi ti·∫øt

## üìã T·ªïng quan

Cache System l√† m·ªôt th√†nh ph·∫ßn quan tr·ªçng c·ªßa pipeline, gi√∫p:
- **TƒÉng t·ªëc ƒë·ªô**: Tr√°nh retrain models kh√¥ng c·∫ßn thi·∫øt
- **ƒê·∫£m b·∫£o consistency**: K·∫øt qu·∫£ reproducible
- **Ti·∫øt ki·ªám t√†i nguy√™n**: Kh√¥ng waste computational power
- **T√≠ch h·ª£p m∆∞·ª£t m√†**: Seamless v·ªõi Step 5 analysis

## üèóÔ∏è Ki·∫øn tr√∫c Cache System

### Cache Structure
```
cache/
‚îú‚îÄ‚îÄ models/                    # Model cache storage
‚îÇ   ‚îú‚îÄ‚îÄ {model_name}/         # Model identifier
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {dataset_id}/     # Dataset identifier
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {config_hash}/ # Configuration hash
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.joblib      # Trained model
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.json      # Performance metrics
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.json       # Training configuration
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ shap_sample.pkl   # SHAP analysis sample
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json     # Cache metadata
‚îú‚îÄ‚îÄ training_results/         # Training results cache
‚îú‚îÄ‚îÄ embeddings/              # Text embeddings cache
‚îî‚îÄ‚îÄ cache_metadata.json      # Global cache metadata
```

### Cache Identifiers
- **Model Key**: T√™n model (e.g., "random_forest", "xgboost")
- **Dataset ID**: Dataset identifier (e.g., "heart_dataset")
- **Config Hash**: Hash c·ªßa training configuration
- **Dataset Fingerprint**: Hash c·ªßa dataset characteristics

## üîß Cache Manager

### Core Functions

#### 1. Save Model Cache
```python
cache_manager.save_model_cache(
    model_key="random_forest",
    dataset_id="heart_dataset", 
    config_hash="abc123",
    dataset_fingerprint="def456",
    model=trained_model,
    params=model_params,
    metrics=performance_metrics,
    config=training_config,
    eval_predictions=test_data,
    shap_sample=shap_data
)
```

#### 2. Load Model Cache
```python
cache_data = cache_manager.load_model_cache(
    model_key="random_forest",
    dataset_id="heart_dataset",
    config_hash="abc123"
)
```

#### 3. Check Cache Exists
```python
exists, cache_info = cache_manager.check_cache_exists(
    model_key="random_forest",
    dataset_id="heart_dataset", 
    config_hash="abc123"
)
```

#### 4. List Cached Models
```python
cached_models = cache_manager.list_cached_models()
```

### Cache Validation

#### Automatic Validation
- **File Integrity**: Ki·ªÉm tra files t·ªìn t·∫°i
- **Data Consistency**: Validate data format
- **Model Compatibility**: Check model compatibility
- **Metadata Validation**: Verify metadata

#### Manual Validation
```python
# Check specific cache
is_valid = cache_manager.validate_cache(cache_path)

# Validate all caches
validation_results = cache_manager.validate_all_caches()
```

## üìä Cache Integration v·ªõi Training

### Step 4 Training Process

#### 1. Pre-training Check
```python
# Check if model already cached
exists, cache_info = cache_manager.check_cache_exists(
    model_key=model_name,
    dataset_id=dataset_id,
    config_hash=config_hash
)

if exists:
    # Load from cache
    cache_data = cache_manager.load_model_cache(...)
    return cache_data
```

#### 2. Training Execution
```python
# Train model
model.fit(X_train, y_train)

# Evaluate model
metrics = evaluate_model(model, X_test, y_test)

# Prepare cache data
cache_data = {
    'model': model,
    'metrics': metrics,
    'eval_predictions': X_test,
    'shap_sample': X_test[:100]
}
```

#### 3. Post-training Save
```python
# Save to cache
cache_manager.save_model_cache(
    model_key=model_name,
    dataset_id=dataset_id,
    config_hash=config_hash,
    **cache_data
)
```

### Cache Hit/Miss Logic

#### Cache Hit
- **Condition**: Same model + dataset + config
- **Action**: Load from cache
- **Benefit**: Skip training, instant results

#### Cache Miss
- **Condition**: Different model/dataset/config
- **Action**: Train new model
- **Benefit**: Fresh training v·ªõi updated config

## üîç Cache Integration v·ªõi Step 5

### SHAP Analysis

#### Cache Requirements
- **Model**: Trained model object
- **SHAP Sample**: Sample data cho SHAP analysis
- **Feature Names**: Column names

#### Cache Usage
```python
# Load model v·ªõi SHAP sample
cache_data = cache_manager.load_model_cache(...)

model = cache_data['model']
shap_sample = cache_data['shap_sample']

# Create SHAP explainer
explainer = create_shap_explainer(model, shap_sample)
shap_values = explainer.shap_values(shap_sample)
```

### Confusion Matrix

#### Cache Requirements
- **Model**: Trained model object
- **Eval Predictions**: Test data
- **Eval Labels**: True labels (optional)

#### Cache Usage
```python
# Load model v·ªõi evaluation data
cache_data = cache_manager.load_model_cache(...)

model = cache_data['model']
eval_predictions = cache_data['eval_predictions']

# Generate predictions
y_pred = model.predict(eval_predictions)
cm = confusion_matrix(y_true, y_pred)
```

### Model Comparison

#### Cache Requirements
- **Multiple Models**: All trained models
- **Metrics**: Performance metrics
- **Metadata**: Model information

#### Cache Usage
```python
# Load all cached models
cached_models = cache_manager.list_cached_models()

comparison_data = []
for cache_info in cached_models:
    cache_data = cache_manager.load_model_cache(...)
    comparison_data.append({
        'model_name': cache_info['model_key'],
        'metrics': cache_data['metrics'],
        'model_type': type(cache_data['model']).__name__
    })
```

## ‚öôÔ∏è Cache Configuration

### Cache Settings
```python
# config.py
CACHE_DIR = "cache"
CACHE_ENABLE = True
CACHE_MAX_SIZE = "10GB"
CACHE_CLEANUP_INTERVAL = 7  # days
```

### Cache Policies
- **LRU**: Least Recently Used
- **Size-based**: Remove largest caches first
- **Age-based**: Remove oldest caches first
- **Manual**: User-controlled cleanup

## üßπ Cache Management

### Automatic Cleanup
```python
# Cleanup old caches
cache_manager.cleanup_old_caches(days=7)

# Cleanup by size
cache_manager.cleanup_by_size(max_size="5GB")

# Cleanup broken caches
cache_manager.cleanup_broken_caches()
```

### Manual Management
```python
# List all caches
cached_models = cache_manager.list_cached_models()

# Remove specific cache
cache_manager.remove_cache(model_key, dataset_id, config_hash)

# Clear all caches
cache_manager.clear_all_caches()
```

### Cache Statistics
```python
# Get cache statistics
stats = cache_manager.get_cache_stats()
print(f"Total caches: {stats['total_caches']}")
print(f"Total size: {stats['total_size']}")
print(f"Oldest cache: {stats['oldest_cache']}")
print(f"Newest cache: {stats['newest_cache']}")
```

## üîß Troubleshooting

### Common Issues

#### "Cache not found"
- **Cause**: Cache b·ªã x√≥a ho·∫∑c corrupt
- **Solution**: Retrain model trong Step 4

#### "Cache loading failed"
- **Cause**: Model format kh√¥ng t∆∞∆°ng th√≠ch
- **Solution**: Clear cache v√† retrain

#### "SHAP sample missing"
- **Cause**: Cache kh√¥ng c√≥ SHAP sample
- **Solution**: Retrain v·ªõi SHAP sample

#### "Cache size too large"
- **Cause**: Qu√° nhi·ªÅu cached models
- **Solution**: Cleanup old caches

### Debug Commands
```python
# Check cache status
cache_manager.check_cache_status()

# Validate specific cache
cache_manager.validate_cache(cache_path)

# Get cache info
cache_info = cache_manager.get_cache_info(model_key, dataset_id, config_hash)
```

## üìà Performance Optimization

### Cache Efficiency
1. **Smart Caching**: Ch·ªâ cache khi c·∫ßn thi·∫øt
2. **Compression**: Compress large models
3. **Lazy Loading**: Load on demand
4. **Parallel Loading**: Load multiple caches

### Memory Management
1. **Model Serialization**: Efficient serialization
2. **Sample Size**: Optimize SHAP sample size
3. **Cleanup**: Regular cleanup old caches
4. **Monitoring**: Monitor cache usage

## üéØ Best Practices

### Cache Strategy
1. **Cache Key Design**: Meaningful, unique keys
2. **Data Validation**: Validate cached data
3. **Version Control**: Handle model versioning
4. **Error Handling**: Graceful cache failures

### Performance Tips
1. **Cache Hit Rate**: Optimize cache hit rate
2. **Cache Size**: Monitor cache size
3. **Cleanup Schedule**: Regular cleanup
4. **Backup Strategy**: Backup important caches

### Development
1. **Testing**: Test cache functionality
2. **Monitoring**: Monitor cache performance
3. **Documentation**: Document cache structure
4. **Maintenance**: Regular maintenance

## üîÆ Future Enhancements

### Planned Features
- **Distributed Caching**: Multi-machine cache
- **Cloud Storage**: Cloud-based cache storage
- **Cache Analytics**: Detailed cache analytics
- **Auto-optimization**: Automatic cache optimization

### Integration Improvements
- **Real-time Sync**: Real-time cache synchronization
- **Version Control**: Git-like cache versioning
- **API Integration**: REST API cho cache
- **Monitoring Dashboard**: Cache monitoring UI

## üìö API Reference

### CacheManager Class
```python
class CacheManager:
    def __init__(self, cache_dir="cache"):
        """Initialize cache manager"""
    
    def save_model_cache(self, model_key, dataset_id, config_hash, **kwargs):
        """Save model to cache"""
    
    def load_model_cache(self, model_key, dataset_id, config_hash):
        """Load model from cache"""
    
    def check_cache_exists(self, model_key, dataset_id, config_hash):
        """Check if cache exists"""
    
    def list_cached_models(self):
        """List all cached models"""
    
    def remove_cache(self, model_key, dataset_id, config_hash):
        """Remove specific cache"""
    
    def clear_all_caches(self):
        """Clear all caches"""
    
    def get_cache_stats(self):
        """Get cache statistics"""
    
    def cleanup_old_caches(self, days=7):
        """Cleanup old caches"""
```

## üéâ Conclusion

Cache System l√† m·ªôt th√†nh ph·∫ßn quan tr·ªçng gi√∫p:
- **TƒÉng hi·ªáu su·∫•t**: Tr√°nh retrain kh√¥ng c·∫ßn thi·∫øt
- **ƒê·∫£m b·∫£o consistency**: K·∫øt qu·∫£ reproducible
- **T√≠ch h·ª£p m∆∞·ª£t m√†**: Seamless v·ªõi analysis tools
- **Qu·∫£n l√Ω hi·ªáu qu·∫£**: Smart cache management

S·ª≠ d·ª•ng cache system ƒë·ªÉ t·ªëi ∆∞u h√≥a workflow v√† tƒÉng productivity!
