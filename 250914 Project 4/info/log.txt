(PJ3.1) PS C:\Users\User\OneDrive\Cloud\0. Studying\250516 AIO2025\z. Git\AIO\250914 Project 4> streamlit run app.py --server.fileWatcherType none --logger.level=debug
2025-10-01 09:55:11.634 Starting new event loop for server
2025-10-01 09:55:11.635 Starting server...
2025-10-01 09:55:11.636 Serving static content from C:\Users\User\miniconda3\envs\PJ3.1\Lib\site-packages\streamlit\static
2025-10-01 09:55:11.642 Server started on port 8501
2025-10-01 09:55:11.642 Runtime state: RuntimeState.INITIAL -> RuntimeState.NO_SESSIONS_CONNECTED

  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.182:8501

2025-10-01 09:55:11.785 Setting up signal handler
2025-10-01 09:55:12.614 AppSession initialized (id=22a85a02-40b7-4cef-a39e-93f4fcfc16c8)
2025-10-01 09:55:12.614 Created new session for client 1898955593872. Session ID: 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:12.614 Runtime state: RuntimeState.NO_SESSIONS_CONNECTED -> RuntimeState.ONE_OR_MORE_SESSIONS_CONNECTED
2025-10-01 09:55:12.700 Received the following back message:
rerun_script {
  widget_states {
  }
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:12.700 Beginning script thread
2025-10-01 09:55:12.701 Running script RerunData(widget_states=, context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:12.701 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:12.701 Sessions still active: dict_keys([])
2025-10-01 09:55:12.701 Files: 0; Sessions with files: 0
SUCCESS: Temp file cleanup registered in training_pipeline
SUCCESS: Temp file cleanup registered in cache_manager
All models registered successfully!
Available models: ['kmeans', 'knn', 'decision_tree', 'naive_bayes', 'svm', 'logistic_regression', 'linear_svc', 'random_forest', 'adaboost', 'gradient_boosting', 'xgboost', 'lightgbm', 'catboost', 'voting_ensemble_hard', 'voting_ensemble_soft', 'stacking_ensemble_logistic_regression', 'stacking_ensemble_random_forest', 'stacking_ensemble_xgboost']

Model Categories:
  clustering: kmeans
  classification: knn, decision_tree, naive_bayes, svm, logistic_regression, linear_svc, random_forest, adaboost, gradient_boosting, xgboost, lightgbm, catboost
  ensemble: voting_ensemble_hard, voting_ensemble_soft, stacking_ensemble_logistic_regression, stacking_ensemble_random_forest, stacking_ensemble_xgboost
All models registered successfully!
Available models: ['kmeans', 'knn', 'decision_tree', 'naive_bayes', 'svm', 'logistic_regression', 'linear_svc', 'random_forest', 'adaboost', 'gradient_boosting', 'xgboost', 'lightgbm', 'catboost', 'voting_ensemble_hard', 'voting_ensemble_soft', 'stacking_ensemble_logistic_regression', 'stacking_ensemble_random_forest', 'stacking_ensemble_xgboost']

Model Categories:
  clustering: kmeans
  classification: knn, decision_tree, naive_bayes, svm, logistic_regression, linear_svc, random_forest, adaboost, gradient_boosting, xgboost, lightgbm, catboost
  ensemble: voting_ensemble_hard, voting_ensemble_soft, stacking_ensemble_logistic_regression, stacking_ensemble_random_forest, stacking_ensemble_xgboost
2025-10-01 09:55:18.365 Creating new ResourceCache (key=33b391f503e826b4611af003bb487669)
2025-10-01 09:55:18.366 Cache key: d41d8cd98f00b204e9800998ecf8427e
INFO:wizard_ui.session_manager:Loading session from backup saved at: 2025-09-30T23:18:54.554102
INFO:wizard_ui.session_manager:Session state restored successfully
INFO:wizard_ui.session_manager:Session state loaded from file: C:\Users\User\OneDrive\Cloud\0. Studying\250516 AIO2025\z. Git\AIO\250914 Project 4\wizard_ui\session_backup.json
INFO:wizard_ui.session_manager:Session state auto-restored from backup
INFO:wizard_ui.session_manager:Session Manager initialized
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
💾 Saved default sampling config from sample: {'num_samples': 100000, 'sampling_strategy': 'Stratified (Recommended)'}
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
💾 [STEP1] Saved sampling config to session: {'num_samples': 100000, 'sampling_strategy': 'Stratified (Recommended)'}
📊 [STEP1] Dataset size: 300,000, Requested samples: 100,000
2025-10-01 09:55:20.430 Removing orphaned files...
2025-10-01 09:55:38.805 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-9ebffe1e51b0bcf570d59ea8fd826d1a-None"
      string_value: "Use Sample Dataset (Cache Folder)"
    }
    widgets {
      id: "$$ID-9ee83401b0c7d4595da2e8ac6e0e0d46-None"
      string_value: "heart.csv"
    }
    widgets {
      id: "$$ID-e8f0b348eb01525f2f22d93a4e95911c-None"
      double_array_value {
        data: 100000
      }
    }
    widgets {
      id: "$$ID-ad59a5b4f412c26a40baa50e51b55411-None"
      int_value: 1
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:38.808 Beginning script thread
2025-10-01 09:55:38.808 Running script RerunData(widget_states=widgets {
  id: "$$ID-9ebffe1e51b0bcf570d59ea8fd826d1a-None"
  string_value: "Use Sample Dataset (Cache Folder)"
}
widgets {
  id: "$$ID-9ee83401b0c7d4595da2e8ac6e0e0d46-None"
  string_value: "heart.csv"
}
widgets {
  id: "$$ID-e8f0b348eb01525f2f22d93a4e95911c-None"
  double_array_value {
    data: 100000
  }
}
widgets {
  id: "$$ID-ad59a5b4f412c26a40baa50e51b55411-None"
  int_value: 1
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:38.809 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:38.809 Sessions still active: dict_keys([])
2025-10-01 09:55:38.809 Files: 0; Sessions with files: 0
2025-10-01 09:55:38.811 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
💾 Saved default sampling config from sample: {'num_samples': 1025, 'sampling_strategy': 'Stratified (Recommended)'}
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
💾 [STEP1] Saved sampling config to session: {'num_samples': 1025, 'sampling_strategy': 'Stratified (Recommended)'}
📊 [STEP1] Dataset size: 1,025, Requested samples: 1,025
2025-10-01 09:55:38.976 Removing orphaned files...
2025-10-01 09:55:40.662 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-9ebffe1e51b0bcf570d59ea8fd826d1a-None"
      string_value: "Use Sample Dataset (Cache Folder)"
    }
    widgets {
      id: "$$ID-9ee83401b0c7d4595da2e8ac6e0e0d46-None"
      string_value: "heart.csv"
    }
    widgets {
      id: "$$ID-ad59a5b4f412c26a40baa50e51b55411-None"
      int_value: 1
    }
    widgets {
      id: "$$ID-5ea744d2af25a3a5075eb1f827cf2ffa-None"
      double_array_value {
        data: 1025
      }
    }
    widgets {
      id: "$$ID-891d9fe078fd3b2097115dd2d8c5580e-next_btn_1"
      trigger_value: true
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:40.663 Beginning script thread
2025-10-01 09:55:40.664 Running script RerunData(widget_states=widgets {
  id: "$$ID-9ebffe1e51b0bcf570d59ea8fd826d1a-None"
  string_value: "Use Sample Dataset (Cache Folder)"
}
widgets {
  id: "$$ID-9ee83401b0c7d4595da2e8ac6e0e0d46-None"
  string_value: "heart.csv"
}
widgets {
  id: "$$ID-ad59a5b4f412c26a40baa50e51b55411-None"
  int_value: 1
}
widgets {
  id: "$$ID-5ea744d2af25a3a5075eb1f827cf2ffa-None"
  double_array_value {
    data: 1025
  }
}
widgets {
  id: "$$ID-891d9fe078fd3b2097115dd2d8c5580e-next_btn_1"
  trigger_value: true
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:40.664 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:40.664 Sessions still active: dict_keys([])
2025-10-01 09:55:40.664 Files: 0; Sessions with files: 0
2025-10-01 09:55:40.665 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
💾 Saved default sampling config from sample: {'num_samples': 1025, 'sampling_strategy': 'Stratified (Recommended)'}
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
SUCCESS: Step 1 data saved to session state
DEBUG: Auto-save disabled to prevent crashes
💾 [STEP1] Saved sampling config to session: {'num_samples': 1025, 'sampling_strategy': 'Stratified (Recommended)'}
📊 [STEP1] Dataset size: 1,025, Requested samples: 1,025

🔄 [NAVIGATION] Moving from Step 1 to Step 2...
📊 [NAVIGATION] Step 1 data keys: ['dataframe', 'file_path', 'sampling_config', 'dataset_size']
💾 [NAVIGATION] Sampling config found: {'num_samples': 1025, 'sampling_strategy': 'Stratified (Recommended)'}
📊 [NAVIGATION] Dataset size: 1,025, Requested samples: 1025
2025-10-01 09:55:40.690 Removing orphaned files...
2025-10-01 09:55:40.808 Running script RerunData(page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:40.808 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:40.809 Sessions still active: dict_keys([])
2025-10-01 09:55:40.809 Files: 0; Sessions with files: 0
2025-10-01 09:55:40.810 Cache key: d41d8cd98f00b204e9800998ecf8427e
WARNING: Label column has only 2 classes (binary classification)
2025-10-01 09:55:40.844 Removing orphaned files...
2025-10-01 09:55:47.313 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-c4830022cb40e4a63331d72f3196190a-None"
      string_value: "age"
    }
    widgets {
      id: "$$ID-9e8c706f48af9c9ea1cc8d22e38f695c-None"
      string_value: "sex"
    }
    widgets {
      id: "$$ID-4fe318aa9a47ac8d004fc218c4e588fe-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-59334011565792afb3da2286c983bf6a-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-ca9c21a5d143f084815c4ed662b92149-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-7ec44be39cd6fbaabb18564f4901bbce-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-dfea30af62d7f0a160467f694d883282-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-1b6a7a129ba30661b9e0e5ea23e32650-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-266ce47a97b9875897ab61d2722eff40-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-9989725332afeb2f8d63cebf622197d2-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-a69787b253181e91d28d3928c18a3283-multi_input_label_col"
      string_value: "target"
    }
    widgets {
      id: "$$ID-e6afcb40529c98f6a4c2cc649eec3c5e-multi_input_text_encoding"
      string_value: "None"
    }
    widgets {
      id: "$$ID-0d722c7ab474fcff7d9c4e638c1eff6d-multi_input_remove_duplicates"
      bool_value: false
    }
    widgets {
      id: "$$ID-4afc705390e6f167ae6194b3fee551a6-multi_input_outlier_detection"
      bool_value: false
    }
    widgets {
      id: "$$ID-87c2cdf4bf3cea63097cea81697ca967-multi_input_missing_strategy"
      string_value: "Fill with mean/median"
    }
    widgets {
      id: "$$ID-2d33f069dc41d37996098e6db5b0aa48-multi_input_input_cols"
      string_array_value {
        data: "age"
        data: "sex"
        data: "cp"
        data: "trestbps"
        data: "chol"
        data: "fbs"
        data: "restecg"
        data: "thalach"
        data: "exang"
        data: "oldpeak"
        data: "slope"
        data: "ca"
        data: "thal"
      }
    }
    widgets {
      id: "$$ID-1bd81b78063333b77cd229ca735366d5-multi_input_numeric_scaler"
      string_array_value {
        data: "StandardScaler"
        data: "MinMaxScaler"
      }
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:47.314 Beginning script thread
2025-10-01 09:55:47.315 Running script RerunData(widget_states=widgets {
  id: "$$ID-c4830022cb40e4a63331d72f3196190a-None"
  string_value: "age"
}
widgets {
  id: "$$ID-9e8c706f48af9c9ea1cc8d22e38f695c-None"
  string_value: "sex"
}
widgets {
  id: "$$ID-4fe318aa9a47ac8d004fc218c4e588fe-None"
  bool_value: true
}
widgets {
  id: "$$ID-59334011565792afb3da2286c983bf6a-None"
  bool_value: true
}
widgets {
  id: "$$ID-ca9c21a5d143f084815c4ed662b92149-None"
  bool_value: true
}
widgets {
  id: "$$ID-7ec44be39cd6fbaabb18564f4901bbce-None"
  bool_value: true
}
widgets {
  id: "$$ID-dfea30af62d7f0a160467f694d883282-None"
  bool_value: false
}
widgets {
  id: "$$ID-1b6a7a129ba30661b9e0e5ea23e32650-None"
  bool_value: false
}
widgets {
  id: "$$ID-266ce47a97b9875897ab61d2722eff40-None"
  bool_value: false
}
widgets {
  id: "$$ID-9989725332afeb2f8d63cebf622197d2-None"
  bool_value: false
}
widgets {
  id: "$$ID-a69787b253181e91d28d3928c18a3283-multi_input_label_col"
  string_value: "target"
}
widgets {
  id: "$$ID-e6afcb40529c98f6a4c2cc649eec3c5e-multi_input_text_encoding"
  string_value: "None"
}
widgets {
  id: "$$ID-0d722c7ab474fcff7d9c4e638c1eff6d-multi_input_remove_duplicates"
  bool_value: false
}
widgets {
  id: "$$ID-4afc705390e6f167ae6194b3fee551a6-multi_input_outlier_detection"
  bool_value: false
}
widgets {
  id: "$$ID-87c2cdf4bf3cea63097cea81697ca967-multi_input_missing_strategy"
  string_value: "Fill with mean/median"
}
widgets {
  id: "$$ID-2d33f069dc41d37996098e6db5b0aa48-multi_input_input_cols"
  string_array_value {
    data: "age"
    data: "sex"
    data: "cp"
    data: "trestbps"
    data: "chol"
    data: "fbs"
    data: "restecg"
    data: "thalach"
    data: "exang"
    data: "oldpeak"
    data: "slope"
    data: "ca"
    data: "thal"
  }
}
widgets {
  id: "$$ID-1bd81b78063333b77cd229ca735366d5-multi_input_numeric_scaler"
  string_array_value {
    data: "StandardScaler"
    data: "MinMaxScaler"
  }
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:47.315 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:47.315 Sessions still active: dict_keys([])
2025-10-01 09:55:47.315 Files: 0; Sessions with files: 0
2025-10-01 09:55:47.316 Cache key: d41d8cd98f00b204e9800998ecf8427e
WARNING: Label column has only 2 classes (binary classification)
2025-10-01 09:55:47.350 Removing orphaned files...
2025-10-01 09:55:47.777 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-c4830022cb40e4a63331d72f3196190a-None"
      string_value: "age"
    }
    widgets {
      id: "$$ID-9e8c706f48af9c9ea1cc8d22e38f695c-None"
      string_value: "sex"
    }
    widgets {
      id: "$$ID-4fe318aa9a47ac8d004fc218c4e588fe-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-59334011565792afb3da2286c983bf6a-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-ca9c21a5d143f084815c4ed662b92149-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-7ec44be39cd6fbaabb18564f4901bbce-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-dfea30af62d7f0a160467f694d883282-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-1b6a7a129ba30661b9e0e5ea23e32650-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-266ce47a97b9875897ab61d2722eff40-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-9989725332afeb2f8d63cebf622197d2-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-a69787b253181e91d28d3928c18a3283-multi_input_label_col"
      string_value: "target"
    }
    widgets {
      id: "$$ID-e6afcb40529c98f6a4c2cc649eec3c5e-multi_input_text_encoding"
      string_value: "None"
    }
    widgets {
      id: "$$ID-0d722c7ab474fcff7d9c4e638c1eff6d-multi_input_remove_duplicates"
      bool_value: false
    }
    widgets {
      id: "$$ID-4afc705390e6f167ae6194b3fee551a6-multi_input_outlier_detection"
      bool_value: false
    }
    widgets {
      id: "$$ID-87c2cdf4bf3cea63097cea81697ca967-multi_input_missing_strategy"
      string_value: "Fill with mean/median"
    }
    widgets {
      id: "$$ID-2d33f069dc41d37996098e6db5b0aa48-multi_input_input_cols"
      string_array_value {
        data: "age"
        data: "sex"
        data: "cp"
        data: "trestbps"
        data: "chol"
        data: "fbs"
        data: "restecg"
        data: "thalach"
        data: "exang"
        data: "oldpeak"
        data: "slope"
        data: "ca"
        data: "thal"
      }
    }
    widgets {
      id: "$$ID-1bd81b78063333b77cd229ca735366d5-multi_input_numeric_scaler"
      string_array_value {
        data: "StandardScaler"
        data: "MinMaxScaler"
        data: "RobustScaler"
      }
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:47.779 Beginning script thread
2025-10-01 09:55:47.779 Running script RerunData(widget_states=widgets {
  id: "$$ID-c4830022cb40e4a63331d72f3196190a-None"
  string_value: "age"
}
widgets {
  id: "$$ID-9e8c706f48af9c9ea1cc8d22e38f695c-None"
  string_value: "sex"
}
widgets {
  id: "$$ID-4fe318aa9a47ac8d004fc218c4e588fe-None"
  bool_value: true
}
widgets {
  id: "$$ID-59334011565792afb3da2286c983bf6a-None"
  bool_value: true
}
widgets {
  id: "$$ID-ca9c21a5d143f084815c4ed662b92149-None"
  bool_value: true
}
widgets {
  id: "$$ID-7ec44be39cd6fbaabb18564f4901bbce-None"
  bool_value: true
}
widgets {
  id: "$$ID-dfea30af62d7f0a160467f694d883282-None"
  bool_value: false
}
widgets {
  id: "$$ID-1b6a7a129ba30661b9e0e5ea23e32650-None"
  bool_value: false
}
widgets {
  id: "$$ID-266ce47a97b9875897ab61d2722eff40-None"
  bool_value: false
}
widgets {
  id: "$$ID-9989725332afeb2f8d63cebf622197d2-None"
  bool_value: false
}
widgets {
  id: "$$ID-a69787b253181e91d28d3928c18a3283-multi_input_label_col"
  string_value: "target"
}
widgets {
  id: "$$ID-e6afcb40529c98f6a4c2cc649eec3c5e-multi_input_text_encoding"
  string_value: "None"
}
widgets {
  id: "$$ID-0d722c7ab474fcff7d9c4e638c1eff6d-multi_input_remove_duplicates"
  bool_value: false
}
widgets {
  id: "$$ID-4afc705390e6f167ae6194b3fee551a6-multi_input_outlier_detection"
  bool_value: false
}
widgets {
  id: "$$ID-87c2cdf4bf3cea63097cea81697ca967-multi_input_missing_strategy"
  string_value: "Fill with mean/median"
}
widgets {
  id: "$$ID-2d33f069dc41d37996098e6db5b0aa48-multi_input_input_cols"
  string_array_value {
    data: "age"
    data: "sex"
    data: "cp"
    data: "trestbps"
    data: "chol"
    data: "fbs"
    data: "restecg"
    data: "thalach"
    data: "exang"
    data: "oldpeak"
    data: "slope"
    data: "ca"
    data: "thal"
  }
}
widgets {
  id: "$$ID-1bd81b78063333b77cd229ca735366d5-multi_input_numeric_scaler"
  string_array_value {
    data: "StandardScaler"
    data: "MinMaxScaler"
    data: "RobustScaler"
  }
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:47.780 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:47.780 Sessions still active: dict_keys([])
2025-10-01 09:55:47.780 Files: 0; Sessions with files: 0
2025-10-01 09:55:47.781 Cache key: d41d8cd98f00b204e9800998ecf8427e
WARNING: Label column has only 2 classes (binary classification)
2025-10-01 09:55:47.817 Removing orphaned files...
2025-10-01 09:55:50.111 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-c4830022cb40e4a63331d72f3196190a-None"
      string_value: "age"
    }
    widgets {
      id: "$$ID-9e8c706f48af9c9ea1cc8d22e38f695c-None"
      string_value: "sex"
    }
    widgets {
      id: "$$ID-4fe318aa9a47ac8d004fc218c4e588fe-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-59334011565792afb3da2286c983bf6a-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-ca9c21a5d143f084815c4ed662b92149-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-7ec44be39cd6fbaabb18564f4901bbce-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-dfea30af62d7f0a160467f694d883282-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-1b6a7a129ba30661b9e0e5ea23e32650-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-266ce47a97b9875897ab61d2722eff40-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-9989725332afeb2f8d63cebf622197d2-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-a69787b253181e91d28d3928c18a3283-multi_input_label_col"
      string_value: "target"
    }
    widgets {
      id: "$$ID-e6afcb40529c98f6a4c2cc649eec3c5e-multi_input_text_encoding"
      string_value: "None"
    }
    widgets {
      id: "$$ID-0d722c7ab474fcff7d9c4e638c1eff6d-multi_input_remove_duplicates"
      bool_value: false
    }
    widgets {
      id: "$$ID-4afc705390e6f167ae6194b3fee551a6-multi_input_outlier_detection"
      bool_value: false
    }
    widgets {
      id: "$$ID-87c2cdf4bf3cea63097cea81697ca967-multi_input_missing_strategy"
      string_value: "Fill with mean/median"
    }
    widgets {
      id: "$$ID-2d33f069dc41d37996098e6db5b0aa48-multi_input_input_cols"
      string_array_value {
        data: "age"
        data: "sex"
        data: "cp"
        data: "trestbps"
        data: "chol"
        data: "fbs"
        data: "restecg"
        data: "thalach"
        data: "exang"
        data: "oldpeak"
        data: "slope"
        data: "ca"
        data: "thal"
      }
    }
    widgets {
      id: "$$ID-1bd81b78063333b77cd229ca735366d5-multi_input_numeric_scaler"
      string_array_value {
        data: "StandardScaler"
        data: "MinMaxScaler"
        data: "RobustScaler"
      }
    }
    widgets {
      id: "$$ID-e4ffc2e4fa578af949a4a44711a1ee2f-multi_input_process_button"
      trigger_value: true
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:50.112 Beginning script thread
2025-10-01 09:55:50.112 Running script RerunData(widget_states=widgets {
  id: "$$ID-c4830022cb40e4a63331d72f3196190a-None"
  string_value: "age"
}
widgets {
  id: "$$ID-9e8c706f48af9c9ea1cc8d22e38f695c-None"
  string_value: "sex"
}
widgets {
  id: "$$ID-4fe318aa9a47ac8d004fc218c4e588fe-None"
  bool_value: true
}
widgets {
  id: "$$ID-59334011565792afb3da2286c983bf6a-None"
  bool_value: true
}
widgets {
  id: "$$ID-ca9c21a5d143f084815c4ed662b92149-None"
  bool_value: true
}
widgets {
  id: "$$ID-7ec44be39cd6fbaabb18564f4901bbce-None"
  bool_value: true
}
widgets {
  id: "$$ID-dfea30af62d7f0a160467f694d883282-None"
  bool_value: false
}
widgets {
  id: "$$ID-1b6a7a129ba30661b9e0e5ea23e32650-None"
  bool_value: false
}
widgets {
  id: "$$ID-266ce47a97b9875897ab61d2722eff40-None"
  bool_value: false
}
widgets {
  id: "$$ID-9989725332afeb2f8d63cebf622197d2-None"
  bool_value: false
}
widgets {
  id: "$$ID-a69787b253181e91d28d3928c18a3283-multi_input_label_col"
  string_value: "target"
}
widgets {
  id: "$$ID-e6afcb40529c98f6a4c2cc649eec3c5e-multi_input_text_encoding"
  string_value: "None"
}
widgets {
  id: "$$ID-0d722c7ab474fcff7d9c4e638c1eff6d-multi_input_remove_duplicates"
  bool_value: false
}
widgets {
  id: "$$ID-4afc705390e6f167ae6194b3fee551a6-multi_input_outlier_detection"
  bool_value: false
}
widgets {
  id: "$$ID-87c2cdf4bf3cea63097cea81697ca967-multi_input_missing_strategy"
  string_value: "Fill with mean/median"
}
widgets {
  id: "$$ID-2d33f069dc41d37996098e6db5b0aa48-multi_input_input_cols"
  string_array_value {
    data: "age"
    data: "sex"
    data: "cp"
    data: "trestbps"
    data: "chol"
    data: "fbs"
    data: "restecg"
    data: "thalach"
    data: "exang"
    data: "oldpeak"
    data: "slope"
    data: "ca"
    data: "thal"
  }
}
widgets {
  id: "$$ID-1bd81b78063333b77cd229ca735366d5-multi_input_numeric_scaler"
  string_array_value {
    data: "StandardScaler"
    data: "MinMaxScaler"
    data: "RobustScaler"
  }
}
widgets {
  id: "$$ID-e4ffc2e4fa578af949a4a44711a1ee2f-multi_input_process_button"
  trigger_value: true
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:50.112 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:50.112 Sessions still active: dict_keys([])
2025-10-01 09:55:50.112 Files: 0; Sessions with files: 0
2025-10-01 09:55:50.113 Cache key: d41d8cd98f00b204e9800998ecf8427e
WARNING: Label column has only 2 classes (binary classification)
SUCCESS: Step 2 data saved to session state
2025-10-01 09:55:50.152 Removing orphaned files...
2025-10-01 09:55:52.006 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-c4830022cb40e4a63331d72f3196190a-None"
      string_value: "age"
    }
    widgets {
      id: "$$ID-9e8c706f48af9c9ea1cc8d22e38f695c-None"
      string_value: "sex"
    }
    widgets {
      id: "$$ID-4fe318aa9a47ac8d004fc218c4e588fe-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-59334011565792afb3da2286c983bf6a-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-ca9c21a5d143f084815c4ed662b92149-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-7ec44be39cd6fbaabb18564f4901bbce-None"
      bool_value: true
    }
    widgets {
      id: "$$ID-dfea30af62d7f0a160467f694d883282-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-1b6a7a129ba30661b9e0e5ea23e32650-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-266ce47a97b9875897ab61d2722eff40-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-9989725332afeb2f8d63cebf622197d2-None"
      bool_value: false
    }
    widgets {
      id: "$$ID-a69787b253181e91d28d3928c18a3283-multi_input_label_col"
      string_value: "target"
    }
    widgets {
      id: "$$ID-e6afcb40529c98f6a4c2cc649eec3c5e-multi_input_text_encoding"
      string_value: "None"
    }
    widgets {
      id: "$$ID-0d722c7ab474fcff7d9c4e638c1eff6d-multi_input_remove_duplicates"
      bool_value: false
    }
    widgets {
      id: "$$ID-4afc705390e6f167ae6194b3fee551a6-multi_input_outlier_detection"
      bool_value: false
    }
    widgets {
      id: "$$ID-87c2cdf4bf3cea63097cea81697ca967-multi_input_missing_strategy"
      string_value: "Fill with mean/median"
    }
    widgets {
      id: "$$ID-2d33f069dc41d37996098e6db5b0aa48-multi_input_input_cols"
      string_array_value {
        data: "age"
        data: "sex"
        data: "cp"
        data: "trestbps"
        data: "chol"
        data: "fbs"
        data: "restecg"
        data: "thalach"
        data: "exang"
        data: "oldpeak"
        data: "slope"
        data: "ca"
        data: "thal"
      }
    }
    widgets {
      id: "$$ID-1bd81b78063333b77cd229ca735366d5-multi_input_numeric_scaler"
      string_array_value {
        data: "StandardScaler"
        data: "MinMaxScaler"
        data: "RobustScaler"
      }
    }
    widgets {
      id: "$$ID-d164b8d0bcfc31bd2d5d975581e5fa64-next_btn_2"
      trigger_value: true
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:52.007 Beginning script thread
2025-10-01 09:55:52.007 Running script RerunData(widget_states=widgets {
  id: "$$ID-c4830022cb40e4a63331d72f3196190a-None"
  string_value: "age"
}
widgets {
  id: "$$ID-9e8c706f48af9c9ea1cc8d22e38f695c-None"
  string_value: "sex"
}
widgets {
  id: "$$ID-4fe318aa9a47ac8d004fc218c4e588fe-None"
  bool_value: true
}
widgets {
  id: "$$ID-59334011565792afb3da2286c983bf6a-None"
  bool_value: true
}
widgets {
  id: "$$ID-ca9c21a5d143f084815c4ed662b92149-None"
  bool_value: true
}
widgets {
  id: "$$ID-7ec44be39cd6fbaabb18564f4901bbce-None"
  bool_value: true
}
widgets {
  id: "$$ID-dfea30af62d7f0a160467f694d883282-None"
  bool_value: false
}
widgets {
  id: "$$ID-1b6a7a129ba30661b9e0e5ea23e32650-None"
  bool_value: false
}
widgets {
  id: "$$ID-266ce47a97b9875897ab61d2722eff40-None"
  bool_value: false
}
widgets {
  id: "$$ID-9989725332afeb2f8d63cebf622197d2-None"
  bool_value: false
}
widgets {
  id: "$$ID-a69787b253181e91d28d3928c18a3283-multi_input_label_col"
  string_value: "target"
}
widgets {
  id: "$$ID-e6afcb40529c98f6a4c2cc649eec3c5e-multi_input_text_encoding"
  string_value: "None"
}
widgets {
  id: "$$ID-0d722c7ab474fcff7d9c4e638c1eff6d-multi_input_remove_duplicates"
  bool_value: false
}
widgets {
  id: "$$ID-4afc705390e6f167ae6194b3fee551a6-multi_input_outlier_detection"
  bool_value: false
}
widgets {
  id: "$$ID-87c2cdf4bf3cea63097cea81697ca967-multi_input_missing_strategy"
  string_value: "Fill with mean/median"
}
widgets {
  id: "$$ID-2d33f069dc41d37996098e6db5b0aa48-multi_input_input_cols"
  string_array_value {
    data: "age"
    data: "sex"
    data: "cp"
    data: "trestbps"
    data: "chol"
    data: "fbs"
    data: "restecg"
    data: "thalach"
    data: "exang"
    data: "oldpeak"
    data: "slope"
    data: "ca"
    data: "thal"
  }
}
widgets {
  id: "$$ID-1bd81b78063333b77cd229ca735366d5-multi_input_numeric_scaler"
  string_array_value {
    data: "StandardScaler"
    data: "MinMaxScaler"
    data: "RobustScaler"
  }
}
widgets {
  id: "$$ID-d164b8d0bcfc31bd2d5d975581e5fa64-next_btn_2"
  trigger_value: true
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:52.008 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:52.008 Sessions still active: dict_keys([])
2025-10-01 09:55:52.008 Files: 0; Sessions with files: 0
2025-10-01 09:55:52.009 Cache key: d41d8cd98f00b204e9800998ecf8427e
WARNING: Label column has only 2 classes (binary classification)
2025-10-01 09:55:52.041 Removing orphaned files...
2025-10-01 09:55:52.162 Running script RerunData(page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:52.162 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:52.162 Sessions still active: dict_keys([])
2025-10-01 09:55:52.163 Files: 0; Sessions with files: 0
2025-10-01 09:55:52.164 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
2025-10-01 09:55:52.175 Removing orphaned files...
2025-10-01 09:55:53.759 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
      bool_value: true
    }
    widgets {
      id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
      bool_value: false
    }
    widgets {
      id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
      bool_value: false
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:53.760 Beginning script thread
2025-10-01 09:55:53.761 Running script RerunData(widget_states=widgets {
  id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
  bool_value: true
}
widgets {
  id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
  bool_value: false
}
widgets {
  id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
  bool_value: false
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:53.761 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:53.761 Sessions still active: dict_keys([])
2025-10-01 09:55:53.761 Files: 0; Sessions with files: 0
2025-10-01 09:55:53.762 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
2025-10-01 09:55:53.781 Removing orphaned files...
2025-10-01 09:55:55.471 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
      bool_value: true
    }
    widgets {
      id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
      bool_value: true
    }
    widgets {
      id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
      bool_value: false
    }
    widgets {
      id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
      string_value: "maximize"
    }
    widgets {
      id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
      string_value: "accuracy"
    }
    widgets {
      id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "adaboost"
        data: "gradient_boosting"
        data: "decision_tree"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
      }
    }
    widgets {
      id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
      int_value: 50
    }
    widgets {
      id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
      int_value: 30
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:55.472 Beginning script thread
2025-10-01 09:55:55.472 Running script RerunData(widget_states=widgets {
  id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
  bool_value: true
}
widgets {
  id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
  bool_value: true
}
widgets {
  id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
  bool_value: false
}
widgets {
  id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
  string_value: "maximize"
}
widgets {
  id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
  string_value: "accuracy"
}
widgets {
  id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "adaboost"
    data: "gradient_boosting"
    data: "decision_tree"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
  }
}
widgets {
  id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
  int_value: 50
}
widgets {
  id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
  int_value: 30
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:55.473 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:55.473 Sessions still active: dict_keys([])
2025-10-01 09:55:55.473 Files: 0; Sessions with files: 0
2025-10-01 09:55:55.475 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
2025-10-01 09:55:55.490 Removing orphaned files...
2025-10-01 09:55:56.967 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
      bool_value: true
    }
    widgets {
      id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
      bool_value: true
    }
    widgets {
      id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
      bool_value: true
    }
    widgets {
      id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
      string_value: "maximize"
    }
    widgets {
      id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
      string_value: "accuracy"
    }
    widgets {
      id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "adaboost"
        data: "gradient_boosting"
        data: "decision_tree"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
      }
    }
    widgets {
      id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
      int_value: 50
    }
    widgets {
      id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
      int_value: 30
    }
    widgets {
      id: "$$ID-dabc48f8e280de6f67c0a2a66395b7ef-voting_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
        data: "decision_tree"
        data: "adaboost"
        data: "gradient_boosting"
      }
    }
    widgets {
      id: "$$ID-386c282017a0ba255b8300448db03b13-voting_method"
      string_value: "hard"
    }
    widgets {
      id: "$$ID-52c87a07d11f4baf7dd6f4673411ae5c-use_custom_weights"
      bool_value: false
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:55:56.968 Beginning script thread
2025-10-01 09:55:56.968 Running script RerunData(widget_states=widgets {
  id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
  bool_value: true
}
widgets {
  id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
  bool_value: true
}
widgets {
  id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
  bool_value: true
}
widgets {
  id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
  string_value: "maximize"
}
widgets {
  id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
  string_value: "accuracy"
}
widgets {
  id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "adaboost"
    data: "gradient_boosting"
    data: "decision_tree"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
  }
}
widgets {
  id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
  int_value: 50
}
widgets {
  id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
  int_value: 30
}
widgets {
  id: "$$ID-dabc48f8e280de6f67c0a2a66395b7ef-voting_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
    data: "decision_tree"
    data: "adaboost"
    data: "gradient_boosting"
  }
}
widgets {
  id: "$$ID-386c282017a0ba255b8300448db03b13-voting_method"
  string_value: "hard"
}
widgets {
  id: "$$ID-52c87a07d11f4baf7dd6f4673411ae5c-use_custom_weights"
  bool_value: false
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:55:56.968 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:55:56.968 Sessions still active: dict_keys([])
2025-10-01 09:55:56.968 Files: 0; Sessions with files: 0
2025-10-01 09:55:56.969 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
2025-10-01 09:55:56.992 Removing orphaned files...
2025-10-01 09:56:00.461 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
      bool_value: true
    }
    widgets {
      id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
      bool_value: true
    }
    widgets {
      id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
      bool_value: true
    }
    widgets {
      id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
      string_value: "maximize"
    }
    widgets {
      id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
      string_value: "accuracy"
    }
    widgets {
      id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "adaboost"
        data: "gradient_boosting"
        data: "decision_tree"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
      }
    }
    widgets {
      id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
      int_value: 10
    }
    widgets {
      id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
      int_value: 30
    }
    widgets {
      id: "$$ID-dabc48f8e280de6f67c0a2a66395b7ef-voting_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
        data: "decision_tree"
        data: "adaboost"
        data: "gradient_boosting"
      }
    }
    widgets {
      id: "$$ID-386c282017a0ba255b8300448db03b13-voting_method"
      string_value: "hard"
    }
    widgets {
      id: "$$ID-52c87a07d11f4baf7dd6f4673411ae5c-use_custom_weights"
      bool_value: false
    }
    widgets {
      id: "$$ID-8a006bcee3b35e56f81d69c924f48638-stacking_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "adaboost"
        data: "gradient_boosting"
        data: "decision_tree"
      }
    }
    widgets {
      id: "$$ID-2229f549601f10b9b934ec204f36c877-meta_learner"
      string_value: "logistic_regression"
    }
    widgets {
      id: "$$ID-ac9d047abe6110371a2d8d073fceb1cf-cv_folds"
      int_value: 5
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:56:00.462 Beginning script thread
2025-10-01 09:56:00.463 Running script RerunData(widget_states=widgets {
  id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
  bool_value: true
}
widgets {
  id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
  bool_value: true
}
widgets {
  id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
  bool_value: true
}
widgets {
  id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
  string_value: "maximize"
}
widgets {
  id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
  string_value: "accuracy"
}
widgets {
  id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "adaboost"
    data: "gradient_boosting"
    data: "decision_tree"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
  }
}
widgets {
  id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
  int_value: 10
}
widgets {
  id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
  int_value: 30
}
widgets {
  id: "$$ID-dabc48f8e280de6f67c0a2a66395b7ef-voting_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
    data: "decision_tree"
    data: "adaboost"
    data: "gradient_boosting"
  }
}
widgets {
  id: "$$ID-386c282017a0ba255b8300448db03b13-voting_method"
  string_value: "hard"
}
widgets {
  id: "$$ID-52c87a07d11f4baf7dd6f4673411ae5c-use_custom_weights"
  bool_value: false
}
widgets {
  id: "$$ID-8a006bcee3b35e56f81d69c924f48638-stacking_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "adaboost"
    data: "gradient_boosting"
    data: "decision_tree"
  }
}
widgets {
  id: "$$ID-2229f549601f10b9b934ec204f36c877-meta_learner"
  string_value: "logistic_regression"
}
widgets {
  id: "$$ID-ac9d047abe6110371a2d8d073fceb1cf-cv_folds"
  int_value: 5
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:56:00.463 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:56:00.463 Sessions still active: dict_keys([])
2025-10-01 09:56:00.463 Files: 0; Sessions with files: 0
2025-10-01 09:56:00.467 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
2025-10-01 09:56:00.488 Removing orphaned files...
2025-10-01 09:56:00.605 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
      bool_value: true
    }
    widgets {
      id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
      bool_value: true
    }
    widgets {
      id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
      bool_value: true
    }
    widgets {
      id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
      string_value: "maximize"
    }
    widgets {
      id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
      string_value: "accuracy"
    }
    widgets {
      id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "adaboost"
        data: "gradient_boosting"
        data: "decision_tree"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
      }
    }
    widgets {
      id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
      int_value: 10
    }
    widgets {
      id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
      int_value: 30
    }
    widgets {
      id: "$$ID-dabc48f8e280de6f67c0a2a66395b7ef-voting_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
        data: "decision_tree"
        data: "adaboost"
        data: "gradient_boosting"
      }
    }
    widgets {
      id: "$$ID-386c282017a0ba255b8300448db03b13-voting_method"
      string_value: "hard"
    }
    widgets {
      id: "$$ID-52c87a07d11f4baf7dd6f4673411ae5c-use_custom_weights"
      bool_value: false
    }
    widgets {
      id: "$$ID-8a006bcee3b35e56f81d69c924f48638-stacking_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "adaboost"
        data: "gradient_boosting"
        data: "decision_tree"
      }
    }
    widgets {
      id: "$$ID-2229f549601f10b9b934ec204f36c877-meta_learner"
      string_value: "logistic_regression"
    }
    widgets {
      id: "$$ID-ac9d047abe6110371a2d8d073fceb1cf-cv_folds"
      int_value: 5
    }
    widgets {
      id: "$$ID-3813cf60f051b17cdee138bda6085de8-complete_step3"
      trigger_value: true
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:56:00.606 Beginning script thread
2025-10-01 09:56:00.606 Running script RerunData(widget_states=widgets {
  id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
  bool_value: true
}
widgets {
  id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
  bool_value: true
}
widgets {
  id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
  bool_value: true
}
widgets {
  id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
  string_value: "maximize"
}
widgets {
  id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
  string_value: "accuracy"
}
widgets {
  id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "adaboost"
    data: "gradient_boosting"
    data: "decision_tree"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
  }
}
widgets {
  id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
  int_value: 10
}
widgets {
  id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
  int_value: 30
}
widgets {
  id: "$$ID-dabc48f8e280de6f67c0a2a66395b7ef-voting_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
    data: "decision_tree"
    data: "adaboost"
    data: "gradient_boosting"
  }
}
widgets {
  id: "$$ID-386c282017a0ba255b8300448db03b13-voting_method"
  string_value: "hard"
}
widgets {
  id: "$$ID-52c87a07d11f4baf7dd6f4673411ae5c-use_custom_weights"
  bool_value: false
}
widgets {
  id: "$$ID-8a006bcee3b35e56f81d69c924f48638-stacking_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "adaboost"
    data: "gradient_boosting"
    data: "decision_tree"
  }
}
widgets {
  id: "$$ID-2229f549601f10b9b934ec204f36c877-meta_learner"
  string_value: "logistic_regression"
}
widgets {
  id: "$$ID-ac9d047abe6110371a2d8d073fceb1cf-cv_folds"
  int_value: 5
}
widgets {
  id: "$$ID-3813cf60f051b17cdee138bda6085de8-complete_step3"
  trigger_value: true
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:56:00.607 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:56:00.607 Sessions still active: dict_keys([])
2025-10-01 09:56:00.607 Files: 0; Sessions with files: 0
2025-10-01 09:56:00.611 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
2025-10-01 09:56:00.634 Removing orphaned files...
2025-10-01 09:56:00.755 Running script RerunData(page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:56:00.755 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:56:00.755 Sessions still active: dict_keys([])
2025-10-01 09:56:00.755 Files: 0; Sessions with files: 0
2025-10-01 09:56:00.757 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
2025-10-01 09:56:00.777 Removing orphaned files...
2025-10-01 09:56:01.887 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
      bool_value: true
    }
    widgets {
      id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
      bool_value: true
    }
    widgets {
      id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
      bool_value: true
    }
    widgets {
      id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
      string_value: "maximize"
    }
    widgets {
      id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
      string_value: "accuracy"
    }
    widgets {
      id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "adaboost"
        data: "gradient_boosting"
        data: "decision_tree"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
      }
    }
    widgets {
      id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
      int_value: 10
    }
    widgets {
      id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
      int_value: 30
    }
    widgets {
      id: "$$ID-dabc48f8e280de6f67c0a2a66395b7ef-voting_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "logistic_regression"
        data: "svm"
        data: "knn"
        data: "naive_bayes"
        data: "decision_tree"
        data: "adaboost"
        data: "gradient_boosting"
      }
    }
    widgets {
      id: "$$ID-386c282017a0ba255b8300448db03b13-voting_method"
      string_value: "hard"
    }
    widgets {
      id: "$$ID-52c87a07d11f4baf7dd6f4673411ae5c-use_custom_weights"
      bool_value: false
    }
    widgets {
      id: "$$ID-8a006bcee3b35e56f81d69c924f48638-stacking_models"
      string_array_value {
        data: "random_forest"
        data: "xgboost"
        data: "lightgbm"
        data: "catboost"
        data: "adaboost"
        data: "gradient_boosting"
        data: "decision_tree"
      }
    }
    widgets {
      id: "$$ID-2229f549601f10b9b934ec204f36c877-meta_learner"
      string_value: "logistic_regression"
    }
    widgets {
      id: "$$ID-ac9d047abe6110371a2d8d073fceb1cf-cv_folds"
      int_value: 5
    }
    widgets {
      id: "$$ID-4bc050fb3f2996787fa67c5813ef361f-next_btn_3"
      trigger_value: true
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:56:01.887 Beginning script thread
2025-10-01 09:56:01.888 Running script RerunData(widget_states=widgets {
  id: "$$ID-b70bb12305ce7f6867b1ff15e180c10c-enable_optuna"
  bool_value: true
}
widgets {
  id: "$$ID-08223c1eecbed38b9498873cc14344f9-enable_voting"
  bool_value: true
}
widgets {
  id: "$$ID-224d7672dc2d2ae351119766a03224e7-enable_stacking"
  bool_value: true
}
widgets {
  id: "$$ID-7d0cd8231066fdd31769266f4c6b23a9-optuna_direction"
  string_value: "maximize"
}
widgets {
  id: "$$ID-7dbd474d037b8af6147e09d8edbdae87-optuna_metric"
  string_value: "accuracy"
}
widgets {
  id: "$$ID-384f8fc7ff1963c39f60578c382cfd82-optuna_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "adaboost"
    data: "gradient_boosting"
    data: "decision_tree"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
  }
}
widgets {
  id: "$$ID-e7f80df500d352e679623e8a2f29d9b3-optuna_trials"
  int_value: 10
}
widgets {
  id: "$$ID-14d14739dcf5c640e3494c910f81afdd-optuna_timeout"
  int_value: 30
}
widgets {
  id: "$$ID-dabc48f8e280de6f67c0a2a66395b7ef-voting_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "logistic_regression"
    data: "svm"
    data: "knn"
    data: "naive_bayes"
    data: "decision_tree"
    data: "adaboost"
    data: "gradient_boosting"
  }
}
widgets {
  id: "$$ID-386c282017a0ba255b8300448db03b13-voting_method"
  string_value: "hard"
}
widgets {
  id: "$$ID-52c87a07d11f4baf7dd6f4673411ae5c-use_custom_weights"
  bool_value: false
}
widgets {
  id: "$$ID-8a006bcee3b35e56f81d69c924f48638-stacking_models"
  string_array_value {
    data: "random_forest"
    data: "xgboost"
    data: "lightgbm"
    data: "catboost"
    data: "adaboost"
    data: "gradient_boosting"
    data: "decision_tree"
  }
}
widgets {
  id: "$$ID-2229f549601f10b9b934ec204f36c877-meta_learner"
  string_value: "logistic_regression"
}
widgets {
  id: "$$ID-ac9d047abe6110371a2d8d073fceb1cf-cv_folds"
  int_value: 5
}
widgets {
  id: "$$ID-4bc050fb3f2996787fa67c5813ef361f-next_btn_3"
  trigger_value: true
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:56:01.888 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:56:01.888 Sessions still active: dict_keys([])
2025-10-01 09:56:01.888 Files: 0; Sessions with files: 0
2025-10-01 09:56:01.889 Cache key: d41d8cd98f00b204e9800998ecf8427e
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
SUCCESS: Step 3 data saved to session state
2025-10-01 09:56:01.912 Removing orphaned files...
2025-10-01 09:56:02.031 Running script RerunData(page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:56:02.031 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:56:02.031 Sessions still active: dict_keys([])
2025-10-01 09:56:02.031 Files: 0; Sessions with files: 0
2025-10-01 09:56:02.032 Cache key: d41d8cd98f00b204e9800998ecf8427e
2025-10-01 09:56:02.039 Removing orphaned files...
2025-10-01 09:56:03.502 Received the following back message:
rerun_script {
  widget_states {
    widgets {
      id: "$$ID-cbd2c2bd884883c0114fa21f9827b06a-None"
      double_array_value {
        data: 80
      }
    }
    widgets {
      id: "$$ID-666a7656dcd34c21751836e73f4b9827-None"
      double_array_value {
        data: 10
      }
    }
    widgets {
      id: "$$ID-85b5aaa9d106e7c7efa867f0aa27092a-None"
      double_array_value {
        data: 10
      }
    }
    widgets {
      id: "$$ID-dd18d892cb2f89c582bd77d5c60d577c-None"
      trigger_value: true
    }
  }
  page_script_hash: "3f41e546893dc64b71aaacad12cad815"
  context_info {
    timezone: "Asia/Saigon"
    timezone_offset: -420
    locale: "en-GB"
    url: "http://localhost:8501/"
    is_embedded: false
    color_scheme: "dark"
  }
}

2025-10-01 09:56:03.503 Beginning script thread
2025-10-01 09:56:03.503 Running script RerunData(widget_states=widgets {
  id: "$$ID-cbd2c2bd884883c0114fa21f9827b06a-None"
  double_array_value {
    data: 80
  }
}
widgets {
  id: "$$ID-666a7656dcd34c21751836e73f4b9827-None"
  double_array_value {
    data: 10
  }
}
widgets {
  id: "$$ID-85b5aaa9d106e7c7efa867f0aa27092a-None"
  double_array_value {
    data: 10
  }
}
widgets {
  id: "$$ID-dd18d892cb2f89c582bd77d5c60d577c-None"
  trigger_value: true
}
, page_script_hash='3f41e546893dc64b71aaacad12cad815', context_info=timezone: "Asia/Saigon"
timezone_offset: -420
locale: "en-GB"
url: "http://localhost:8501/"
is_embedded: false
color_scheme: "dark"
)
2025-10-01 09:56:03.503 Disconnecting files for session with ID 22a85a02-40b7-4cef-a39e-93f4fcfc16c8
2025-10-01 09:56:03.503 Sessions still active: dict_keys([])
2025-10-01 09:56:03.503 Files: 0; Sessions with files: 0
2025-10-01 09:56:03.505 Cache key: d41d8cd98f00b204e9800998ecf8427e
[I 2025-10-01 09:56:03,531] A new study created in memory with name: random_forest_optimization
INFO:optuna_optimizer:Created Optuna study: random_forest_optimization
INFO:optuna_optimizer:Starting optimization for random_forest...
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:03,838] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:04,821] Trial 1 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 440, 'max_depth': 13, 'max_features': None, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:04,977] Trial 2 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 132, 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:05,233] Trial 3 finished with value: 0.9313725490196079 and parameters: {'n_estimators': 112, 'max_depth': 8, 'max_features': None, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:05,559] Trial 4 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 317, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:06,073] Trial 5 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 414, 'max_depth': 8, 'max_features': 'log2', 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:06,159] Trial 6 finished with value: 0.9509803921568627 and parameters: {'n_estimators': 65, 'max_depth': 19, 'max_features': 'log2', 'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:06,315] Trial 7 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 133, 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:06,490] Trial 8 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 89, 'max_depth': 6, 'max_features': None, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:06,888] Trial 9 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 210, 'max_depth': 8, 'max_features': None, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for random_forest
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 1}
CPU multithreading: Using all 12 available cores
DEBUG: Starting cache save for random_forest
DEBUG: Cache directory created: cache\models\random_forest\numeric_dataset_StandardScaler\63169c8e32b5aeae31343f88aa6a0de72b90899b7dd1bbc8464560ab6cfe3f07
DEBUG: Model artifact saved: cache\models\random_forest\numeric_dataset_StandardScaler\63169c8e32b5aeae31343f88aa6a0de72b90899b7dd1bbc8464560ab6cfe3f07\model.pkl
DEBUG: Params saved: cache\models\random_forest\numeric_dataset_StandardScaler\63169c8e32b5aeae31343f88aa6a0de72b90899b7dd1bbc8464560ab6cfe3f07\params.json
DEBUG: Metrics saved: cache\models\random_forest\numeric_dataset_StandardScaler\63169c8e32b5aeae31343f88aa6a0de72b90899b7dd1bbc8464560ab6cfe3f07\metrics.json
DEBUG: Config saved: cache\models\random_forest\numeric_dataset_StandardScaler\63169c8e32b5aeae31343f88aa6a0de72b90899b7dd1bbc8464560ab6cfe3f07\config.json
INFO:cache_manager:Cache saved for random_forest at cache\models\random_forest\numeric_dataset_StandardScaler\63169c8e32b5aeae31343f88aa6a0de72b90899b7dd1bbc8464560ab6cfe3f07
DEBUG: Garbage collection completed for random_forest
DEBUG: Garbage collection completed for random_forest
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:08,099] A new study created in memory with name: xgboost_optimization
INFO:optuna_optimizer:Created Optuna study: xgboost_optimization
INFO:optuna_optimizer:Starting optimization for xgboost...
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:08,568] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'max_depth': 10, 'eta': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'reg_lambda': 0.0017073967431528124, 'reg_alpha': 2.9154431891537547}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:09,300] Trial 1 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 321, 'max_depth': 8, 'eta': 0.010725209743171996, 'subsample': 0.9879639408647978, 'colsample_bytree': 0.9329770563201687, 'min_child_weight': 3, 'reg_lambda': 0.005337032762603957, 'reg_alpha': 0.00541524411940254}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:09,672] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 187, 'max_depth': 7, 'eta': 0.04345454109729477, 'subsample': 0.7164916560792167, 'colsample_bytree': 0.8447411578889518, 'min_child_weight': 2, 'reg_lambda': 0.01474275315991467, 'reg_alpha': 0.029204338471814112}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:10,312] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 255, 'max_depth': 9, 'eta': 0.019721610970574007, 'subsample': 0.8056937753654446, 'colsample_bytree': 0.836965827544817, 'min_child_weight': 1, 'reg_lambda': 0.26926469100861794, 'reg_alpha': 0.004809461967501573}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:10,471] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 79, 'max_depth': 10, 'eta': 0.26690431824362526, 'subsample': 0.9233589392465844, 'colsample_bytree': 0.7218455076693483, 'min_child_weight': 1, 'reg_lambda': 0.5456725485601477, 'reg_alpha': 0.057624872164786026}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:10,670] Trial 5 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 105, 'max_depth': 6, 'eta': 0.011240768803005551, 'subsample': 0.9637281608315128, 'colsample_bytree': 0.7035119926400067, 'min_child_weight': 7, 'reg_lambda': 0.017654048052495083, 'reg_alpha': 0.12030178871154672}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:10,935] Trial 6 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 296, 'max_depth': 4, 'eta': 0.27051668818999286, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'min_child_weight': 9, 'reg_lambda': 0.24637685958997463, 'reg_alpha': 4.869640941520899}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:11,072] Trial 7 finished with value: 0.8921568627450981 and parameters: {'n_estimators': 89, 'max_depth': 4, 'eta': 0.011662890273931383, 'subsample': 0.7301321323053057, 'colsample_bytree': 0.7554709158757928, 'min_child_weight': 3, 'reg_lambda': 2.0651425578959257, 'reg_alpha': 0.026730883107816707}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:11,346] Trial 8 finished with value: 0.8921568627450981 and parameters: {'n_estimators': 176, 'max_depth': 7, 'eta': 0.016149614799999188, 'subsample': 0.9208787923016158, 'colsample_bytree': 0.6298202574719083, 'min_child_weight': 10, 'reg_lambda': 1.2273800987852967, 'reg_alpha': 0.0062353771356731605}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:11,486] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 52, 'max_depth': 9, 'eta': 0.11069143219393454, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'min_child_weight': 1, 'reg_lambda': 0.02715581955282941, 'reg_alpha': 0.0029072088906598446}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for xgboost
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'max_depth': 10, 'eta': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'reg_lambda': 0.0017073967431528124, 'reg_alpha': 2.9154431891537547}
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for xgboost
DEBUG: Cache directory created: cache\models\xgboost\numeric_dataset_StandardScaler\34f28e807b84cfe3d20fbf875aaab181677084229685009d074b93d56c03efdd
DEBUG: Model artifact saved: cache\models\xgboost\numeric_dataset_StandardScaler\34f28e807b84cfe3d20fbf875aaab181677084229685009d074b93d56c03efdd\model.json
DEBUG: Params saved: cache\models\xgboost\numeric_dataset_StandardScaler\34f28e807b84cfe3d20fbf875aaab181677084229685009d074b93d56c03efdd\params.json
DEBUG: Metrics saved: cache\models\xgboost\numeric_dataset_StandardScaler\34f28e807b84cfe3d20fbf875aaab181677084229685009d074b93d56c03efdd\metrics.json
DEBUG: Config saved: cache\models\xgboost\numeric_dataset_StandardScaler\34f28e807b84cfe3d20fbf875aaab181677084229685009d074b93d56c03efdd\config.json
INFO:cache_manager:Cache saved for xgboost at cache\models\xgboost\numeric_dataset_StandardScaler\34f28e807b84cfe3d20fbf875aaab181677084229685009d074b93d56c03efdd
DEBUG: Garbage collection completed for xgboost
DEBUG: Garbage collection completed for xgboost
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:12,120] A new study created in memory with name: lightgbm_optimization
INFO:optuna_optimizer:Created Optuna study: lightgbm_optimization
INFO:optuna_optimizer:Starting optimization for lightgbm...
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:12,820] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'num_leaves': 96, 'learning_rate': 0.1205712628744377, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6624074561769746, 'min_child_samples': 12, 'lambda_l1': 0.0017073967431528124, 'lambda_l2': 2.9154431891537547}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:13,877] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 321, 'num_leaves': 74, 'learning_rate': 0.010725209743171996, 'feature_fraction': 0.9879639408647978, 'bagging_fraction': 0.9329770563201687, 'min_child_samples': 14, 'lambda_l1': 0.005337032762603957, 'lambda_l2': 0.00541524411940254}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:14,612] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 187, 'num_leaves': 57, 'learning_rate': 0.04345454109729477, 'feature_fraction': 0.7164916560792167, 'bagging_fraction': 0.8447411578889518, 'min_child_samples': 11, 'lambda_l1': 0.01474275315991467, 'lambda_l2': 0.029204338471814112}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:15,697] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 255, 'num_leaves': 81, 'learning_rate': 0.019721610970574007, 'feature_fraction': 0.8056937753654446, 'bagging_fraction': 0.836965827544817, 'min_child_samples': 7, 'lambda_l1': 0.26926469100861794, 'lambda_l2': 0.004809461967501573}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:15,904] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 79, 'num_leaves': 96, 'learning_rate': 0.26690431824362526, 'feature_fraction': 0.9233589392465844, 'bagging_fraction': 0.7218455076693483, 'min_child_samples': 9, 'lambda_l1': 0.5456725485601477, 'lambda_l2': 0.057624872164786026}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:16,157] Trial 5 finished with value: 0.8627450980392157 and parameters: {'n_estimators': 105, 'num_leaves': 55, 'learning_rate': 0.011240768803005551, 'feature_fraction': 0.9637281608315128, 'bagging_fraction': 0.7035119926400067, 'min_child_samples': 35, 'lambda_l1': 0.017654048052495083, 'lambda_l2': 0.12030178871154672}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:16,601] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 296, 'num_leaves': 26, 'learning_rate': 0.27051668818999286, 'feature_fraction': 0.9100531293444458, 'bagging_fraction': 0.9757995766256756, 'min_child_samples': 46, 'lambda_l1': 0.24637685958997463, 'lambda_l2': 4.869640941520899}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:16,845] Trial 7 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 89, 'num_leaves': 27, 'learning_rate': 0.011662890273931383, 'feature_fraction': 0.7301321323053057, 'bagging_fraction': 0.7554709158757928, 'min_child_samples': 17, 'lambda_l1': 2.0651425578959257, 'lambda_l2': 0.026730883107816707}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:17,146] Trial 8 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 176, 'num_leaves': 59, 'learning_rate': 0.016149614799999188, 'feature_fraction': 0.9208787923016158, 'bagging_fraction': 0.6298202574719083, 'min_child_samples': 50, 'lambda_l1': 1.2273800987852967, 'lambda_l2': 0.0062353771356731605}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:17,442] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 52, 'num_leaves': 84, 'learning_rate': 0.11069143219393454, 'feature_fraction': 0.8916028672163949, 'bagging_fraction': 0.9085081386743783, 'min_child_samples': 8, 'lambda_l1': 0.02715581955282941, 'lambda_l2': 0.0029072088906598446}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for lightgbm
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'num_leaves': 96, 'learning_rate': 0.1205712628744377, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6624074561769746, 'min_child_samples': 12, 'lambda_l1': 0.0017073967431528124, 'lambda_l2': 2.9154431891537547}
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for lightgbm
DEBUG: Cache directory created: cache\models\lightgbm\numeric_dataset_StandardScaler\b86851ac3074763d1c0cba4eef50ce76570705b2b9030fcfa678f0c8f76494ce
DEBUG: Model artifact saved: cache\models\lightgbm\numeric_dataset_StandardScaler\b86851ac3074763d1c0cba4eef50ce76570705b2b9030fcfa678f0c8f76494ce\model.txt
DEBUG: Params saved: cache\models\lightgbm\numeric_dataset_StandardScaler\b86851ac3074763d1c0cba4eef50ce76570705b2b9030fcfa678f0c8f76494ce\params.json
DEBUG: Metrics saved: cache\models\lightgbm\numeric_dataset_StandardScaler\b86851ac3074763d1c0cba4eef50ce76570705b2b9030fcfa678f0c8f76494ce\metrics.json
DEBUG: Config saved: cache\models\lightgbm\numeric_dataset_StandardScaler\b86851ac3074763d1c0cba4eef50ce76570705b2b9030fcfa678f0c8f76494ce\config.json
INFO:cache_manager:Cache saved for lightgbm at cache\models\lightgbm\numeric_dataset_StandardScaler\b86851ac3074763d1c0cba4eef50ce76570705b2b9030fcfa678f0c8f76494ce
DEBUG: Garbage collection completed for lightgbm
DEBUG: Garbage collection completed for lightgbm
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:18,441] A new study created in memory with name: catboost_optimization
INFO:optuna_optimizer:Created Optuna study: catboost_optimization
INFO:optuna_optimizer:Starting optimization for catboost...
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:22,349] Trial 0 finished with value: 1.0 and parameters: {'iterations': 218, 'depth': 10, 'learning_rate': 0.1205712628744377, 'l2_leaf_reg': 3.968793330444372, 'border_count': 66}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:22,963] Trial 1 finished with value: 0.9215686274509803 and parameters: {'iterations': 120, 'depth': 3, 'learning_rate': 0.19030368381735815, 'l2_leaf_reg': 3.9913058785616786, 'border_count': 190}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:23,701] Trial 2 finished with value: 1.0 and parameters: {'iterations': 59, 'depth': 10, 'learning_rate': 0.16967533607196555, 'l2_leaf_reg': 1.6305687346221471, 'border_count': 72}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:24,367] Trial 3 finished with value: 0.9705882352941176 and parameters: {'iterations': 132, 'depth': 5, 'learning_rate': 0.05958389350068958, 'l2_leaf_reg': 2.7036160666620015, 'border_count': 97}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:25,904] Trial 4 finished with value: 1.0 and parameters: {'iterations': 325, 'depth': 4, 'learning_rate': 0.027010527749605478, 'l2_leaf_reg': 2.324672848950434, 'border_count': 134}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:27,724] Trial 5 finished with value: 1.0 and parameters: {'iterations': 404, 'depth': 4, 'learning_rate': 0.05748924681991978, 'l2_leaf_reg': 3.9121416285496955, 'border_count': 42}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:29,191] Trial 6 finished with value: 0.9313725490196079 and parameters: {'iterations': 324, 'depth': 4, 'learning_rate': 0.012476394272569451, 'l2_leaf_reg': 8.88966790701893, 'border_count': 248}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:31,228] Trial 7 finished with value: 1.0 and parameters: {'iterations': 414, 'depth': 5, 'learning_rate': 0.013940346079873234, 'l2_leaf_reg': 4.833180632488465, 'border_count': 130}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:31,873] Trial 8 finished with value: 0.9215686274509803 and parameters: {'iterations': 105, 'depth': 6, 'learning_rate': 0.011240768803005551, 'l2_leaf_reg': 8.115595675970502, 'border_count': 89}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:33,686] Trial 9 finished with value: 1.0 and parameters: {'iterations': 348, 'depth': 5, 'learning_rate': 0.05864129169696527, 'l2_leaf_reg': 3.521358805467868, 'border_count': 73}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for catboost
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'iterations': 218, 'depth': 10, 'learning_rate': 0.1205712628744377, 'l2_leaf_reg': 3.968793330444372, 'border_count': 66}
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for catboost
DEBUG: Cache directory created: cache\models\catboost\numeric_dataset_StandardScaler\1a951cb75f7849e000b77f9f7bd0d0c9b8e4e7b37bf444706aff0eadb72226fd
DEBUG: Model artifact saved: cache\models\catboost\numeric_dataset_StandardScaler\1a951cb75f7849e000b77f9f7bd0d0c9b8e4e7b37bf444706aff0eadb72226fd\model.cbm
DEBUG: Params saved: cache\models\catboost\numeric_dataset_StandardScaler\1a951cb75f7849e000b77f9f7bd0d0c9b8e4e7b37bf444706aff0eadb72226fd\params.json
DEBUG: Metrics saved: cache\models\catboost\numeric_dataset_StandardScaler\1a951cb75f7849e000b77f9f7bd0d0c9b8e4e7b37bf444706aff0eadb72226fd\metrics.json
DEBUG: Config saved: cache\models\catboost\numeric_dataset_StandardScaler\1a951cb75f7849e000b77f9f7bd0d0c9b8e4e7b37bf444706aff0eadb72226fd\config.json
INFO:cache_manager:Cache saved for catboost at cache\models\catboost\numeric_dataset_StandardScaler\1a951cb75f7849e000b77f9f7bd0d0c9b8e4e7b37bf444706aff0eadb72226fd
DEBUG: Garbage collection completed for catboost
DEBUG: Garbage collection completed for catboost
[I 2025-10-01 09:56:37,749] A new study created in memory with name: adaboost_optimization
INFO:optuna_optimizer:Created Optuna study: adaboost_optimization
INFO:optuna_optimizer:Starting optimization for adaboost...
[I 2025-10-01 09:56:37,889] Trial 0 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 87, 'learning_rate': 1.5403596595019242}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:38,112] Trial 1 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 152, 'learning_rate': 0.23852347578447078}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:38,174] Trial 2 finished with value: 0.8529411764705882 and parameters: {'n_estimators': 48, 'learning_rate': 0.022853255256339213}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:38,219] Trial 3 finished with value: 0.8431372549019608 and parameters: {'n_estimators': 30, 'learning_rate': 0.98423157385026}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:38,399] Trial 4 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 128, 'learning_rate': 0.4258888210290082}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:38,431] Trial 5 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 23, 'learning_rate': 1.7052641538983098}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:38,709] Trial 6 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 170, 'learning_rate': 0.030803400529839688}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:38,795] Trial 7 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 52, 'learning_rate': 0.02642526057549918}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:38,905] Trial 8 finished with value: 0.8627450980392157 and parameters: {'n_estimators': 75, 'learning_rate': 0.16124278458562616}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:56:39,049] Trial 9 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 98, 'learning_rate': 0.04678719265016203}. Best is trial 0 with value: 0.9117647058823529.
INFO:optuna_optimizer:Optimization completed for adaboost
INFO:optuna_optimizer:Best score: 0.9118
INFO:optuna_optimizer:Best params: {'n_estimators': 87, 'learning_rate': 1.5403596595019242}
DEBUG: Starting cache save for adaboost
DEBUG: Cache directory created: cache\models\adaboost\numeric_dataset_StandardScaler\3e294c821ced5dfd356b784893759002790c0f8bb8b37995f3dcc3f33e9c49a5
DEBUG: Model artifact saved: cache\models\adaboost\numeric_dataset_StandardScaler\3e294c821ced5dfd356b784893759002790c0f8bb8b37995f3dcc3f33e9c49a5\model.pkl
DEBUG: Params saved: cache\models\adaboost\numeric_dataset_StandardScaler\3e294c821ced5dfd356b784893759002790c0f8bb8b37995f3dcc3f33e9c49a5\params.json
DEBUG: Metrics saved: cache\models\adaboost\numeric_dataset_StandardScaler\3e294c821ced5dfd356b784893759002790c0f8bb8b37995f3dcc3f33e9c49a5\metrics.json
DEBUG: Config saved: cache\models\adaboost\numeric_dataset_StandardScaler\3e294c821ced5dfd356b784893759002790c0f8bb8b37995f3dcc3f33e9c49a5\config.json
INFO:cache_manager:Cache saved for adaboost at cache\models\adaboost\numeric_dataset_StandardScaler\3e294c821ced5dfd356b784893759002790c0f8bb8b37995f3dcc3f33e9c49a5
DEBUG: Garbage collection completed for adaboost
DEBUG: Garbage collection completed for adaboost
[I 2025-10-01 09:56:39,473] A new study created in memory with name: gradient_boosting_optimization
INFO:optuna_optimizer:Created Optuna study: gradient_boosting_optimization
INFO:optuna_optimizer:Starting optimization for gradient_boosting...
[I 2025-10-01 09:56:39,878] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 144, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'subsample': 0.8394633936788146}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:40,006] Trial 1 finished with value: 0.8431372549019608 and parameters: {'n_estimators': 89, 'learning_rate': 0.01699897838270077, 'max_depth': 3, 'subsample': 0.9464704583099741}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:40,289] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 200, 'learning_rate': 0.11114989443094977, 'max_depth': 3, 'subsample': 0.9879639408647978}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:40,767] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 258, 'learning_rate': 0.020589728197687916, 'max_depth': 4, 'subsample': 0.6733618039413735}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:41,142] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 126, 'learning_rate': 0.05958389350068958, 'max_depth': 6, 'subsample': 0.7164916560792167}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:41,654] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 203, 'learning_rate': 0.01607123851203988, 'max_depth': 5, 'subsample': 0.7465447373174767}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:41,925] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 164, 'learning_rate': 0.14447746112718687, 'max_depth': 4, 'subsample': 0.8056937753654446}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:42,592] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 198, 'learning_rate': 0.011711509955524094, 'max_depth': 7, 'subsample': 0.6682096494749166}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:42,802] Trial 8 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 66, 'learning_rate': 0.2521267904777921, 'max_depth': 10, 'subsample': 0.9233589392465844}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:56:43,291] Trial 9 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 126, 'learning_rate': 0.013940346079873234, 'max_depth': 8, 'subsample': 0.7760609974958406}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for gradient_boosting
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 144, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'subsample': 0.8394633936788146}
DEBUG: Starting cache save for gradient_boosting
DEBUG: Cache directory created: cache\models\gradient_boosting\numeric_dataset_StandardScaler\7f45f2ecfc186e79f23f837c081468fffed776514686c000c83f25ea45b5c1e2
DEBUG: Model artifact saved: cache\models\gradient_boosting\numeric_dataset_StandardScaler\7f45f2ecfc186e79f23f837c081468fffed776514686c000c83f25ea45b5c1e2\model.pkl
DEBUG: Params saved: cache\models\gradient_boosting\numeric_dataset_StandardScaler\7f45f2ecfc186e79f23f837c081468fffed776514686c000c83f25ea45b5c1e2\params.json
DEBUG: Metrics saved: cache\models\gradient_boosting\numeric_dataset_StandardScaler\7f45f2ecfc186e79f23f837c081468fffed776514686c000c83f25ea45b5c1e2\metrics.json
DEBUG: Config saved: cache\models\gradient_boosting\numeric_dataset_StandardScaler\7f45f2ecfc186e79f23f837c081468fffed776514686c000c83f25ea45b5c1e2\config.json
INFO:cache_manager:Cache saved for gradient_boosting at cache\models\gradient_boosting\numeric_dataset_StandardScaler\7f45f2ecfc186e79f23f837c081468fffed776514686c000c83f25ea45b5c1e2
DEBUG: Garbage collection completed for gradient_boosting
DEBUG: Garbage collection completed for gradient_boosting
[I 2025-10-01 09:56:43,921] A new study created in memory with name: decision_tree_optimization
INFO:optuna_optimizer:Created Optuna study: decision_tree_optimization
INFO:optuna_optimizer:Starting optimization for decision_tree...
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,925] Trial 0 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,928] Trial 1 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,932] Trial 2 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,934] Trial 3 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,937] Trial 4 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,940] Trial 5 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,943] Trial 6 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,947] Trial 7 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,950] Trial 8 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:56:43,954] Trial 9 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
INFO:optuna_optimizer:Optimization completed for decision_tree
INFO:optuna_optimizer:Best score: 0.9804
INFO:optuna_optimizer:Best params: {}
🖥️ Using CPU without pruning (CCP disabled on Windows)
DEBUG: Starting cache save for decision_tree
DEBUG: Cache directory created: cache\models\decision_tree\numeric_dataset_StandardScaler\bd725e1127e6942d2cabd875aabcf68f096e7253b033ad48d65454cbc006d797
DEBUG: Model artifact saved: cache\models\decision_tree\numeric_dataset_StandardScaler\bd725e1127e6942d2cabd875aabcf68f096e7253b033ad48d65454cbc006d797\model.pkl
DEBUG: Params saved: cache\models\decision_tree\numeric_dataset_StandardScaler\bd725e1127e6942d2cabd875aabcf68f096e7253b033ad48d65454cbc006d797\params.json
DEBUG: Metrics saved: cache\models\decision_tree\numeric_dataset_StandardScaler\bd725e1127e6942d2cabd875aabcf68f096e7253b033ad48d65454cbc006d797\metrics.json
DEBUG: Config saved: cache\models\decision_tree\numeric_dataset_StandardScaler\bd725e1127e6942d2cabd875aabcf68f096e7253b033ad48d65454cbc006d797\config.json
INFO:cache_manager:Cache saved for decision_tree at cache\models\decision_tree\numeric_dataset_StandardScaler\bd725e1127e6942d2cabd875aabcf68f096e7253b033ad48d65454cbc006d797
DEBUG: Garbage collection completed for decision_tree
DEBUG: Garbage collection completed for decision_tree
[I 2025-10-01 09:56:44,227] A new study created in memory with name: logistic_regression_optimization
INFO:optuna_optimizer:Created Optuna study: logistic_regression_optimization
INFO:optuna_optimizer:Starting optimization for logistic_regression...
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,231] Trial 0 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,235] Trial 1 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,239] Trial 2 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,242] Trial 3 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,246] Trial 4 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,250] Trial 5 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,254] Trial 6 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,258] Trial 7 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,261] Trial 8 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:44,264] Trial 9 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
INFO:optuna_optimizer:Optimization completed for logistic_regression
INFO:optuna_optimizer:Best score: 0.8137
INFO:optuna_optimizer:Best params: {}
🔄 CPU multithreading: Using all 12 available cores
DEBUG: Starting cache save for logistic_regression
DEBUG: Cache directory created: cache\models\logistic_regression\numeric_dataset_StandardScaler\7b6c6457b746766d8fc6a5daef0b3a925227491c97a59011f3066a4429289aa9
DEBUG: Model artifact saved: cache\models\logistic_regression\numeric_dataset_StandardScaler\7b6c6457b746766d8fc6a5daef0b3a925227491c97a59011f3066a4429289aa9\model.pkl
DEBUG: Params saved: cache\models\logistic_regression\numeric_dataset_StandardScaler\7b6c6457b746766d8fc6a5daef0b3a925227491c97a59011f3066a4429289aa9\params.json
DEBUG: Metrics saved: cache\models\logistic_regression\numeric_dataset_StandardScaler\7b6c6457b746766d8fc6a5daef0b3a925227491c97a59011f3066a4429289aa9\metrics.json
DEBUG: Config saved: cache\models\logistic_regression\numeric_dataset_StandardScaler\7b6c6457b746766d8fc6a5daef0b3a925227491c97a59011f3066a4429289aa9\config.json
INFO:cache_manager:Cache saved for logistic_regression at cache\models\logistic_regression\numeric_dataset_StandardScaler\7b6c6457b746766d8fc6a5daef0b3a925227491c97a59011f3066a4429289aa9
DEBUG: Garbage collection completed for logistic_regression
DEBUG: Garbage collection completed for logistic_regression
⚡ Using SGDClassifier (fastest overall)
[I 2025-10-01 09:56:44,544] A new study created in memory with name: svm_optimization
INFO:optuna_optimizer:Created Optuna study: svm_optimization
INFO:optuna_optimizer:Starting optimization for svm...
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0015s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:56:44,547] Trial 0 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:56:44,550] Trial 1 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:56:44,552] Trial 2 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0010s
[I 2025-10-01 09:56:44,555] Trial 3 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:56:44,558] Trial 4 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0010s
[I 2025-10-01 09:56:44,561] Trial 5 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:56:44,564] Trial 6 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0020s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:56:44,566] Trial 7 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0010s
[I 2025-10-01 09:56:44,570] Trial 8 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:56:44,572] Trial 9 finished with value: 0.7647058823529411 and parameters: {}. Best is trial 0 with value: 0.7647058823529411.
INFO:optuna_optimizer:Optimization completed for svm
INFO:optuna_optimizer:Best score: 0.7647
INFO:optuna_optimizer:Best params: {}
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:56:44
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 103 samples using CPU in 0.0000s
DEBUG: Starting cache save for svm
DEBUG: Cache directory created: cache\models\svm\numeric_dataset_StandardScaler\c583dba7b20fff6e580535de53acca23a835791cb152106d3bba0f97481633b2
DEBUG: Model artifact saved: cache\models\svm\numeric_dataset_StandardScaler\c583dba7b20fff6e580535de53acca23a835791cb152106d3bba0f97481633b2\model.pkl
DEBUG: Params saved: cache\models\svm\numeric_dataset_StandardScaler\c583dba7b20fff6e580535de53acca23a835791cb152106d3bba0f97481633b2\params.json
DEBUG: Metrics saved: cache\models\svm\numeric_dataset_StandardScaler\c583dba7b20fff6e580535de53acca23a835791cb152106d3bba0f97481633b2\metrics.json
DEBUG: Config saved: cache\models\svm\numeric_dataset_StandardScaler\c583dba7b20fff6e580535de53acca23a835791cb152106d3bba0f97481633b2\config.json
INFO:cache_manager:Cache saved for svm at cache\models\svm\numeric_dataset_StandardScaler\c583dba7b20fff6e580535de53acca23a835791cb152106d3bba0f97481633b2
DEBUG: Garbage collection completed for svm
DEBUG: Garbage collection completed for svm
[I 2025-10-01 09:56:44,857] A new study created in memory with name: knn_optimization
INFO:optuna_optimizer:Created Optuna study: knn_optimization
INFO:optuna_optimizer:Starting optimization for knn...
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,861] Trial 0 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,866] Trial 1 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,869] Trial 2 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,872] Trial 3 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,876] Trial 4 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,879] Trial 5 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,882] Trial 6 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,886] Trial 7 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,888] Trial 8 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:56:44,892] Trial 9 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
INFO:optuna_optimizer:Optimization completed for knn
INFO:optuna_optimizer:Best score: 0.8922
INFO:optuna_optimizer:Best params: {}
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
DEBUG: Starting cache save for knn
DEBUG: Cache directory created: cache\models\knn\numeric_dataset_StandardScaler\ef090393cb101054454ff482587c4a18dcf33c1514424c71e2add78b1657a68f
DEBUG: Model artifact saved: cache\models\knn\numeric_dataset_StandardScaler\ef090393cb101054454ff482587c4a18dcf33c1514424c71e2add78b1657a68f\model.pkl
DEBUG: Params saved: cache\models\knn\numeric_dataset_StandardScaler\ef090393cb101054454ff482587c4a18dcf33c1514424c71e2add78b1657a68f\params.json
DEBUG: Metrics saved: cache\models\knn\numeric_dataset_StandardScaler\ef090393cb101054454ff482587c4a18dcf33c1514424c71e2add78b1657a68f\metrics.json
DEBUG: Config saved: cache\models\knn\numeric_dataset_StandardScaler\ef090393cb101054454ff482587c4a18dcf33c1514424c71e2add78b1657a68f\config.json
INFO:cache_manager:Cache saved for knn at cache\models\knn\numeric_dataset_StandardScaler\ef090393cb101054454ff482587c4a18dcf33c1514424c71e2add78b1657a68f
DEBUG: Garbage collection completed for knn
DEBUG: Garbage collection completed for knn
[I 2025-10-01 09:56:45,176] A new study created in memory with name: naive_bayes_optimization
INFO:optuna_optimizer:Created Optuna study: naive_bayes_optimization
INFO:optuna_optimizer:Starting optimization for naive_bayes...
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,178] Trial 0 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,180] Trial 1 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,182] Trial 2 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,183] Trial 3 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,184] Trial 4 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,186] Trial 5 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,186] Trial 6 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,187] Trial 7 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,188] Trial 8 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:56:45,189] Trial 9 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
INFO:optuna_optimizer:Optimization completed for naive_bayes
INFO:optuna_optimizer:Best score: 0.8333
INFO:optuna_optimizer:Best params: {}
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
DEBUG: Starting cache save for naive_bayes
DEBUG: Cache directory created: cache\models\naive_bayes\numeric_dataset_StandardScaler\ec515b709a2bbd975d54ac6ce9ed074cc6e6a54268af8258314572dc6cb4f2af
DEBUG: Model artifact saved: cache\models\naive_bayes\numeric_dataset_StandardScaler\ec515b709a2bbd975d54ac6ce9ed074cc6e6a54268af8258314572dc6cb4f2af\model.pkl
DEBUG: Params saved: cache\models\naive_bayes\numeric_dataset_StandardScaler\ec515b709a2bbd975d54ac6ce9ed074cc6e6a54268af8258314572dc6cb4f2af\params.json
DEBUG: Metrics saved: cache\models\naive_bayes\numeric_dataset_StandardScaler\ec515b709a2bbd975d54ac6ce9ed074cc6e6a54268af8258314572dc6cb4f2af\metrics.json
DEBUG: Config saved: cache\models\naive_bayes\numeric_dataset_StandardScaler\ec515b709a2bbd975d54ac6ce9ed074cc6e6a54268af8258314572dc6cb4f2af\config.json
INFO:cache_manager:Cache saved for naive_bayes at cache\models\naive_bayes\numeric_dataset_StandardScaler\ec515b709a2bbd975d54ac6ce9ed074cc6e6a54268af8258314572dc6cb4f2af
DEBUG: Garbage collection completed for naive_bayes
DEBUG: Garbage collection completed for naive_bayes
[I 2025-10-01 09:56:45,479] A new study created in memory with name: random_forest_optimization
INFO:optuna_optimizer:Created Optuna study: random_forest_optimization
INFO:optuna_optimizer:Starting optimization for random_forest...
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:45,792] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:46,787] Trial 1 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 440, 'max_depth': 13, 'max_features': None, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:46,939] Trial 2 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 132, 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:47,188] Trial 3 finished with value: 0.9313725490196079 and parameters: {'n_estimators': 112, 'max_depth': 8, 'max_features': None, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:47,476] Trial 4 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 317, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:48,001] Trial 5 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 414, 'max_depth': 8, 'max_features': 'log2', 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:48,084] Trial 6 finished with value: 0.9509803921568627 and parameters: {'n_estimators': 65, 'max_depth': 19, 'max_features': 'log2', 'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:48,240] Trial 7 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 133, 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:48,428] Trial 8 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 89, 'max_depth': 6, 'max_features': None, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:56:48,823] Trial 9 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 210, 'max_depth': 8, 'max_features': None, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for random_forest
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 1}
CPU multithreading: Using all 12 available cores
DEBUG: Starting cache save for random_forest
DEBUG: Cache directory created: cache\models\random_forest\numeric_dataset_MinMaxScaler\97962d01c39a25785e8930354e36813ccbdc182812c2b6434aae5b1812fd249a
DEBUG: Model artifact saved: cache\models\random_forest\numeric_dataset_MinMaxScaler\97962d01c39a25785e8930354e36813ccbdc182812c2b6434aae5b1812fd249a\model.pkl
DEBUG: Params saved: cache\models\random_forest\numeric_dataset_MinMaxScaler\97962d01c39a25785e8930354e36813ccbdc182812c2b6434aae5b1812fd249a\params.json
DEBUG: Metrics saved: cache\models\random_forest\numeric_dataset_MinMaxScaler\97962d01c39a25785e8930354e36813ccbdc182812c2b6434aae5b1812fd249a\metrics.json
DEBUG: Config saved: cache\models\random_forest\numeric_dataset_MinMaxScaler\97962d01c39a25785e8930354e36813ccbdc182812c2b6434aae5b1812fd249a\config.json
INFO:cache_manager:Cache saved for random_forest at cache\models\random_forest\numeric_dataset_MinMaxScaler\97962d01c39a25785e8930354e36813ccbdc182812c2b6434aae5b1812fd249a
DEBUG: Garbage collection completed for random_forest
DEBUG: Garbage collection completed for random_forest
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:49,387] A new study created in memory with name: xgboost_optimization
INFO:optuna_optimizer:Created Optuna study: xgboost_optimization
INFO:optuna_optimizer:Starting optimization for xgboost...
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:50,130] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'max_depth': 10, 'eta': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'reg_lambda': 0.0017073967431528124, 'reg_alpha': 2.9154431891537547}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:51,129] Trial 1 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 321, 'max_depth': 8, 'eta': 0.010725209743171996, 'subsample': 0.9879639408647978, 'colsample_bytree': 0.9329770563201687, 'min_child_weight': 3, 'reg_lambda': 0.005337032762603957, 'reg_alpha': 0.00541524411940254}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:51,611] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 187, 'max_depth': 7, 'eta': 0.04345454109729477, 'subsample': 0.7164916560792167, 'colsample_bytree': 0.8447411578889518, 'min_child_weight': 2, 'reg_lambda': 0.01474275315991467, 'reg_alpha': 0.029204338471814112}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:52,312] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 255, 'max_depth': 9, 'eta': 0.019721610970574007, 'subsample': 0.8056937753654446, 'colsample_bytree': 0.836965827544817, 'min_child_weight': 1, 'reg_lambda': 0.26926469100861794, 'reg_alpha': 0.004809461967501573}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:52,462] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 79, 'max_depth': 10, 'eta': 0.26690431824362526, 'subsample': 0.9233589392465844, 'colsample_bytree': 0.7218455076693483, 'min_child_weight': 1, 'reg_lambda': 0.5456725485601477, 'reg_alpha': 0.057624872164786026}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:52,652] Trial 5 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 105, 'max_depth': 6, 'eta': 0.011240768803005551, 'subsample': 0.9637281608315128, 'colsample_bytree': 0.7035119926400067, 'min_child_weight': 7, 'reg_lambda': 0.017654048052495083, 'reg_alpha': 0.12030178871154672}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:52,908] Trial 6 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 296, 'max_depth': 4, 'eta': 0.27051668818999286, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'min_child_weight': 9, 'reg_lambda': 0.24637685958997463, 'reg_alpha': 4.869640941520899}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:53,024] Trial 7 finished with value: 0.8921568627450981 and parameters: {'n_estimators': 89, 'max_depth': 4, 'eta': 0.011662890273931383, 'subsample': 0.7301321323053057, 'colsample_bytree': 0.7554709158757928, 'min_child_weight': 3, 'reg_lambda': 2.0651425578959257, 'reg_alpha': 0.026730883107816707}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:53,283] Trial 8 finished with value: 0.8921568627450981 and parameters: {'n_estimators': 176, 'max_depth': 7, 'eta': 0.016149614799999188, 'subsample': 0.9208787923016158, 'colsample_bytree': 0.6298202574719083, 'min_child_weight': 10, 'reg_lambda': 1.2273800987852967, 'reg_alpha': 0.0062353771356731605}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:53,415] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 52, 'max_depth': 9, 'eta': 0.11069143219393454, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'min_child_weight': 1, 'reg_lambda': 0.02715581955282941, 'reg_alpha': 0.0029072088906598446}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for xgboost
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'max_depth': 10, 'eta': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'reg_lambda': 0.0017073967431528124, 'reg_alpha': 2.9154431891537547}
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for xgboost
DEBUG: Cache directory created: cache\models\xgboost\numeric_dataset_MinMaxScaler\fb759ef3d3c5d040c4ab2f7d5f83a7fa05364cd52b376b35d9b0e5c4d539f06a
DEBUG: Model artifact saved: cache\models\xgboost\numeric_dataset_MinMaxScaler\fb759ef3d3c5d040c4ab2f7d5f83a7fa05364cd52b376b35d9b0e5c4d539f06a\model.json
DEBUG: Params saved: cache\models\xgboost\numeric_dataset_MinMaxScaler\fb759ef3d3c5d040c4ab2f7d5f83a7fa05364cd52b376b35d9b0e5c4d539f06a\params.json
DEBUG: Metrics saved: cache\models\xgboost\numeric_dataset_MinMaxScaler\fb759ef3d3c5d040c4ab2f7d5f83a7fa05364cd52b376b35d9b0e5c4d539f06a\metrics.json
DEBUG: Config saved: cache\models\xgboost\numeric_dataset_MinMaxScaler\fb759ef3d3c5d040c4ab2f7d5f83a7fa05364cd52b376b35d9b0e5c4d539f06a\config.json
INFO:cache_manager:Cache saved for xgboost at cache\models\xgboost\numeric_dataset_MinMaxScaler\fb759ef3d3c5d040c4ab2f7d5f83a7fa05364cd52b376b35d9b0e5c4d539f06a
DEBUG: Garbage collection completed for xgboost
DEBUG: Garbage collection completed for xgboost
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:54,012] A new study created in memory with name: lightgbm_optimization
INFO:optuna_optimizer:Created Optuna study: lightgbm_optimization
INFO:optuna_optimizer:Starting optimization for lightgbm...
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:54,649] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'num_leaves': 96, 'learning_rate': 0.1205712628744377, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6624074561769746, 'min_child_samples': 12, 'lambda_l1': 0.0017073967431528124, 'lambda_l2': 2.9154431891537547}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:55,648] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 321, 'num_leaves': 74, 'learning_rate': 0.010725209743171996, 'feature_fraction': 0.9879639408647978, 'bagging_fraction': 0.9329770563201687, 'min_child_samples': 14, 'lambda_l1': 0.005337032762603957, 'lambda_l2': 0.00541524411940254}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:56,334] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 187, 'num_leaves': 57, 'learning_rate': 0.04345454109729477, 'feature_fraction': 0.7164916560792167, 'bagging_fraction': 0.8447411578889518, 'min_child_samples': 11, 'lambda_l1': 0.01474275315991467, 'lambda_l2': 0.029204338471814112}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:57,336] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 255, 'num_leaves': 81, 'learning_rate': 0.019721610970574007, 'feature_fraction': 0.8056937753654446, 'bagging_fraction': 0.836965827544817, 'min_child_samples': 7, 'lambda_l1': 0.26926469100861794, 'lambda_l2': 0.004809461967501573}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:57,537] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 79, 'num_leaves': 96, 'learning_rate': 0.26690431824362526, 'feature_fraction': 0.9233589392465844, 'bagging_fraction': 0.7218455076693483, 'min_child_samples': 9, 'lambda_l1': 0.5456725485601477, 'lambda_l2': 0.057624872164786026}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:57,777] Trial 5 finished with value: 0.8627450980392157 and parameters: {'n_estimators': 105, 'num_leaves': 55, 'learning_rate': 0.011240768803005551, 'feature_fraction': 0.9637281608315128, 'bagging_fraction': 0.7035119926400067, 'min_child_samples': 35, 'lambda_l1': 0.017654048052495083, 'lambda_l2': 0.12030178871154672}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:58,196] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 296, 'num_leaves': 26, 'learning_rate': 0.27051668818999286, 'feature_fraction': 0.9100531293444458, 'bagging_fraction': 0.9757995766256756, 'min_child_samples': 46, 'lambda_l1': 0.24637685958997463, 'lambda_l2': 4.869640941520899}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:58,459] Trial 7 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 89, 'num_leaves': 27, 'learning_rate': 0.011662890273931383, 'feature_fraction': 0.7301321323053057, 'bagging_fraction': 0.7554709158757928, 'min_child_samples': 17, 'lambda_l1': 2.0651425578959257, 'lambda_l2': 0.026730883107816707}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:58,718] Trial 8 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 176, 'num_leaves': 59, 'learning_rate': 0.016149614799999188, 'feature_fraction': 0.9208787923016158, 'bagging_fraction': 0.6298202574719083, 'min_child_samples': 50, 'lambda_l1': 1.2273800987852967, 'lambda_l2': 0.0062353771356731605}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:59,013] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 52, 'num_leaves': 84, 'learning_rate': 0.11069143219393454, 'feature_fraction': 0.8916028672163949, 'bagging_fraction': 0.9085081386743783, 'min_child_samples': 8, 'lambda_l1': 0.02715581955282941, 'lambda_l2': 0.0029072088906598446}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for lightgbm
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'num_leaves': 96, 'learning_rate': 0.1205712628744377, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6624074561769746, 'min_child_samples': 12, 'lambda_l1': 0.0017073967431528124, 'lambda_l2': 2.9154431891537547}
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for lightgbm
DEBUG: Cache directory created: cache\models\lightgbm\numeric_dataset_MinMaxScaler\80f0b2e1ebf94ab0a1b51985f9c99d5546af55a4a1b78ef95d6e9b58153ccbb0
DEBUG: Model artifact saved: cache\models\lightgbm\numeric_dataset_MinMaxScaler\80f0b2e1ebf94ab0a1b51985f9c99d5546af55a4a1b78ef95d6e9b58153ccbb0\model.txt
DEBUG: Params saved: cache\models\lightgbm\numeric_dataset_MinMaxScaler\80f0b2e1ebf94ab0a1b51985f9c99d5546af55a4a1b78ef95d6e9b58153ccbb0\params.json
DEBUG: Metrics saved: cache\models\lightgbm\numeric_dataset_MinMaxScaler\80f0b2e1ebf94ab0a1b51985f9c99d5546af55a4a1b78ef95d6e9b58153ccbb0\metrics.json
DEBUG: Config saved: cache\models\lightgbm\numeric_dataset_MinMaxScaler\80f0b2e1ebf94ab0a1b51985f9c99d5546af55a4a1b78ef95d6e9b58153ccbb0\config.json
INFO:cache_manager:Cache saved for lightgbm at cache\models\lightgbm\numeric_dataset_MinMaxScaler\80f0b2e1ebf94ab0a1b51985f9c99d5546af55a4a1b78ef95d6e9b58153ccbb0
DEBUG: Garbage collection completed for lightgbm
DEBUG: Garbage collection completed for lightgbm
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:56:59,938] A new study created in memory with name: catboost_optimization
INFO:optuna_optimizer:Created Optuna study: catboost_optimization
INFO:optuna_optimizer:Starting optimization for catboost...
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:03,562] Trial 0 finished with value: 1.0 and parameters: {'iterations': 218, 'depth': 10, 'learning_rate': 0.1205712628744377, 'l2_leaf_reg': 3.968793330444372, 'border_count': 66}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:04,118] Trial 1 finished with value: 0.9215686274509803 and parameters: {'iterations': 120, 'depth': 3, 'learning_rate': 0.19030368381735815, 'l2_leaf_reg': 3.9913058785616786, 'border_count': 190}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:04,837] Trial 2 finished with value: 1.0 and parameters: {'iterations': 59, 'depth': 10, 'learning_rate': 0.16967533607196555, 'l2_leaf_reg': 1.6305687346221471, 'border_count': 72}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:05,508] Trial 3 finished with value: 0.9705882352941176 and parameters: {'iterations': 132, 'depth': 5, 'learning_rate': 0.05958389350068958, 'l2_leaf_reg': 2.7036160666620015, 'border_count': 97}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:06,934] Trial 4 finished with value: 1.0 and parameters: {'iterations': 325, 'depth': 4, 'learning_rate': 0.027010527749605478, 'l2_leaf_reg': 2.324672848950434, 'border_count': 134}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:08,582] Trial 5 finished with value: 1.0 and parameters: {'iterations': 404, 'depth': 4, 'learning_rate': 0.05748924681991978, 'l2_leaf_reg': 3.9121416285496955, 'border_count': 42}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:09,964] Trial 6 finished with value: 0.9313725490196079 and parameters: {'iterations': 324, 'depth': 4, 'learning_rate': 0.012476394272569451, 'l2_leaf_reg': 8.88966790701893, 'border_count': 248}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:11,789] Trial 7 finished with value: 1.0 and parameters: {'iterations': 414, 'depth': 5, 'learning_rate': 0.013940346079873234, 'l2_leaf_reg': 4.833180632488465, 'border_count': 130}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:12,423] Trial 8 finished with value: 0.9215686274509803 and parameters: {'iterations': 105, 'depth': 6, 'learning_rate': 0.011240768803005551, 'l2_leaf_reg': 8.115595675970502, 'border_count': 89}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:14,157] Trial 9 finished with value: 1.0 and parameters: {'iterations': 348, 'depth': 5, 'learning_rate': 0.05864129169696527, 'l2_leaf_reg': 3.521358805467868, 'border_count': 73}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for catboost
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'iterations': 218, 'depth': 10, 'learning_rate': 0.1205712628744377, 'l2_leaf_reg': 3.968793330444372, 'border_count': 66}
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for catboost
DEBUG: Cache directory created: cache\models\catboost\numeric_dataset_MinMaxScaler\84c3ffc02ed1ac794c42a2e82d06ded540633abe22415a9bb7644385000f877a
DEBUG: Model artifact saved: cache\models\catboost\numeric_dataset_MinMaxScaler\84c3ffc02ed1ac794c42a2e82d06ded540633abe22415a9bb7644385000f877a\model.cbm
DEBUG: Params saved: cache\models\catboost\numeric_dataset_MinMaxScaler\84c3ffc02ed1ac794c42a2e82d06ded540633abe22415a9bb7644385000f877a\params.json
DEBUG: Metrics saved: cache\models\catboost\numeric_dataset_MinMaxScaler\84c3ffc02ed1ac794c42a2e82d06ded540633abe22415a9bb7644385000f877a\metrics.json
DEBUG: Config saved: cache\models\catboost\numeric_dataset_MinMaxScaler\84c3ffc02ed1ac794c42a2e82d06ded540633abe22415a9bb7644385000f877a\config.json
INFO:cache_manager:Cache saved for catboost at cache\models\catboost\numeric_dataset_MinMaxScaler\84c3ffc02ed1ac794c42a2e82d06ded540633abe22415a9bb7644385000f877a
DEBUG: Garbage collection completed for catboost
DEBUG: Garbage collection completed for catboost
[I 2025-10-01 09:57:18,104] A new study created in memory with name: adaboost_optimization
INFO:optuna_optimizer:Created Optuna study: adaboost_optimization
INFO:optuna_optimizer:Starting optimization for adaboost...
[I 2025-10-01 09:57:18,235] Trial 0 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 87, 'learning_rate': 1.5403596595019242}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:18,441] Trial 1 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 152, 'learning_rate': 0.23852347578447078}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:18,503] Trial 2 finished with value: 0.8529411764705882 and parameters: {'n_estimators': 48, 'learning_rate': 0.022853255256339213}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:18,543] Trial 3 finished with value: 0.8431372549019608 and parameters: {'n_estimators': 30, 'learning_rate': 0.98423157385026}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:18,711] Trial 4 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 128, 'learning_rate': 0.4258888210290082}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:18,746] Trial 5 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 23, 'learning_rate': 1.7052641538983098}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:18,979] Trial 6 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 170, 'learning_rate': 0.030803400529839688}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:19,066] Trial 7 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 52, 'learning_rate': 0.02642526057549918}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:19,167] Trial 8 finished with value: 0.8627450980392157 and parameters: {'n_estimators': 75, 'learning_rate': 0.16124278458562616}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:57:19,306] Trial 9 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 98, 'learning_rate': 0.04678719265016203}. Best is trial 0 with value: 0.9117647058823529.
INFO:optuna_optimizer:Optimization completed for adaboost
INFO:optuna_optimizer:Best score: 0.9118
INFO:optuna_optimizer:Best params: {'n_estimators': 87, 'learning_rate': 1.5403596595019242}
DEBUG: Starting cache save for adaboost
DEBUG: Cache directory created: cache\models\adaboost\numeric_dataset_MinMaxScaler\bcdc0d12e39efb2f88fab82409c90175e93956988991359032d4c0d6729636e2
DEBUG: Model artifact saved: cache\models\adaboost\numeric_dataset_MinMaxScaler\bcdc0d12e39efb2f88fab82409c90175e93956988991359032d4c0d6729636e2\model.pkl
DEBUG: Params saved: cache\models\adaboost\numeric_dataset_MinMaxScaler\bcdc0d12e39efb2f88fab82409c90175e93956988991359032d4c0d6729636e2\params.json
DEBUG: Metrics saved: cache\models\adaboost\numeric_dataset_MinMaxScaler\bcdc0d12e39efb2f88fab82409c90175e93956988991359032d4c0d6729636e2\metrics.json
DEBUG: Config saved: cache\models\adaboost\numeric_dataset_MinMaxScaler\bcdc0d12e39efb2f88fab82409c90175e93956988991359032d4c0d6729636e2\config.json
INFO:cache_manager:Cache saved for adaboost at cache\models\adaboost\numeric_dataset_MinMaxScaler\bcdc0d12e39efb2f88fab82409c90175e93956988991359032d4c0d6729636e2
DEBUG: Garbage collection completed for adaboost
DEBUG: Garbage collection completed for adaboost
[I 2025-10-01 09:57:19,710] A new study created in memory with name: gradient_boosting_optimization
INFO:optuna_optimizer:Created Optuna study: gradient_boosting_optimization
INFO:optuna_optimizer:Starting optimization for gradient_boosting...
[I 2025-10-01 09:57:20,115] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 144, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'subsample': 0.8394633936788146}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:20,237] Trial 1 finished with value: 0.8431372549019608 and parameters: {'n_estimators': 89, 'learning_rate': 0.01699897838270077, 'max_depth': 3, 'subsample': 0.9464704583099741}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:20,492] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 200, 'learning_rate': 0.11114989443094977, 'max_depth': 3, 'subsample': 0.9879639408647978}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:20,924] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 258, 'learning_rate': 0.020589728197687916, 'max_depth': 4, 'subsample': 0.6733618039413735}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:21,272] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 126, 'learning_rate': 0.05958389350068958, 'max_depth': 6, 'subsample': 0.7164916560792167}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:21,704] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 203, 'learning_rate': 0.01607123851203988, 'max_depth': 5, 'subsample': 0.7465447373174767}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:21,976] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 164, 'learning_rate': 0.14447746112718687, 'max_depth': 4, 'subsample': 0.8056937753654446}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:22,731] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 198, 'learning_rate': 0.011711509955524094, 'max_depth': 7, 'subsample': 0.6682096494749166}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:22,946] Trial 8 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 66, 'learning_rate': 0.2521267904777921, 'max_depth': 10, 'subsample': 0.9233589392465844}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:57:23,421] Trial 9 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 126, 'learning_rate': 0.013940346079873234, 'max_depth': 8, 'subsample': 0.7760609974958406}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for gradient_boosting
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 144, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'subsample': 0.8394633936788146}
DEBUG: Starting cache save for gradient_boosting
DEBUG: Cache directory created: cache\models\gradient_boosting\numeric_dataset_MinMaxScaler\bd1ad21c0a30e849371923cf8205b06c3534f4287726b65950f7b3173adc8d47
DEBUG: Model artifact saved: cache\models\gradient_boosting\numeric_dataset_MinMaxScaler\bd1ad21c0a30e849371923cf8205b06c3534f4287726b65950f7b3173adc8d47\model.pkl
DEBUG: Params saved: cache\models\gradient_boosting\numeric_dataset_MinMaxScaler\bd1ad21c0a30e849371923cf8205b06c3534f4287726b65950f7b3173adc8d47\params.json
DEBUG: Metrics saved: cache\models\gradient_boosting\numeric_dataset_MinMaxScaler\bd1ad21c0a30e849371923cf8205b06c3534f4287726b65950f7b3173adc8d47\metrics.json
DEBUG: Config saved: cache\models\gradient_boosting\numeric_dataset_MinMaxScaler\bd1ad21c0a30e849371923cf8205b06c3534f4287726b65950f7b3173adc8d47\config.json
INFO:cache_manager:Cache saved for gradient_boosting at cache\models\gradient_boosting\numeric_dataset_MinMaxScaler\bd1ad21c0a30e849371923cf8205b06c3534f4287726b65950f7b3173adc8d47
DEBUG: Garbage collection completed for gradient_boosting
DEBUG: Garbage collection completed for gradient_boosting
[I 2025-10-01 09:57:24,042] A new study created in memory with name: decision_tree_optimization
INFO:optuna_optimizer:Created Optuna study: decision_tree_optimization
INFO:optuna_optimizer:Starting optimization for decision_tree...
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,047] Trial 0 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,050] Trial 1 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,054] Trial 2 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,057] Trial 3 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,064] Trial 4 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,067] Trial 5 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,072] Trial 6 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,075] Trial 7 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,078] Trial 8 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:57:24,082] Trial 9 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
INFO:optuna_optimizer:Optimization completed for decision_tree
INFO:optuna_optimizer:Best score: 0.9804
INFO:optuna_optimizer:Best params: {}
🖥️ Using CPU without pruning (CCP disabled on Windows)
DEBUG: Starting cache save for decision_tree
DEBUG: Cache directory created: cache\models\decision_tree\numeric_dataset_MinMaxScaler\79e43c22c8cbe65a1214a0f088e2eaf69a02d4bf31e0a2284074d2092774d501
DEBUG: Model artifact saved: cache\models\decision_tree\numeric_dataset_MinMaxScaler\79e43c22c8cbe65a1214a0f088e2eaf69a02d4bf31e0a2284074d2092774d501\model.pkl
DEBUG: Params saved: cache\models\decision_tree\numeric_dataset_MinMaxScaler\79e43c22c8cbe65a1214a0f088e2eaf69a02d4bf31e0a2284074d2092774d501\params.json
DEBUG: Metrics saved: cache\models\decision_tree\numeric_dataset_MinMaxScaler\79e43c22c8cbe65a1214a0f088e2eaf69a02d4bf31e0a2284074d2092774d501\metrics.json
DEBUG: Config saved: cache\models\decision_tree\numeric_dataset_MinMaxScaler\79e43c22c8cbe65a1214a0f088e2eaf69a02d4bf31e0a2284074d2092774d501\config.json
INFO:cache_manager:Cache saved for decision_tree at cache\models\decision_tree\numeric_dataset_MinMaxScaler\79e43c22c8cbe65a1214a0f088e2eaf69a02d4bf31e0a2284074d2092774d501
DEBUG: Garbage collection completed for decision_tree
DEBUG: Garbage collection completed for decision_tree
[I 2025-10-01 09:57:24,389] A new study created in memory with name: logistic_regression_optimization
INFO:optuna_optimizer:Created Optuna study: logistic_regression_optimization
INFO:optuna_optimizer:Starting optimization for logistic_regression...
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,397] Trial 0 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,402] Trial 1 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,408] Trial 2 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,415] Trial 3 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,419] Trial 4 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,424] Trial 5 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,430] Trial 6 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,434] Trial 7 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,441] Trial 8 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:24,448] Trial 9 finished with value: 0.803921568627451 and parameters: {}. Best is trial 0 with value: 0.803921568627451.
INFO:optuna_optimizer:Optimization completed for logistic_regression
INFO:optuna_optimizer:Best score: 0.8039
INFO:optuna_optimizer:Best params: {}
🔄 CPU multithreading: Using all 12 available cores
DEBUG: Starting cache save for logistic_regression
DEBUG: Cache directory created: cache\models\logistic_regression\numeric_dataset_MinMaxScaler\fedcb625d839c14b500b96f6cd808bfbbd2b02455ddcde06cbc5cbd27519815a
DEBUG: Model artifact saved: cache\models\logistic_regression\numeric_dataset_MinMaxScaler\fedcb625d839c14b500b96f6cd808bfbbd2b02455ddcde06cbc5cbd27519815a\model.pkl
DEBUG: Params saved: cache\models\logistic_regression\numeric_dataset_MinMaxScaler\fedcb625d839c14b500b96f6cd808bfbbd2b02455ddcde06cbc5cbd27519815a\params.json
DEBUG: Metrics saved: cache\models\logistic_regression\numeric_dataset_MinMaxScaler\fedcb625d839c14b500b96f6cd808bfbbd2b02455ddcde06cbc5cbd27519815a\metrics.json
DEBUG: Config saved: cache\models\logistic_regression\numeric_dataset_MinMaxScaler\fedcb625d839c14b500b96f6cd808bfbbd2b02455ddcde06cbc5cbd27519815a\config.json
INFO:cache_manager:Cache saved for logistic_regression at cache\models\logistic_regression\numeric_dataset_MinMaxScaler\fedcb625d839c14b500b96f6cd808bfbbd2b02455ddcde06cbc5cbd27519815a
DEBUG: Garbage collection completed for logistic_regression
DEBUG: Garbage collection completed for logistic_regression
⚡ Using SGDClassifier (fastest overall)
[I 2025-10-01 09:57:24,727] A new study created in memory with name: svm_optimization
INFO:optuna_optimizer:Created Optuna study: svm_optimization
INFO:optuna_optimizer:Starting optimization for svm...
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0015s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:57:24,731] Trial 0 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0010s
[I 2025-10-01 09:57:24,734] Trial 1 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:57:24,735] Trial 2 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0009s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0012s
[I 2025-10-01 09:57:24,739] Trial 3 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:57:24,741] Trial 4 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0020s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:57:24,744] Trial 5 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0015s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:57:24,747] Trial 6 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:57:24,750] Trial 7 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0022s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:57:24,753] Trial 8 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0010s
[I 2025-10-01 09:57:24,756] Trial 9 finished with value: 0.5098039215686274 and parameters: {}. Best is trial 0 with value: 0.5098039215686274.
INFO:optuna_optimizer:Optimization completed for svm
INFO:optuna_optimizer:Best score: 0.5098
INFO:optuna_optimizer:Best params: {}
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:57:24
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 103 samples using CPU in 0.0000s
DEBUG: Starting cache save for svm
DEBUG: Cache directory created: cache\models\svm\numeric_dataset_MinMaxScaler\315fc9e1a10c4af2b2642ff1606b072d7dcaa2ed33ef8eba7febea01fdbba4c5
DEBUG: Model artifact saved: cache\models\svm\numeric_dataset_MinMaxScaler\315fc9e1a10c4af2b2642ff1606b072d7dcaa2ed33ef8eba7febea01fdbba4c5\model.pkl
DEBUG: Params saved: cache\models\svm\numeric_dataset_MinMaxScaler\315fc9e1a10c4af2b2642ff1606b072d7dcaa2ed33ef8eba7febea01fdbba4c5\params.json
DEBUG: Metrics saved: cache\models\svm\numeric_dataset_MinMaxScaler\315fc9e1a10c4af2b2642ff1606b072d7dcaa2ed33ef8eba7febea01fdbba4c5\metrics.json
DEBUG: Config saved: cache\models\svm\numeric_dataset_MinMaxScaler\315fc9e1a10c4af2b2642ff1606b072d7dcaa2ed33ef8eba7febea01fdbba4c5\config.json
INFO:cache_manager:Cache saved for svm at cache\models\svm\numeric_dataset_MinMaxScaler\315fc9e1a10c4af2b2642ff1606b072d7dcaa2ed33ef8eba7febea01fdbba4c5
DEBUG: Garbage collection completed for svm
DEBUG: Garbage collection completed for svm
[I 2025-10-01 09:57:25,042] A new study created in memory with name: knn_optimization
INFO:optuna_optimizer:Created Optuna study: knn_optimization
INFO:optuna_optimizer:Starting optimization for knn...
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,047] Trial 0 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,050] Trial 1 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,053] Trial 2 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,057] Trial 3 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,061] Trial 4 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,064] Trial 5 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,067] Trial 6 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,069] Trial 7 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,072] Trial 8 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:57:25,075] Trial 9 finished with value: 0.8823529411764706 and parameters: {}. Best is trial 0 with value: 0.8823529411764706.
INFO:optuna_optimizer:Optimization completed for knn
INFO:optuna_optimizer:Best score: 0.8824
INFO:optuna_optimizer:Best params: {}
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
DEBUG: Starting cache save for knn
DEBUG: Cache directory created: cache\models\knn\numeric_dataset_MinMaxScaler\13365b4345511435657f8dedb4926b582c76be86c5711720ab91421781fcc97f
DEBUG: Model artifact saved: cache\models\knn\numeric_dataset_MinMaxScaler\13365b4345511435657f8dedb4926b582c76be86c5711720ab91421781fcc97f\model.pkl
DEBUG: Params saved: cache\models\knn\numeric_dataset_MinMaxScaler\13365b4345511435657f8dedb4926b582c76be86c5711720ab91421781fcc97f\params.json
DEBUG: Metrics saved: cache\models\knn\numeric_dataset_MinMaxScaler\13365b4345511435657f8dedb4926b582c76be86c5711720ab91421781fcc97f\metrics.json
DEBUG: Config saved: cache\models\knn\numeric_dataset_MinMaxScaler\13365b4345511435657f8dedb4926b582c76be86c5711720ab91421781fcc97f\config.json
INFO:cache_manager:Cache saved for knn at cache\models\knn\numeric_dataset_MinMaxScaler\13365b4345511435657f8dedb4926b582c76be86c5711720ab91421781fcc97f
DEBUG: Garbage collection completed for knn
DEBUG: Garbage collection completed for knn
[I 2025-10-01 09:57:25,371] A new study created in memory with name: naive_bayes_optimization
INFO:optuna_optimizer:Created Optuna study: naive_bayes_optimization
INFO:optuna_optimizer:Starting optimization for naive_bayes...
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,373] Trial 0 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,374] Trial 1 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,376] Trial 2 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,377] Trial 3 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,378] Trial 4 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,379] Trial 5 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,380] Trial 6 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,381] Trial 7 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,382] Trial 8 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:57:25,384] Trial 9 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
INFO:optuna_optimizer:Optimization completed for naive_bayes
INFO:optuna_optimizer:Best score: 0.8333
INFO:optuna_optimizer:Best params: {}
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
DEBUG: Starting cache save for naive_bayes
DEBUG: Cache directory created: cache\models\naive_bayes\numeric_dataset_MinMaxScaler\9724ae1744059f3cc983bfa4b372df0cb7912420c30e027a6c60f612ac710cc2
DEBUG: Model artifact saved: cache\models\naive_bayes\numeric_dataset_MinMaxScaler\9724ae1744059f3cc983bfa4b372df0cb7912420c30e027a6c60f612ac710cc2\model.pkl
DEBUG: Params saved: cache\models\naive_bayes\numeric_dataset_MinMaxScaler\9724ae1744059f3cc983bfa4b372df0cb7912420c30e027a6c60f612ac710cc2\params.json
DEBUG: Metrics saved: cache\models\naive_bayes\numeric_dataset_MinMaxScaler\9724ae1744059f3cc983bfa4b372df0cb7912420c30e027a6c60f612ac710cc2\metrics.json
DEBUG: Config saved: cache\models\naive_bayes\numeric_dataset_MinMaxScaler\9724ae1744059f3cc983bfa4b372df0cb7912420c30e027a6c60f612ac710cc2\config.json
INFO:cache_manager:Cache saved for naive_bayes at cache\models\naive_bayes\numeric_dataset_MinMaxScaler\9724ae1744059f3cc983bfa4b372df0cb7912420c30e027a6c60f612ac710cc2
DEBUG: Garbage collection completed for naive_bayes
DEBUG: Garbage collection completed for naive_bayes
[I 2025-10-01 09:57:25,666] A new study created in memory with name: random_forest_optimization
INFO:optuna_optimizer:Created Optuna study: random_forest_optimization
INFO:optuna_optimizer:Starting optimization for random_forest...
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:25,948] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:26,975] Trial 1 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 440, 'max_depth': 13, 'max_features': None, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:27,138] Trial 2 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 132, 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:27,445] Trial 3 finished with value: 0.9313725490196079 and parameters: {'n_estimators': 112, 'max_depth': 8, 'max_features': None, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:27,783] Trial 4 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 317, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:28,266] Trial 5 finished with value: 0.9705882352941176 and parameters: {'n_estimators': 414, 'max_depth': 8, 'max_features': 'log2', 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:28,351] Trial 6 finished with value: 0.9509803921568627 and parameters: {'n_estimators': 65, 'max_depth': 19, 'max_features': 'log2', 'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:28,514] Trial 7 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 133, 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:28,682] Trial 8 finished with value: 0.9215686274509803 and parameters: {'n_estimators': 89, 'max_depth': 6, 'max_features': None, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.
CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:57:29,065] Trial 9 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 210, 'max_depth': 8, 'max_features': None, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for random_forest
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 1}
CPU multithreading: Using all 12 available cores
DEBUG: Starting cache save for random_forest
DEBUG: Cache directory created: cache\models\random_forest\numeric_dataset_RobustScaler\58f1c5753095665e2c68a783ecbf3b345400d05661f6f8af45b7f9bfaa524927
DEBUG: Model artifact saved: cache\models\random_forest\numeric_dataset_RobustScaler\58f1c5753095665e2c68a783ecbf3b345400d05661f6f8af45b7f9bfaa524927\model.pkl
DEBUG: Params saved: cache\models\random_forest\numeric_dataset_RobustScaler\58f1c5753095665e2c68a783ecbf3b345400d05661f6f8af45b7f9bfaa524927\params.json
DEBUG: Metrics saved: cache\models\random_forest\numeric_dataset_RobustScaler\58f1c5753095665e2c68a783ecbf3b345400d05661f6f8af45b7f9bfaa524927\metrics.json
DEBUG: Config saved: cache\models\random_forest\numeric_dataset_RobustScaler\58f1c5753095665e2c68a783ecbf3b345400d05661f6f8af45b7f9bfaa524927\config.json
INFO:cache_manager:Cache saved for random_forest at cache\models\random_forest\numeric_dataset_RobustScaler\58f1c5753095665e2c68a783ecbf3b345400d05661f6f8af45b7f9bfaa524927
DEBUG: Garbage collection completed for random_forest
DEBUG: Garbage collection completed for random_forest
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:29,626] A new study created in memory with name: xgboost_optimization
INFO:optuna_optimizer:Created Optuna study: xgboost_optimization
INFO:optuna_optimizer:Starting optimization for xgboost...
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:30,435] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'max_depth': 10, 'eta': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'reg_lambda': 0.0017073967431528124, 'reg_alpha': 2.9154431891537547}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:31,659] Trial 1 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 321, 'max_depth': 8, 'eta': 0.010725209743171996, 'subsample': 0.9879639408647978, 'colsample_bytree': 0.9329770563201687, 'min_child_weight': 3, 'reg_lambda': 0.005337032762603957, 'reg_alpha': 0.00541524411940254}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:32,137] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 187, 'max_depth': 7, 'eta': 0.04345454109729477, 'subsample': 0.7164916560792167, 'colsample_bytree': 0.8447411578889518, 'min_child_weight': 2, 'reg_lambda': 0.01474275315991467, 'reg_alpha': 0.029204338471814112}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:32,929] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 255, 'max_depth': 9, 'eta': 0.019721610970574007, 'subsample': 0.8056937753654446, 'colsample_bytree': 0.836965827544817, 'min_child_weight': 1, 'reg_lambda': 0.26926469100861794, 'reg_alpha': 0.004809461967501573}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:33,127] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 79, 'max_depth': 10, 'eta': 0.26690431824362526, 'subsample': 0.9233589392465844, 'colsample_bytree': 0.7218455076693483, 'min_child_weight': 1, 'reg_lambda': 0.5456725485601477, 'reg_alpha': 0.057624872164786026}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:33,376] Trial 5 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 105, 'max_depth': 6, 'eta': 0.011240768803005551, 'subsample': 0.9637281608315128, 'colsample_bytree': 0.7035119926400067, 'min_child_weight': 7, 'reg_lambda': 0.017654048052495083, 'reg_alpha': 0.12030178871154672}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:33,690] Trial 6 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 296, 'max_depth': 4, 'eta': 0.27051668818999286, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'min_child_weight': 9, 'reg_lambda': 0.24637685958997463, 'reg_alpha': 4.869640941520899}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:33,838] Trial 7 finished with value: 0.8921568627450981 and parameters: {'n_estimators': 89, 'max_depth': 4, 'eta': 0.011662890273931383, 'subsample': 0.7301321323053057, 'colsample_bytree': 0.7554709158757928, 'min_child_weight': 3, 'reg_lambda': 2.0651425578959257, 'reg_alpha': 0.026730883107816707}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:34,231] Trial 8 finished with value: 0.8921568627450981 and parameters: {'n_estimators': 176, 'max_depth': 7, 'eta': 0.016149614799999188, 'subsample': 0.9208787923016158, 'colsample_bytree': 0.6298202574719083, 'min_child_weight': 10, 'reg_lambda': 1.2273800987852967, 'reg_alpha': 0.0062353771356731605}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:34,417] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 52, 'max_depth': 9, 'eta': 0.11069143219393454, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'min_child_weight': 1, 'reg_lambda': 0.02715581955282941, 'reg_alpha': 0.0029072088906598446}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for xgboost
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'max_depth': 10, 'eta': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'reg_lambda': 0.0017073967431528124, 'reg_alpha': 2.9154431891537547}
INFO:gpu_config_manager:GPU mode enabled for xgboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 XGBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for xgboost
DEBUG: Cache directory created: cache\models\xgboost\numeric_dataset_RobustScaler\62da7e6def7acd7e28c412df23388dc629567e0771da61cf226477499a84f255
DEBUG: Model artifact saved: cache\models\xgboost\numeric_dataset_RobustScaler\62da7e6def7acd7e28c412df23388dc629567e0771da61cf226477499a84f255\model.json
DEBUG: Params saved: cache\models\xgboost\numeric_dataset_RobustScaler\62da7e6def7acd7e28c412df23388dc629567e0771da61cf226477499a84f255\params.json
DEBUG: Metrics saved: cache\models\xgboost\numeric_dataset_RobustScaler\62da7e6def7acd7e28c412df23388dc629567e0771da61cf226477499a84f255\metrics.json
DEBUG: Config saved: cache\models\xgboost\numeric_dataset_RobustScaler\62da7e6def7acd7e28c412df23388dc629567e0771da61cf226477499a84f255\config.json
INFO:cache_manager:Cache saved for xgboost at cache\models\xgboost\numeric_dataset_RobustScaler\62da7e6def7acd7e28c412df23388dc629567e0771da61cf226477499a84f255
DEBUG: Garbage collection completed for xgboost
DEBUG: Garbage collection completed for xgboost
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:35,124] A new study created in memory with name: lightgbm_optimization
INFO:optuna_optimizer:Created Optuna study: lightgbm_optimization
INFO:optuna_optimizer:Starting optimization for lightgbm...
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:35,856] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 218, 'num_leaves': 96, 'learning_rate': 0.1205712628744377, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6624074561769746, 'min_child_samples': 12, 'lambda_l1': 0.0017073967431528124, 'lambda_l2': 2.9154431891537547}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:36,876] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 321, 'num_leaves': 74, 'learning_rate': 0.010725209743171996, 'feature_fraction': 0.9879639408647978, 'bagging_fraction': 0.9329770563201687, 'min_child_samples': 14, 'lambda_l1': 0.005337032762603957, 'lambda_l2': 0.00541524411940254}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:37,599] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 187, 'num_leaves': 57, 'learning_rate': 0.04345454109729477, 'feature_fraction': 0.7164916560792167, 'bagging_fraction': 0.8447411578889518, 'min_child_samples': 11, 'lambda_l1': 0.01474275315991467, 'lambda_l2': 0.029204338471814112}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:38,613] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 255, 'num_leaves': 81, 'learning_rate': 0.019721610970574007, 'feature_fraction': 0.8056937753654446, 'bagging_fraction': 0.836965827544817, 'min_child_samples': 7, 'lambda_l1': 0.26926469100861794, 'lambda_l2': 0.004809461967501573}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:38,811] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 79, 'num_leaves': 96, 'learning_rate': 0.26690431824362526, 'feature_fraction': 0.9233589392465844, 'bagging_fraction': 0.7218455076693483, 'min_child_samples': 9, 'lambda_l1': 0.5456725485601477, 'lambda_l2': 0.057624872164786026}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:39,040] Trial 5 finished with value: 0.8627450980392157 and parameters: {'n_estimators': 105, 'num_leaves': 55, 'learning_rate': 0.011240768803005551, 'feature_fraction': 0.9637281608315128, 'bagging_fraction': 0.7035119926400067, 'min_child_samples': 35, 'lambda_l1': 0.017654048052495083, 'lambda_l2': 0.12030178871154672}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:39,447] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 296, 'num_leaves': 26, 'learning_rate': 0.27051668818999286, 'feature_fraction': 0.9100531293444458, 'bagging_fraction': 0.9757995766256756, 'min_child_samples': 46, 'lambda_l1': 0.24637685958997463, 'lambda_l2': 4.869640941520899}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:39,687] Trial 7 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 89, 'num_leaves': 27, 'learning_rate': 0.011662890273931383, 'feature_fraction': 0.7301321323053057, 'bagging_fraction': 0.7554709158757928, 'min_child_samples': 17, 'lambda_l1': 2.0651425578959257, 'lambda_l2': 0.026730883107816707}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:39,946] Trial 8 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 176, 'num_leaves': 59, 'learning_rate': 0.016149614799999188, 'feature_fraction': 0.9208787923016158, 'bagging_fraction': 0.6298202574719083, 'min_child_samples': 50, 'lambda_l1': 1.2273800987852967, 'lambda_l2': 0.0062353771356731605}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:40,222] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 52, 'num_leaves': 84, 'learning_rate': 0.11069143219393454, 'feature_fraction': 0.8916028672163949, 'bagging_fraction': 0.9085081386743783, 'min_child_samples': 8, 'lambda_l1': 0.02715581955282941, 'lambda_l2': 0.0029072088906598446}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for lightgbm
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 218, 'num_leaves': 96, 'learning_rate': 0.1205712628744377, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6624074561769746, 'min_child_samples': 12, 'lambda_l1': 0.0017073967431528124, 'lambda_l2': 2.9154431891537547}
INFO:gpu_config_manager:GPU mode enabled for lightgbm: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 LightGBM configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for lightgbm
DEBUG: Cache directory created: cache\models\lightgbm\numeric_dataset_RobustScaler\adf26cc01549f09c6bf1390d44bc2855ac255035bb9752e57359ce3b485f4153
DEBUG: Model artifact saved: cache\models\lightgbm\numeric_dataset_RobustScaler\adf26cc01549f09c6bf1390d44bc2855ac255035bb9752e57359ce3b485f4153\model.txt
DEBUG: Params saved: cache\models\lightgbm\numeric_dataset_RobustScaler\adf26cc01549f09c6bf1390d44bc2855ac255035bb9752e57359ce3b485f4153\params.json
DEBUG: Metrics saved: cache\models\lightgbm\numeric_dataset_RobustScaler\adf26cc01549f09c6bf1390d44bc2855ac255035bb9752e57359ce3b485f4153\metrics.json
DEBUG: Config saved: cache\models\lightgbm\numeric_dataset_RobustScaler\adf26cc01549f09c6bf1390d44bc2855ac255035bb9752e57359ce3b485f4153\config.json
INFO:cache_manager:Cache saved for lightgbm at cache\models\lightgbm\numeric_dataset_RobustScaler\adf26cc01549f09c6bf1390d44bc2855ac255035bb9752e57359ce3b485f4153
DEBUG: Garbage collection completed for lightgbm
DEBUG: Garbage collection completed for lightgbm
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:41,160] A new study created in memory with name: catboost_optimization
INFO:optuna_optimizer:Created Optuna study: catboost_optimization
INFO:optuna_optimizer:Starting optimization for catboost...
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:44,770] Trial 0 finished with value: 1.0 and parameters: {'iterations': 218, 'depth': 10, 'learning_rate': 0.1205712628744377, 'l2_leaf_reg': 3.968793330444372, 'border_count': 66}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:45,331] Trial 1 finished with value: 0.9215686274509803 and parameters: {'iterations': 120, 'depth': 3, 'learning_rate': 0.19030368381735815, 'l2_leaf_reg': 3.9913058785616786, 'border_count': 190}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:46,053] Trial 2 finished with value: 1.0 and parameters: {'iterations': 59, 'depth': 10, 'learning_rate': 0.16967533607196555, 'l2_leaf_reg': 1.6305687346221471, 'border_count': 72}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:46,714] Trial 3 finished with value: 0.9705882352941176 and parameters: {'iterations': 132, 'depth': 5, 'learning_rate': 0.05958389350068958, 'l2_leaf_reg': 2.7036160666620015, 'border_count': 97}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:48,125] Trial 4 finished with value: 1.0 and parameters: {'iterations': 325, 'depth': 4, 'learning_rate': 0.027010527749605478, 'l2_leaf_reg': 2.324672848950434, 'border_count': 134}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:49,852] Trial 5 finished with value: 1.0 and parameters: {'iterations': 404, 'depth': 4, 'learning_rate': 0.05748924681991978, 'l2_leaf_reg': 3.9121416285496955, 'border_count': 42}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:51,331] Trial 6 finished with value: 0.9313725490196079 and parameters: {'iterations': 324, 'depth': 4, 'learning_rate': 0.012476394272569451, 'l2_leaf_reg': 8.88966790701893, 'border_count': 248}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:53,297] Trial 7 finished with value: 1.0 and parameters: {'iterations': 414, 'depth': 5, 'learning_rate': 0.013940346079873234, 'l2_leaf_reg': 4.833180632488465, 'border_count': 130}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:53,950] Trial 8 finished with value: 0.9215686274509803 and parameters: {'iterations': 105, 'depth': 6, 'learning_rate': 0.011240768803005551, 'l2_leaf_reg': 8.115595675970502, 'border_count': 89}. Best is trial 0 with value: 1.0.
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
[I 2025-10-01 09:57:55,723] Trial 9 finished with value: 1.0 and parameters: {'iterations': 348, 'depth': 5, 'learning_rate': 0.05864129169696527, 'l2_leaf_reg': 3.521358805467868, 'border_count': 73}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for catboost
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'iterations': 218, 'depth': 10, 'learning_rate': 0.1205712628744377, 'l2_leaf_reg': 3.968793330444372, 'border_count': 66}
INFO:gpu_config_manager:GPU mode enabled for catboost: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
🚀 CatBoost configured for GPU: GPU: NVIDIA GeForce RTX 3060 (1 devices, 12.0GB)
DEBUG: Starting cache save for catboost
DEBUG: Cache directory created: cache\models\catboost\numeric_dataset_RobustScaler\6b9dd0deb4907ae8f15ba40992ead51dc7db7d76bf737e1479b3798576be8505
DEBUG: Model artifact saved: cache\models\catboost\numeric_dataset_RobustScaler\6b9dd0deb4907ae8f15ba40992ead51dc7db7d76bf737e1479b3798576be8505\model.cbm
DEBUG: Params saved: cache\models\catboost\numeric_dataset_RobustScaler\6b9dd0deb4907ae8f15ba40992ead51dc7db7d76bf737e1479b3798576be8505\params.json
DEBUG: Metrics saved: cache\models\catboost\numeric_dataset_RobustScaler\6b9dd0deb4907ae8f15ba40992ead51dc7db7d76bf737e1479b3798576be8505\metrics.json
DEBUG: Config saved: cache\models\catboost\numeric_dataset_RobustScaler\6b9dd0deb4907ae8f15ba40992ead51dc7db7d76bf737e1479b3798576be8505\config.json
INFO:cache_manager:Cache saved for catboost at cache\models\catboost\numeric_dataset_RobustScaler\6b9dd0deb4907ae8f15ba40992ead51dc7db7d76bf737e1479b3798576be8505
DEBUG: Garbage collection completed for catboost
DEBUG: Garbage collection completed for catboost
[I 2025-10-01 09:57:59,677] A new study created in memory with name: adaboost_optimization
INFO:optuna_optimizer:Created Optuna study: adaboost_optimization
INFO:optuna_optimizer:Starting optimization for adaboost...
[I 2025-10-01 09:57:59,803] Trial 0 finished with value: 0.9117647058823529 and parameters: {'n_estimators': 87, 'learning_rate': 1.5403596595019242}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,027] Trial 1 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 152, 'learning_rate': 0.23852347578447078}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,091] Trial 2 finished with value: 0.8529411764705882 and parameters: {'n_estimators': 48, 'learning_rate': 0.022853255256339213}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,139] Trial 3 finished with value: 0.8431372549019608 and parameters: {'n_estimators': 30, 'learning_rate': 0.98423157385026}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,336] Trial 4 finished with value: 0.9019607843137255 and parameters: {'n_estimators': 128, 'learning_rate': 0.4258888210290082}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,371] Trial 5 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 23, 'learning_rate': 1.7052641538983098}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,611] Trial 6 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 170, 'learning_rate': 0.030803400529839688}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,685] Trial 7 finished with value: 0.8823529411764706 and parameters: {'n_estimators': 52, 'learning_rate': 0.02642526057549918}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,786] Trial 8 finished with value: 0.8627450980392157 and parameters: {'n_estimators': 75, 'learning_rate': 0.16124278458562616}. Best is trial 0 with value: 0.9117647058823529.
[I 2025-10-01 09:58:00,921] Trial 9 finished with value: 0.8725490196078431 and parameters: {'n_estimators': 98, 'learning_rate': 0.04678719265016203}. Best is trial 0 with value: 0.9117647058823529.
INFO:optuna_optimizer:Optimization completed for adaboost
INFO:optuna_optimizer:Best score: 0.9118
INFO:optuna_optimizer:Best params: {'n_estimators': 87, 'learning_rate': 1.5403596595019242}
DEBUG: Starting cache save for adaboost
DEBUG: Cache directory created: cache\models\adaboost\numeric_dataset_RobustScaler\a4cf24b8ab01c94de30d6ee9f77a14a556d507b19acd1261a666635bda1a2823
DEBUG: Model artifact saved: cache\models\adaboost\numeric_dataset_RobustScaler\a4cf24b8ab01c94de30d6ee9f77a14a556d507b19acd1261a666635bda1a2823\model.pkl
DEBUG: Params saved: cache\models\adaboost\numeric_dataset_RobustScaler\a4cf24b8ab01c94de30d6ee9f77a14a556d507b19acd1261a666635bda1a2823\params.json
DEBUG: Metrics saved: cache\models\adaboost\numeric_dataset_RobustScaler\a4cf24b8ab01c94de30d6ee9f77a14a556d507b19acd1261a666635bda1a2823\metrics.json
DEBUG: Config saved: cache\models\adaboost\numeric_dataset_RobustScaler\a4cf24b8ab01c94de30d6ee9f77a14a556d507b19acd1261a666635bda1a2823\config.json
INFO:cache_manager:Cache saved for adaboost at cache\models\adaboost\numeric_dataset_RobustScaler\a4cf24b8ab01c94de30d6ee9f77a14a556d507b19acd1261a666635bda1a2823
DEBUG: Garbage collection completed for adaboost
DEBUG: Garbage collection completed for adaboost
[I 2025-10-01 09:58:01,335] A new study created in memory with name: gradient_boosting_optimization
INFO:optuna_optimizer:Created Optuna study: gradient_boosting_optimization
INFO:optuna_optimizer:Starting optimization for gradient_boosting...
[I 2025-10-01 09:58:01,720] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 144, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'subsample': 0.8394633936788146}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:01,848] Trial 1 finished with value: 0.8431372549019608 and parameters: {'n_estimators': 89, 'learning_rate': 0.01699897838270077, 'max_depth': 3, 'subsample': 0.9464704583099741}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:02,126] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 200, 'learning_rate': 0.11114989443094977, 'max_depth': 3, 'subsample': 0.9879639408647978}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:02,550] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 258, 'learning_rate': 0.020589728197687916, 'max_depth': 4, 'subsample': 0.6733618039413735}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:02,916] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 126, 'learning_rate': 0.05958389350068958, 'max_depth': 6, 'subsample': 0.7164916560792167}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:03,394] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 203, 'learning_rate': 0.01607123851203988, 'max_depth': 5, 'subsample': 0.7465447373174767}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:03,671] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 164, 'learning_rate': 0.14447746112718687, 'max_depth': 4, 'subsample': 0.8056937753654446}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:04,383] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 198, 'learning_rate': 0.011711509955524094, 'max_depth': 7, 'subsample': 0.6682096494749166}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:04,607] Trial 8 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 66, 'learning_rate': 0.2521267904777921, 'max_depth': 10, 'subsample': 0.9233589392465844}. Best is trial 0 with value: 1.0.
[I 2025-10-01 09:58:05,141] Trial 9 finished with value: 0.9803921568627451 and parameters: {'n_estimators': 126, 'learning_rate': 0.013940346079873234, 'max_depth': 8, 'subsample': 0.7760609974958406}. Best is trial 0 with value: 1.0.
INFO:optuna_optimizer:Optimization completed for gradient_boosting
INFO:optuna_optimizer:Best score: 1.0000
INFO:optuna_optimizer:Best params: {'n_estimators': 144, 'learning_rate': 0.2536999076681772, 'max_depth': 8, 'subsample': 0.8394633936788146}
DEBUG: Starting cache save for gradient_boosting
DEBUG: Cache directory created: cache\models\gradient_boosting\numeric_dataset_RobustScaler\7c761199eec68874ab3d1b3d6b39507849f2139dfa0baaaeba30b816a598f1d9
DEBUG: Model artifact saved: cache\models\gradient_boosting\numeric_dataset_RobustScaler\7c761199eec68874ab3d1b3d6b39507849f2139dfa0baaaeba30b816a598f1d9\model.pkl
DEBUG: Params saved: cache\models\gradient_boosting\numeric_dataset_RobustScaler\7c761199eec68874ab3d1b3d6b39507849f2139dfa0baaaeba30b816a598f1d9\params.json
DEBUG: Metrics saved: cache\models\gradient_boosting\numeric_dataset_RobustScaler\7c761199eec68874ab3d1b3d6b39507849f2139dfa0baaaeba30b816a598f1d9\metrics.json
DEBUG: Config saved: cache\models\gradient_boosting\numeric_dataset_RobustScaler\7c761199eec68874ab3d1b3d6b39507849f2139dfa0baaaeba30b816a598f1d9\config.json
INFO:cache_manager:Cache saved for gradient_boosting at cache\models\gradient_boosting\numeric_dataset_RobustScaler\7c761199eec68874ab3d1b3d6b39507849f2139dfa0baaaeba30b816a598f1d9
DEBUG: Garbage collection completed for gradient_boosting
DEBUG: Garbage collection completed for gradient_boosting
[I 2025-10-01 09:58:05,796] A new study created in memory with name: decision_tree_optimization
INFO:optuna_optimizer:Created Optuna study: decision_tree_optimization
INFO:optuna_optimizer:Starting optimization for decision_tree...
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,799] Trial 0 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,802] Trial 1 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,805] Trial 2 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,809] Trial 3 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,812] Trial 4 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,815] Trial 5 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,819] Trial 6 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,822] Trial 7 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,825] Trial 8 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
🖥️ Using CPU without pruning (CCP disabled on Windows)
[I 2025-10-01 09:58:05,829] Trial 9 finished with value: 0.9803921568627451 and parameters: {}. Best is trial 0 with value: 0.9803921568627451.
INFO:optuna_optimizer:Optimization completed for decision_tree
INFO:optuna_optimizer:Best score: 0.9804
INFO:optuna_optimizer:Best params: {}
🖥️ Using CPU without pruning (CCP disabled on Windows)
DEBUG: Starting cache save for decision_tree
DEBUG: Cache directory created: cache\models\decision_tree\numeric_dataset_RobustScaler\f7264d2aa3f72632c3feda7bd88165678dd202fd2d1ece10a52cb6bc9a430d62
DEBUG: Model artifact saved: cache\models\decision_tree\numeric_dataset_RobustScaler\f7264d2aa3f72632c3feda7bd88165678dd202fd2d1ece10a52cb6bc9a430d62\model.pkl
DEBUG: Params saved: cache\models\decision_tree\numeric_dataset_RobustScaler\f7264d2aa3f72632c3feda7bd88165678dd202fd2d1ece10a52cb6bc9a430d62\params.json
DEBUG: Metrics saved: cache\models\decision_tree\numeric_dataset_RobustScaler\f7264d2aa3f72632c3feda7bd88165678dd202fd2d1ece10a52cb6bc9a430d62\metrics.json
DEBUG: Config saved: cache\models\decision_tree\numeric_dataset_RobustScaler\f7264d2aa3f72632c3feda7bd88165678dd202fd2d1ece10a52cb6bc9a430d62\config.json
INFO:cache_manager:Cache saved for decision_tree at cache\models\decision_tree\numeric_dataset_RobustScaler\f7264d2aa3f72632c3feda7bd88165678dd202fd2d1ece10a52cb6bc9a430d62
DEBUG: Garbage collection completed for decision_tree
DEBUG: Garbage collection completed for decision_tree
[I 2025-10-01 09:58:06,129] A new study created in memory with name: logistic_regression_optimization
INFO:optuna_optimizer:Created Optuna study: logistic_regression_optimization
INFO:optuna_optimizer:Starting optimization for logistic_regression...
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,133] Trial 0 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,138] Trial 1 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,142] Trial 2 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,146] Trial 3 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,149] Trial 4 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,152] Trial 5 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,155] Trial 6 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,159] Trial 7 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,164] Trial 8 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
🔄 CPU multithreading: Using all 12 available cores
[I 2025-10-01 09:58:06,167] Trial 9 finished with value: 0.8137254901960784 and parameters: {}. Best is trial 0 with value: 0.8137254901960784.
INFO:optuna_optimizer:Optimization completed for logistic_regression
INFO:optuna_optimizer:Best score: 0.8137
INFO:optuna_optimizer:Best params: {}
🔄 CPU multithreading: Using all 12 available cores
DEBUG: Starting cache save for logistic_regression
DEBUG: Cache directory created: cache\models\logistic_regression\numeric_dataset_RobustScaler\cb175f63c7000164aaf9381efa06905b441de85037086dac1874e89069efe083
DEBUG: Model artifact saved: cache\models\logistic_regression\numeric_dataset_RobustScaler\cb175f63c7000164aaf9381efa06905b441de85037086dac1874e89069efe083\model.pkl
DEBUG: Params saved: cache\models\logistic_regression\numeric_dataset_RobustScaler\cb175f63c7000164aaf9381efa06905b441de85037086dac1874e89069efe083\params.json
DEBUG: Metrics saved: cache\models\logistic_regression\numeric_dataset_RobustScaler\cb175f63c7000164aaf9381efa06905b441de85037086dac1874e89069efe083\metrics.json
DEBUG: Config saved: cache\models\logistic_regression\numeric_dataset_RobustScaler\cb175f63c7000164aaf9381efa06905b441de85037086dac1874e89069efe083\config.json
INFO:cache_manager:Cache saved for logistic_regression at cache\models\logistic_regression\numeric_dataset_RobustScaler\cb175f63c7000164aaf9381efa06905b441de85037086dac1874e89069efe083
DEBUG: Garbage collection completed for logistic_regression
DEBUG: Garbage collection completed for logistic_regression
⚡ Using SGDClassifier (fastest overall)
[I 2025-10-01 09:58:06,448] A new study created in memory with name: svm_optimization
INFO:optuna_optimizer:Created Optuna study: svm_optimization
INFO:optuna_optimizer:Starting optimization for svm...
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:58:06,451] Trial 0 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0020s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:58:06,453] Trial 1 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:58:06,455] Trial 2 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0015s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:58:06,458] Trial 3 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0017s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0010s
[I 2025-10-01 09:58:06,462] Trial 4 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0020s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:58:06,464] Trial 5 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:58:06,466] Trial 6 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:58:06,469] Trial 7 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0010s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0010s
[I 2025-10-01 09:58:06,472] Trial 8 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0020s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 102 samples using CPU in 0.0000s
[I 2025-10-01 09:58:06,476] Trial 9 finished with value: 0.7549019607843137 and parameters: {}. Best is trial 0 with value: 0.7549019607843137.
INFO:optuna_optimizer:Optimization completed for svm
INFO:optuna_optimizer:Best score: 0.7549
INFO:optuna_optimizer:Best params: {}
⚡ Using SGDClassifier (fastest overall)
INFO:SVM_Training:🚀 Starting SVM training at 2025-10-01 09:58:06
INFO:SVM_Training:📊 Data: 820 samples, 13 features, 1 classes
INFO:SVM_Training:⚙️  Parameters: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale', 'random_state': 42, 'max_iter': 1000, 'tol': 0.001, 'auto_fast': True}
INFO:SVM_Training:💾 Estimated memory: 0.08 MB
INFO:SVM_Training:💻 Using CPU (scikit-learn) - Fast and reliable
📊 Using dense array for SVM training: (820, 13)
INFO:SVM_Training:🔧 Data preparation: dense_array
INFO:SVM_Training:✅ Training completed on CPU in 0.0020s
INFO:SVM_Training:🎯 Total support vectors: 0
INFO:SVM_Training:🔮 Prediction on 103 samples using CPU in 0.0000s
DEBUG: Starting cache save for svm
DEBUG: Cache directory created: cache\models\svm\numeric_dataset_RobustScaler\ab4e7b5ecdc5eff42ab0094f6615d7cf1ac3a37151884d37919b45dbc2cbcf68
DEBUG: Model artifact saved: cache\models\svm\numeric_dataset_RobustScaler\ab4e7b5ecdc5eff42ab0094f6615d7cf1ac3a37151884d37919b45dbc2cbcf68\model.pkl
DEBUG: Params saved: cache\models\svm\numeric_dataset_RobustScaler\ab4e7b5ecdc5eff42ab0094f6615d7cf1ac3a37151884d37919b45dbc2cbcf68\params.json
DEBUG: Metrics saved: cache\models\svm\numeric_dataset_RobustScaler\ab4e7b5ecdc5eff42ab0094f6615d7cf1ac3a37151884d37919b45dbc2cbcf68\metrics.json
DEBUG: Config saved: cache\models\svm\numeric_dataset_RobustScaler\ab4e7b5ecdc5eff42ab0094f6615d7cf1ac3a37151884d37919b45dbc2cbcf68\config.json
INFO:cache_manager:Cache saved for svm at cache\models\svm\numeric_dataset_RobustScaler\ab4e7b5ecdc5eff42ab0094f6615d7cf1ac3a37151884d37919b45dbc2cbcf68
DEBUG: Garbage collection completed for svm
DEBUG: Garbage collection completed for svm
[I 2025-10-01 09:58:06,766] A new study created in memory with name: knn_optimization
INFO:optuna_optimizer:Created Optuna study: knn_optimization
INFO:optuna_optimizer:Starting optimization for knn...
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,772] Trial 0 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,775] Trial 1 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,780] Trial 2 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,784] Trial 3 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,788] Trial 4 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,792] Trial 5 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,795] Trial 6 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,799] Trial 7 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,804] Trial 8 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
[I 2025-10-01 09:58:06,807] Trial 9 finished with value: 0.8921568627450981 and parameters: {}. Best is trial 0 with value: 0.8921568627450981.
INFO:optuna_optimizer:Optimization completed for knn
INFO:optuna_optimizer:Best score: 0.8922
INFO:optuna_optimizer:Best params: {}
🖥️ Using FAISS CPU-accelerated KNN for embeddings
✅ FAISS CPU index created with 820 vectors, dimension 13
🚀 Using euclidean metric on CPU (optimized)
DEBUG: Starting cache save for knn
DEBUG: Cache directory created: cache\models\knn\numeric_dataset_RobustScaler\8720ce35c468034e6315b6c5536a34998e20d2a7c35fe65164b87c6162cd223f
DEBUG: Model artifact saved: cache\models\knn\numeric_dataset_RobustScaler\8720ce35c468034e6315b6c5536a34998e20d2a7c35fe65164b87c6162cd223f\model.pkl
DEBUG: Params saved: cache\models\knn\numeric_dataset_RobustScaler\8720ce35c468034e6315b6c5536a34998e20d2a7c35fe65164b87c6162cd223f\params.json
DEBUG: Metrics saved: cache\models\knn\numeric_dataset_RobustScaler\8720ce35c468034e6315b6c5536a34998e20d2a7c35fe65164b87c6162cd223f\metrics.json
DEBUG: Config saved: cache\models\knn\numeric_dataset_RobustScaler\8720ce35c468034e6315b6c5536a34998e20d2a7c35fe65164b87c6162cd223f\config.json
INFO:cache_manager:Cache saved for knn at cache\models\knn\numeric_dataset_RobustScaler\8720ce35c468034e6315b6c5536a34998e20d2a7c35fe65164b87c6162cd223f
DEBUG: Garbage collection completed for knn
DEBUG: Garbage collection completed for knn
[I 2025-10-01 09:58:07,144] A new study created in memory with name: naive_bayes_optimization
INFO:optuna_optimizer:Created Optuna study: naive_bayes_optimization
INFO:optuna_optimizer:Starting optimization for naive_bayes...
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,147] Trial 0 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,148] Trial 1 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,150] Trial 2 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,151] Trial 3 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,152] Trial 4 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,153] Trial 5 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,154] Trial 6 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,155] Trial 7 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,156] Trial 8 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
[I 2025-10-01 09:58:07,157] Trial 9 finished with value: 0.8333333333333334 and parameters: {}. Best is trial 0 with value: 0.8333333333333334.
INFO:optuna_optimizer:Optimization completed for naive_bayes
INFO:optuna_optimizer:Best score: 0.8333
INFO:optuna_optimizer:Best params: {}
📊 Using GaussianNB for dense features
🔄 CPU multithreading: Using all available cores
DEBUG: Starting cache save for naive_bayes
DEBUG: Cache directory created: cache\models\naive_bayes\numeric_dataset_RobustScaler\8268c18c8ed997b8cf0ec0fea976f3a73fe29e7a7b905f210e9a15d8590a1f8a
DEBUG: Model artifact saved: cache\models\naive_bayes\numeric_dataset_RobustScaler\8268c18c8ed997b8cf0ec0fea976f3a73fe29e7a7b905f210e9a15d8590a1f8a\model.pkl
DEBUG: Params saved: cache\models\naive_bayes\numeric_dataset_RobustScaler\8268c18c8ed997b8cf0ec0fea976f3a73fe29e7a7b905f210e9a15d8590a1f8a\params.json
DEBUG: Metrics saved: cache\models\naive_bayes\numeric_dataset_RobustScaler\8268c18c8ed997b8cf0ec0fea976f3a73fe29e7a7b905f210e9a15d8590a1f8a\metrics.json
DEBUG: Config saved: cache\models\naive_bayes\numeric_dataset_RobustScaler\8268c18c8ed997b8cf0ec0fea976f3a73fe29e7a7b905f210e9a15d8590a1f8a\config.json
INFO:cache_manager:Cache saved for naive_bayes at cache\models\naive_bayes\numeric_dataset_RobustScaler\8268c18c8ed997b8cf0ec0fea976f3a73fe29e7a7b905f210e9a15d8590a1f8a
DEBUG: Garbage collection completed for naive_bayes
DEBUG: Garbage collection completed for naive_bayes
SUCCESS: Step 4 data saved to session state
2025-10-01 09:58:07.464 Removing orphaned files...
(PJ3.1) PS C:\Users\User\OneDrive\Cloud\0. Studying\250516 AIO2025\z. Git\AIO\250914 Project 4>