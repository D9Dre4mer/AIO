# Ph∆∞∆°ng Ph√°p Tr·ª±c Quan H√≥a Step 5 - SHAP Visualization & Model Interpretation

## T·ªïng Quan Step 5

**Step 5** l√† b∆∞·ªõc tr·ª±c quan h√≥a v√† ph√¢n t√≠ch m√¥ h√¨nh trong Comprehensive Machine Learning Platform. ƒê√¢y l√† b∆∞·ªõc quan tr·ªçng gi√∫p ng∆∞·ªùi d√πng hi·ªÉu s√¢u v·ªÅ c√°ch c√°c m√¥ h√¨nh ML ƒë∆∞a ra quy·∫øt ƒë·ªãnh th√¥ng qua SHAP (SHapley Additive exPlanations) v√† c√°c ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrices).

---

## 1. Ki·∫øn Tr√∫c Step 5 (`wizard_ui/steps/step5_shap_visualization.py`)

### 1.1 SHAPVisualizationStep Class

```python
class SHAPVisualizationStep:
    """Step 5: SHAP Visualization & Model Interpretation"""
    
    def __init__(self):
        """Initialize Step 5"""
        self.session_manager = SessionManager()
        self.confusion_matrix_cache = confusion_matrix_cache
    
    def render(self) -> None:
        """Render the complete Step 5 interface"""
        st.title("üìä Step 5: SHAP Visualization & Model Interpretation")
        
        # Create tabs for different visualization sections
        tab1, tab2, tab3, tab4 = st.tabs([
            "üéØ Model Selection", 
            "üìä SHAP Analysis", 
            "üìà Confusion Matrices", 
            "üíæ Results Summary"
        ])
```

**ƒê·∫∑c ƒëi·ªÉm ch√≠nh:**
- **4-Tab Interface**: Model Selection, SHAP Analysis, Confusion Matrices, Results Summary
- **Session Management**: T√≠ch h·ª£p v·ªõi SessionManager ƒë·ªÉ l∆∞u tr·ªØ k·∫øt qu·∫£
- **Cache Integration**: S·ª≠ d·ª•ng confusion_matrix_cache ƒë·ªÉ truy c·∫≠p d·ªØ li·ªáu
- **Interactive UI**: Giao di·ªán t∆∞∆°ng t√°c v·ªõi Streamlit

### 1.2 Workflow Step 5

```
1. Model Selection ‚Üí 2. SHAP Analysis ‚Üí 3. Confusion Matrices ‚Üí 4. Results Summary
     ‚Üì                    ‚Üì                    ‚Üì                    ‚Üì
Select Models    Generate SHAP Plots    Create Confusion     Download Results
Load Cache       Feature Importance     Matrix Plots         Comprehensive Report
Configure        Model Interpretation   Classification       Performance
                 Memory Management      Metrics              Comparison
```

---

## 2. Tab 1: Model Selection

### 2.1 Model Selection Interface

```python
def _render_model_selection(self, available_caches: List[Dict[str, Any]]):
    """Render model selection interface"""
    st.subheader("üéØ Select Models for Analysis")
    
    # Filter models with eval_predictions
    models_with_predictions = [cache for cache in available_caches if cache['has_eval_predictions']]
    
    # Model selection
    model_options = []
    for cache in models_with_predictions:
        model_name = f"{cache['model_key']} ({cache['dataset_id']})"
        model_options.append((model_name, cache))
    
    selected_model_names = st.multiselect(
        "Select models to analyze:",
        [option[0] for option in model_options],
        default=[option[0] for option in model_options[:3]],  # Select first 3 by default
        help="Choose which trained models to include in the analysis"
    )
```

**T√≠nh nƒÉng Model Selection:**
- **Filtering**: Ch·ªâ hi·ªÉn th·ªã models c√≥ eval_predictions
- **Multi-select**: Ch·ªçn nhi·ªÅu models c√πng l√∫c
- **Default Selection**: T·ª± ƒë·ªông ch·ªçn 3 models ƒë·∫ßu ti√™n
- **Model Info Display**: Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng model

### 2.2 Model Information Display

```python
# Display selected models info
st.markdown("**üìã Selected Models:**")

for i, model in enumerate(selected_models, 1):
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.write(f"**{i}.** {model['model_key']}")
    
    with col2:
        st.write(f"Dataset: {model['dataset_id']}")
    
    with col3:
        st.write(f"Accuracy: {model.get('accuracy', 'N/A')}")
    
    with col4:
        has_shap = "‚úÖ" if model['has_shap_sample'] else "‚ùå"
        st.write(f"SHAP: {has_shap}")
```

**Th√¥ng tin hi·ªÉn th·ªã:**
- **Model Key**: T√™n v√† lo·∫°i model
- **Dataset ID**: Dataset ƒë∆∞·ª£c s·ª≠ d·ª•ng
- **Accuracy**: ƒê·ªô ch√≠nh x√°c c·ªßa model
- **SHAP Availability**: C√≥ s·∫µn SHAP sample hay kh√¥ng

### 2.3 SHAP Configuration

```python
# SHAP configuration
st.markdown("**‚öôÔ∏è SHAP Configuration:**")

col1, col2 = st.columns(2)

with col1:
    enable_shap = st.checkbox(
        "Enable SHAP Analysis",
        value=SHAP_ENABLE,
        help="Generate SHAP visualizations for selected models"
    )
    
    sample_size = st.number_input(
        "Sample Size for SHAP",
        min_value=100,
        max_value=10000,
        value=SHAP_SAMPLE_SIZE,
        help="Number of samples to use for SHAP analysis"
    )

with col2:
    output_dir = st.text_input(
        "Output Directory",
        value=SHAP_OUTPUT_DIR,
        help="Directory to save SHAP plots"
    )
    
    plot_types = st.multiselect(
        "Plot Types",
        ["summary", "bar", "dependence", "waterfall"],
        default=["summary", "bar", "dependence"],
        help="Types of SHAP plots to generate"
    )
```

**SHAP Configuration Options:**
- **Enable/Disable**: B·∫≠t/t·∫Øt SHAP analysis
- **Sample Size**: S·ªë l∆∞·ª£ng samples cho SHAP (100-10000)
- **Output Directory**: Th∆∞ m·ª•c l∆∞u plots
- **Plot Types**: C√°c lo·∫°i plots (summary, bar, dependence, waterfall)

---

## 3. Tab 2: SHAP Analysis

### 3.1 SHAP Analysis Interface

```python
def _render_shap_analysis(self):
    """Render SHAP analysis interface"""
    st.subheader("üìä SHAP Analysis")
    
    # SHAP analysis controls
    st.markdown("**üîß SHAP Analysis Controls:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üöÄ Generate SHAP Analysis", type="primary"):
            self._generate_shap_analysis(selected_models, shap_config)
    
    with col2:
        if st.button("üìä Preview SHAP Sample"):
            self._preview_shap_sample(selected_models[0])
```

### 3.2 SHAP Generation Process

```python
def _generate_shap_analysis(self, selected_models: List[Dict], shap_config: Dict):
    """Generate SHAP analysis for selected models"""
    with st.spinner("Generating SHAP analysis..."):
        try:
            shap_results = {}
            
            for model_info in selected_models:
                model_key = model_info['model_key']
                
                st.write(f"üîç Analyzing {model_key}...")
                
                try:
                    # Load model and data from cache
                    from cache_manager import cache_manager
                    
                    cache_data = cache_manager.load_model_cache(
                        model_info['model_key'],
                        model_info['dataset_id'],
                        model_info['config_hash']
                    )
                    
                    model = cache_data['model']
                    shap_sample = cache_data.get('shap_sample')
                    
                    if shap_sample is None:
                        st.warning(f"‚ö†Ô∏è No SHAP sample available for {model_key}")
                        continue
                    
                    # Prepare sample data
                    sample_size = min(shap_config['sample_size'], len(shap_sample))
                    X_sample = shap_sample.iloc[:sample_size]
                    
                    # Generate comprehensive SHAP analysis
                    result = generate_comprehensive_shap_analysis(
                        model=model,
                        X_sample=X_sample,
                        feature_names=cache_data.get('feature_names'),
                        output_dir=shap_config['output_dir'],
                        model_name=model_key,
                        plot_types=shap_config['plot_types']
                    )
                    
                    shap_results[model_key] = result
                    st.success(f"‚úÖ SHAP analysis completed for {model_key}")
                    
                except Exception as e:
                    st.error(f"‚ùå Error analyzing {model_key}: {str(e)}")
                    continue
```

**SHAP Generation Steps:**
1. **Load Model**: T·∫£i model t·ª´ cache
2. **Load SHAP Sample**: T·∫£i d·ªØ li·ªáu sample cho SHAP
3. **Prepare Data**: Chu·∫©n b·ªã d·ªØ li·ªáu v·ªõi sample size ph√π h·ª£p
4. **Generate Analysis**: T·∫°o comprehensive SHAP analysis
5. **Save Results**: L∆∞u k·∫øt qu·∫£ v√†o session

### 3.3 SHAP Visualization Functions (`visualization.py`)

#### A. SHAP Explainer Creation

```python
def create_shap_explainer(model, X_sample):
    """Create appropriate SHAP explainer for the model"""
    try:
        import shap
        
        # Extract underlying sklearn model
        underlying_model = extract_underlying_model(model)
        if underlying_model is None:
            print("ERROR: Cannot extract underlying sklearn model")
            return None
        
        model_name = model.__class__.__name__
        underlying_name = underlying_model.__class__.__name__
        
        print(f"Creating SHAP explainer for {model_name} -> {underlying_name}")
        
        # Determine model type and create appropriate explainer
        model_type_str = str(type(underlying_model)).lower()
        
        # Try TreeExplainer for tree-based models
        if any(keyword in model_type_str for keyword in ['randomforest', 'lightgbm', 'xgboost', 'gradientboosting', 'decisiontree']):
            try:
                print(f"Attempting TreeExplainer for {underlying_name}")
                
                # Memory safety check
                if len(X_sample) > 100:
                    print(f"Warning: Sample size {len(X_sample)} too large, using first 100 samples")
                    X_sample = X_sample[:100]
                
                explainer = shap.TreeExplainer(underlying_model)
                
                # Test explainer with small sample
                test_sample = X_sample[:5] if len(X_sample) >= 5 else X_sample
                try:
                    _ = explainer.shap_values(test_sample)
                    print(f"SUCCESS: Created TreeExplainer for {underlying_name}")
                    return explainer
                except Exception as test_error:
                    print(f"WARNING: TreeExplainer test failed for {underlying_name}: {test_error}")
                    del explainer
                    import gc
                    gc.collect()
                    raise test_error
                    
            except Exception as e:
                print(f"WARNING: TreeExplainer failed for {underlying_name}: {e}")
                import gc
                gc.collect()
                # Fallback to Explainer with predict_proba
                pass
        
        # Try Explainer with predict_proba for other models
        try:
            print(f"Attempting Explainer with predict_proba for {underlying_name}")
            
            # Memory safety check
            if len(X_sample) > 50:
                print(f"Warning: Sample size {len(X_sample)} too large, using first 50 samples")
                X_sample = X_sample[:50]
            
            def predict_proba_wrapper(X):
                return underlying_model.predict_proba(X)
            
            # Create explainer with smaller background
            background_sample = X_sample[:10] if len(X_sample) >= 10 else X_sample
            explainer = shap.Explainer(predict_proba_wrapper, background_sample)
            
            # Test explainer
            test_sample = X_sample[:3] if len(X_sample) >= 3 else X_sample
            try:
                _ = explainer(test_sample)
                print(f"SUCCESS: Created Explainer with predict_proba for {underlying_name}")
                return explainer
            except Exception as test_error:
                print(f"WARNING: Explainer test failed for {underlying_name}: {test_error}")
                del explainer
                import gc
                gc.collect()
                raise test_error
            
        except Exception as e:
            print(f"ERROR: All SHAP explainer methods failed for {underlying_name}: {e}")
            import gc
            gc.collect()
            return None
```

**SHAP Explainer Strategy:**
- **TreeExplainer**: Cho tree-based models (RandomForest, LightGBM, XGBoost, etc.)
- **Explainer**: Cho linear models v·ªõi predict_proba wrapper
- **Memory Safety**: Gi·ªõi h·∫°n sample size ƒë·ªÉ tr√°nh memory issues
- **Fallback Strategy**: Th·ª≠ nhi·ªÅu ph∆∞∆°ng ph√°p kh√°c nhau
- **Garbage Collection**: Cleanup memory sau m·ªói th·ª≠ nghi·ªám

#### B. SHAP Summary Plot (Beeswarm)

```python
def generate_shap_summary_plot(explainer, X_sample, feature_names=None, max_display=20, save_path=None):
    """Generate SHAP summary plot (beeswarm plot)"""
    try:
        import shap
        
        # Get SHAP values using definitive method
        shap_values, shap_type = get_shap_values_definitive(explainer, X_sample)
        if shap_values is None:
            return None
        
        # Create summary plot
        fig, ax = plt.subplots(figsize=(10, 8))
        shap.summary_plot(shap_values, X_sample, feature_names=feature_names, 
                         max_display=max_display, show=False)
        
        ax.set_title("SHAP Summary Plot (Beeswarm)", fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        # Save plot if path provided
        if save_path:
            fig.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"SUCCESS: SHAP summary plot saved to: {save_path}")
        
        return fig
        
    except Exception as e:
        print(f"Error generating SHAP summary plot: {e}")
        return None
```

**SHAP Summary Plot Features:**
- **Beeswarm Visualization**: Hi·ªÉn th·ªã distribution c·ªßa SHAP values
- **Feature Importance**: S·∫Øp x·∫øp features theo importance
- **Color Coding**: M√†u s·∫Øc th·ªÉ hi·ªán feature values
- **High Resolution**: 300 DPI cho ch·∫•t l∆∞·ª£ng cao
- **Custom Titles**: Ti√™u ƒë·ªÅ t√πy ch·ªânh

#### C. SHAP Bar Plot

```python
def generate_shap_bar_plot(explainer, X_sample, feature_names=None, max_display=20, save_path=None):
    """Generate SHAP bar plot (mean absolute SHAP values)"""
    try:
        import shap
        
        # Get SHAP values using definitive method
        shap_values, shap_type = get_shap_values_definitive(explainer, X_sample)
        if shap_values is None:
            return None
        
        # Create bar plot
        fig, ax = plt.subplots(figsize=(10, 8))
        shap.summary_plot(shap_values, X_sample, feature_names=feature_names, 
                         max_display=max_display, plot_type="bar", show=False)
        
        ax.set_title("SHAP Bar Plot (Mean Absolute SHAP Values)", fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        # Save plot if path provided
        if save_path:
            fig.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"SUCCESS: SHAP bar plot saved to: {save_path}")
        
        return fig
        
    except Exception as e:
        print(f"Error generating SHAP bar plot: {e}")
        return None
```

**SHAP Bar Plot Features:**
- **Mean Absolute Values**: Hi·ªÉn th·ªã mean absolute SHAP values
- **Feature Ranking**: S·∫Øp x·∫øp features theo importance
- **Clear Visualization**: Bar chart d·ªÖ ƒë·ªçc
- **Consistent Formatting**: Formatting nh·∫•t qu√°n v·ªõi summary plot

#### D. SHAP Dependence Plot

```python
def generate_shap_dependence_plot(explainer, X_sample, feature_names=None, 
                                 feature_index=0, interaction_index=None, save_path=None):
    """Generate SHAP dependence plot for a specific feature"""
    try:
        import shap
        
        # Get SHAP values using definitive method
        shap_values, shap_type = get_shap_values_definitive(explainer, X_sample)
        if shap_values is None:
            return None
        
        # Create dependence plot
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Ensure feature_index is an integer
        if isinstance(feature_index, str):
            try:
                feature_index = int(feature_index)
            except ValueError:
                feature_index = 0
        
        try:
            if interaction_index is not None:
                shap.dependence_plot(feature_index, shap_values, X_sample, 
                                    interaction_index=interaction_index, show=False)
            else:
                shap.dependence_plot(feature_index, shap_values, X_sample, show=False)
            
            # Force set title for all axes after plot creation
            feature_name = feature_names[feature_index] if feature_names and len(feature_names) > feature_index else f"Feature {feature_index}"
            for ax in fig.get_axes():
                if not ax.get_title():  # Only set if title is empty
                    ax.set_title(f"SHAP Dependence Plot: {feature_name}", fontsize=14, fontweight='bold')
            
            # Check if plot has meaningful content
            axes = fig.get_axes()
            has_content = False
            for ax in axes:
                if len(ax.get_lines()) > 0 or len(ax.collections) > 0:
                    # Check if collections have actual data points
                    for collection in ax.collections:
                        if hasattr(collection, 'get_offsets') and len(collection.get_offsets()) > 0:
                            has_content = True
                            break
                    if has_content:
                        break
            
            if not has_content:
                print("Warning: Dependence plot has no meaningful content, creating custom plot")
                # Clear and create custom dependence plot
                fig.clear()
                ax = fig.add_subplot(111)
                
                # Extract feature values and SHAP values
                feature_values = X_sample[:, feature_index]
                shap_feature_values = shap_values[:, feature_index]
                
                # Create scatter plot
                scatter = ax.scatter(feature_values, shap_feature_values, 
                                   alpha=0.7, s=50, c=shap_feature_values, 
                                   cmap='RdBu_r', edgecolors='black', linewidth=0.5)
                
                # Add colorbar
                plt.colorbar(scatter, ax=ax, label='SHAP Value')
                
                # Set labels and title
                feature_name = feature_names[feature_index] if feature_names and len(feature_names) > feature_index else f"Feature {feature_index}"
                ax.set_xlabel(feature_name, fontsize=12)
                ax.set_ylabel(f"SHAP Value for {feature_name}", fontsize=12)
                ax.set_title(f"SHAP Dependence Plot: {feature_name}", fontsize=14, fontweight='bold')
                
                # Add grid
                ax.grid(True, alpha=0.3)
```

**SHAP Dependence Plot Features:**
- **Feature Interaction**: Hi·ªÉn th·ªã t∆∞∆°ng t√°c gi·ªØa features
- **Custom Fallback**: T·∫°o custom plot n·∫øu SHAP plot kh√¥ng c√≥ n·ªôi dung
- **Color Mapping**: S·ª≠ d·ª•ng RdBu_r colormap
- **Grid Support**: Th√™m grid ƒë·ªÉ d·ªÖ ƒë·ªçc
- **Flexible Indexing**: H·ªó tr·ª£ c·∫£ string v√† integer feature index

### 3.4 Comprehensive SHAP Analysis

```python
def generate_comprehensive_shap_analysis(model, X_sample, feature_names=None, 
                                       model_name="Model", output_dir="info/Result/"):
    """Generate comprehensive SHAP analysis with multiple plots"""
    try:
        import shap
        from datetime import datetime
        
        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)
        
        # Create SHAP explainer
        explainer = create_shap_explainer(model, X_sample)
        if explainer is None:
            return None
        
        # Generate timestamp for file naming
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Generate plots
        plots = {}
        
        # 1. Summary plot (beeswarm)
        summary_path = os.path.join(output_dir, f"{model_name}_shap_summary_{timestamp}.png")
        summary_plot = generate_shap_summary_plot(explainer, X_sample, feature_names, 
                                                 save_path=summary_path)
        if summary_plot:
            plots['summary'] = summary_path
        
        # 2. Bar plot
        bar_path = os.path.join(output_dir, f"{model_name}_shap_bar_{timestamp}.png")
        bar_plot = generate_shap_bar_plot(explainer, X_sample, feature_names, 
                                        save_path=bar_path)
        if bar_plot:
            plots['bar'] = bar_path
        
        # 3. Dependence plots for top features
        if feature_names:
            # Get top 3 most important features
            shap_values = explainer.shap_values(X_sample)
            if isinstance(shap_values, list):
                shap_values = shap_values[1]
            
            mean_shap = np.mean(np.abs(shap_values), axis=0)
            top_features = np.argsort(mean_shap)[-3:][::-1]
            
            for i, feature_idx in enumerate(top_features):
                dep_path = os.path.join(output_dir, f"{model_name}_shap_dependence_{feature_names[feature_idx]}_{timestamp}.png")
                dep_plot = generate_shap_dependence_plot(explainer, X_sample, feature_names, 
                                                      feature_index=feature_idx, save_path=dep_path)
                if dep_plot:
                    plots[f'dependence_{feature_names[feature_idx]}'] = dep_path
```

**Comprehensive Analysis Features:**
- **Multiple Plot Types**: Summary, Bar, Dependence plots
- **Top Features**: T·ª± ƒë·ªông ch·ªçn top 3 features quan tr·ªçng nh·∫•t
- **Timestamp Naming**: File names v·ªõi timestamp ƒë·ªÉ tr√°nh conflict
- **Directory Management**: T·ª± ƒë·ªông t·∫°o output directory
- **Error Handling**: X·ª≠ l√Ω l·ªói cho t·ª´ng plot type

---

## 4. Tab 3: Confusion Matrices

### 4.1 Confusion Matrix Interface

```python
def _render_confusion_matrices(self):
    """Render confusion matrices interface"""
    st.subheader("üìà Confusion Matrices from Cache")
    
    # Confusion matrix configuration
    st.markdown("**‚öôÔ∏è Confusion Matrix Configuration:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        normalize = st.selectbox(
            "Normalization",
            ["true", "pred", "all", None],
            index=0,
            help="How to normalize the confusion matrix"
        )
    
    with col2:
        save_plots = st.checkbox(
            "Save Plots",
            value=True,
            help="Save confusion matrix plots to disk"
        )
        
        show_metrics = st.checkbox(
            "Show Metrics",
            value=True,
            help="Display classification metrics"
        )
```

### 4.2 Confusion Matrix Generation (`confusion_matrix_cache.py`)

```python
class ConfusionMatrixCache:
    """Generates confusion matrices from cached evaluation predictions"""
    
    def __init__(self, cache_root_dir: str = "cache/models/"):
        """Initialize confusion matrix cache"""
        self.cache_root_dir = Path(cache_root_dir)
        self.cache_manager = cache_manager
    
    def generate_confusion_matrix_from_cache(self, model_key: str, dataset_id: str, 
                                           config_hash: str, 
                                           normalize: str = "true",
                                           labels_order: Optional[List[str]] = None,
                                           save_path: Optional[str] = None) -> Dict[str, Any]:
        """Generate confusion matrix from cached eval_predictions"""
        try:
            # Load cached data
            cache_data = self.cache_manager.load_model_cache(model_key, dataset_id, config_hash)
            
            if cache_data['eval_predictions'] is None:
                raise ValueError(f"No eval_predictions found in cache for {model_key}")
            
            eval_df = cache_data['eval_predictions']
            
            # Extract true labels and predictions
            # Handle different column naming conventions
            if 'y_true' in eval_df.columns:
                y_true = eval_df['y_true'].values
            elif 'true_labels' in eval_df.columns:
                y_true = eval_df['true_labels'].values
            else:
                raise ValueError("No true labels column found. Expected 'y_true' or 'true_labels'")
            
            y_pred = self._extract_predictions(eval_df)
            
            # Get label mapping
            label_mapping = cache_data.get('label_mapping', {})
            if not label_mapping:
                # Create default mapping using integer keys
                unique_labels = sorted(set(y_true) | set(y_pred))
                label_mapping = {int(i): f"Class_{i}" for i in unique_labels}
            else:
                # Convert string keys to integer keys if needed
                label_mapping = {int(k): v for k, v in label_mapping.items()}
            
            # Apply label ordering if provided
            if labels_order:
                label_mapping = {k: v for k, v in label_mapping.items() if v in labels_order}
            
            # Generate confusion matrix
            cm = confusion_matrix(y_true, y_pred, labels=list(label_mapping.keys()))
            
            # Normalize if requested
            if normalize:
                cm_normalized = self._normalize_confusion_matrix(cm, normalize)
            else:
                cm_normalized = cm
            
            # Create plot
            fig, ax = plt.subplots(figsize=(10, 8))
```

**Confusion Matrix Features:**
- **Cache Integration**: T·∫£i d·ªØ li·ªáu t·ª´ model cache
- **Flexible Column Names**: H·ªó tr·ª£ nhi·ªÅu t√™n c·ªôt kh√°c nhau
- **Label Mapping**: Mapping labels t·ª´ integer sang string
- **Normalization Options**: true, pred, all, ho·∫∑c None
- **High-Quality Plots**: 10x8 figure size v·ªõi high DPI

### 4.3 Confusion Matrix Visualization

```python
# Create plot
fig, ax = plt.subplots(figsize=(10, 8))

# Create annotations with raw + normalized values
annotations = np.empty_like(cm).astype(str)
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        raw = cm[i, j]
        if normalize:
            norm = cm_normalized[i, j]
            annotations[i, j] = f"{raw}\n({norm:.2%})"
        else:
            annotations[i, j] = f"{raw}"

# Create heatmap
sns.heatmap(cm_normalized, annot=annotations, fmt='', cmap='Blues',
            xticklabels=[label_mapping[i] for i in range(len(label_mapping))],
            yticklabels=[label_mapping[i] for i in range(len(label_mapping))],
            ax=ax)

# Set title and labels
title = f"Confusion Matrix: {model_key}"
if normalize:
    title += f" (Normalized: {normalize})"
ax.set_title(title, fontsize=14, fontweight='bold')
ax.set_xlabel('Predicted Label', fontsize=12)
ax.set_ylabel('True Label', fontsize=12)

plt.tight_layout()
```

**Visualization Features:**
- **Dual Annotations**: Hi·ªÉn th·ªã c·∫£ raw counts v√† normalized percentages
- **Color Mapping**: S·ª≠ d·ª•ng Blues colormap
- **Custom Labels**: Labels t·ª´ label mapping
- **Dynamic Titles**: Ti√™u ƒë·ªÅ v·ªõi normalization info
- **Professional Formatting**: Font sizes v√† weights nh·∫•t qu√°n

### 4.4 Classification Metrics

```python
def _compute_classification_metrics(self, y_true, y_pred, label_mapping):
    """Compute comprehensive classification metrics"""
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
    
    # Overall metrics
    accuracy = accuracy_score(y_true, y_pred)
    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)
    weighted_f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)
    
    # Per-class metrics
    class_metrics = {}
    for class_id, class_name in label_mapping.items():
        # Convert to binary for this class
        y_true_binary = (y_true == class_id).astype(int)
        y_pred_binary = (y_pred == class_id).astype(int)
        
        if len(np.unique(y_true_binary)) > 1:  # Only if class exists in true labels
            precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)
            recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)
            f1 = f1_score(y_true_binary, y_pred_binary, zero_division=0)
            
            class_metrics[class_name] = {
                'precision': precision,
                'recall': recall,
                'f1': f1
            }
    
    return {
        'accuracy': accuracy,
        'macro_f1': macro_f1,
        'weighted_f1': weighted_f1,
        'class_metrics': class_metrics
    }
```

**Metrics Features:**
- **Overall Metrics**: Accuracy, Macro F1, Weighted F1
- **Per-Class Metrics**: Precision, Recall, F1 cho t·ª´ng class
- **Binary Conversion**: Chuy·ªÉn ƒë·ªïi sang binary classification cho t·ª´ng class
- **Zero Division Handling**: X·ª≠ l√Ω zero division errors
- **Comprehensive Coverage**: Bao ph·ªßm t·∫•t c·∫£ c√°c metrics quan tr·ªçng

---

## 5. Tab 4: Results Summary

### 5.1 Results Summary Interface

```python
def _render_results_summary(self):
    """Render results summary interface"""
    st.subheader("üíæ Results Summary")
    
    # Get all results
    shap_results = self.session_manager.get_step_data(5).get('shap_results', {})
    cm_results = self.session_manager.get_step_data(5).get('confusion_matrix_results', {})
    selected_models = self.session_manager.get_step_data(5).get('selected_models', [])
    
    # Summary statistics
    st.markdown("**üìä Analysis Summary:**")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Models Analyzed", len(selected_models))
    
    with col2:
        st.metric("SHAP Results", len(shap_results))
    
    with col3:
        st.metric("Confusion Matrices", len(cm_results))
    
    with col4:
        total_plots = len(shap_results) + len(cm_results)
        st.metric("Total Plots", total_plots)
```

### 5.2 Model Performance Comparison

```python
# Model performance comparison
if cm_results:
    st.markdown("**üèÜ Model Performance Comparison:**")
    
    performance_data = []
    for model_key, result in cm_results.items():
        metrics = result['metrics']
        performance_data.append({
            'Model': model_key,
            'Accuracy': metrics['accuracy'],
            'Macro F1': metrics['macro_f1'],
            'Weighted F1': metrics['weighted_f1']
        })
    
    if performance_data:
        performance_df = pd.DataFrame(performance_data)
        performance_df = performance_df.sort_values('Accuracy', ascending=False)
        
        st.dataframe(performance_df, width='stretch')
        
        # Best model
        best_model = performance_df.iloc[0]
        st.success(f"üèÜ Best performing model: **{best_model['Model']}** "
                  f"(Accuracy: {best_model['Accuracy']:.3f})")
```

**Performance Comparison Features:**
- **Comprehensive Metrics**: Accuracy, Macro F1, Weighted F1
- **Sorted Results**: S·∫Øp x·∫øp theo Accuracy gi·∫£m d·∫ßn
- **Best Model Highlight**: Highlight model t·ªët nh·∫•t
- **Interactive Table**: DataFrame v·ªõi Streamlit styling

### 5.3 Download Options

```python
# Download options
st.markdown("**üíæ Download Options:**")

col1, col2 = st.columns(2)

with col1:
    if st.button("üìä Download SHAP Results"):
        self._download_shap_results(shap_results)

with col2:
    if st.button("üìà Download Confusion Matrices"):
        self._download_confusion_matrices(cm_results)

# Generate comprehensive report
if st.button("üìã Generate Comprehensive Report", type="primary"):
    self._generate_comprehensive_report(shap_results, cm_results, selected_models)
```

**Download Features:**
- **SHAP Results**: Download SHAP analysis results
- **Confusion Matrices**: Download confusion matrix results
- **Comprehensive Report**: Generate v√† download comprehensive report
- **CSV Format**: T·∫•t c·∫£ downloads ƒë·ªÅu ·ªü format CSV
- **Timestamp Naming**: File names v·ªõi timestamp

---

## 6. SHAP Cache Management (`shap_cache_manager.py`)

### 6.1 SHAPCacheManager Class

```python
class SHAPCacheManager:
    """Manages SHAP explainer and values caching with memory leak protection"""
    
    def __init__(self, cache_dir: str = "cache/shap/"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Memory leak protection
        self._lock = threading.Lock()
        self._active_explainers = {}  # Track active explainers
        self._max_memory_mb = 2000  # Max memory usage in MB
        self._max_sample_size = 500  # Max sample size to prevent memory issues
        
        # Cleanup old cache files on init
        self._cleanup_old_cache()
```

**Memory Management Features:**
- **Threading Lock**: Thread-safe operations
- **Active Explainer Tracking**: Theo d√µi active explainers
- **Memory Limits**: Gi·ªõi h·∫°n memory usage (2GB)
- **Sample Size Limits**: Gi·ªõi h·∫°n sample size (500)
- **Automatic Cleanup**: T·ª± ƒë·ªông cleanup cache files c≈©

### 6.2 Memory Safety Operations

```python
@contextmanager
def _memory_safe_operation(self):
    """Context manager for memory-safe operations"""
    try:
        # Force garbage collection before checking memory
        gc.collect()
        
        # Check memory before operation
        if not self._check_memory_usage():
            print("Warning: High memory usage detected, attempting cleanup...")
            # Try aggressive cleanup
            gc.collect()
            import time
            time.sleep(0.1)  # Brief pause for cleanup
            
            # Check again after cleanup
            if not self._check_memory_usage():
                print("Warning: Still high memory usage after cleanup, skipping SHAP operation")
                yield False
                return
            else:
                print("INFO: Memory usage reduced after cleanup, proceeding with SHAP operation")
        
        yield True
    finally:
        # Aggressive cleanup after operation
        gc.collect()
        import time
        time.sleep(0.05)  # Brief pause for cleanup
```

**Memory Safety Features:**
- **Context Manager**: Context manager cho memory-safe operations
- **Pre-operation Check**: Ki·ªÉm tra memory tr∆∞·ªõc khi th·ª±c hi·ªán
- **Aggressive Cleanup**: Cleanup aggressive khi memory cao
- **Post-operation Cleanup**: Cleanup sau khi th·ª±c hi·ªán
- **Graceful Degradation**: Skip operations n·∫øu memory qu√° cao

### 6.3 Cache Key Generation

```python
def generate_shap_cache_key(self, model, sample_data, model_name=""):
    """Generate cache key for SHAP explainer and values with safety checks"""
    try:
        # Create hash from model and sample data (with safety checks)
        try:
            model_params = model.get_params() if hasattr(model, 'get_params') else {}
        except Exception:
            model_params = {}
        
        model_str = str(type(model)) + str(model_params)
        
        # Create hash from sample data (with safety checks)
        try:
            if hasattr(sample_data, 'shape'):
                # For numpy arrays or dataframes
                sample_str = str(sample_data.shape) + str(sample_data.dtype)
            else:
                # For other data types
                sample_str = str(type(sample_data)) + str(len(sample_data))
        except Exception:
            sample_str = "unknown_sample"
        
        # Combine and hash
        combined_str = model_str + sample_str + model_name
        cache_key = hashlib.md5(combined_str.encode()).hexdigest()[:16]
        
        return cache_key
        
    except Exception as e:
        print(f"Error generating cache key: {e}")
        return f"error_{hashlib.md5(str(e).encode()).hexdigest()[:8]}"
```

**Cache Key Features:**
- **Model Fingerprinting**: Hash t·ª´ model type v√† parameters
- **Sample Fingerprinting**: Hash t·ª´ sample data shape v√† type
- **Safety Checks**: X·ª≠ l√Ω exceptions trong qu√° tr√¨nh hash
- **Consistent Length**: Cache keys c√≥ ƒë·ªô d√†i nh·∫•t qu√°n (16 chars)
- **Error Handling**: Fallback cache key n·∫øu c√≥ l·ªói

---

## 7. K·∫øt Lu·∫≠n

### 7.1 ƒêi·ªÉm M·∫°nh c·ªßa Step 5 Visualization

**A. SHAP Analysis:**
- ‚úÖ **Multiple Explainer Types**: TreeExplainer, Explainer v·ªõi predict_proba
- ‚úÖ **Memory Safety**: Memory management v√† garbage collection
- ‚úÖ **Multiple Plot Types**: Summary, Bar, Dependence plots
- ‚úÖ **Feature Importance**: T·ª± ƒë·ªông ch·ªçn top features
- ‚úÖ **High-Quality Output**: 300 DPI plots v·ªõi professional formatting

**B. Confusion Matrices:**
- ‚úÖ **Cache Integration**: T·∫£i d·ªØ li·ªáu t·ª´ model cache
- ‚úÖ **Flexible Normalization**: true, pred, all, ho·∫∑c None
- ‚úÖ **Comprehensive Metrics**: Accuracy, F1, Precision, Recall
- ‚úÖ **Per-Class Analysis**: Metrics cho t·ª´ng class
- ‚úÖ **Professional Visualization**: Seaborn heatmaps v·ªõi annotations

**C. User Experience:**
- ‚úÖ **4-Tab Interface**: Organized workflow
- ‚úÖ **Interactive Selection**: Multi-select models
- ‚úÖ **Real-time Feedback**: Progress indicators v√† status updates
- ‚úÖ **Download Options**: CSV downloads v·ªõi timestamp naming
- ‚úÖ **Comprehensive Reports**: Detailed analysis reports

**D. Technical Excellence:**
- ‚úÖ **Memory Management**: Advanced memory leak protection
- ‚úÖ **Error Handling**: Comprehensive error handling
- ‚úÖ **Cache System**: Intelligent caching v·ªõi compatibility scoring
- ‚úÖ **Thread Safety**: Thread-safe operations
- ‚úÖ **Performance Optimization**: Memory limits v√† cleanup strategies

### 7.2 T√≠nh NƒÉng ƒê·∫∑c Bi·ªát

1. **Intelligent Explainer Selection**: T·ª± ƒë·ªông ch·ªçn explainer ph√π h·ª£p cho t·ª´ng model type
2. **Memory Leak Protection**: Advanced memory management v·ªõi garbage collection
3. **Fallback Strategies**: Multiple fallback strategies cho SHAP explainers
4. **Custom Plot Generation**: T·∫°o custom plots khi SHAP plots kh√¥ng c√≥ n·ªôi dung
5. **Comprehensive Metrics**: Detailed classification metrics v·ªõi per-class analysis
6. **Professional Visualization**: High-quality plots v·ªõi consistent formatting
7. **Cache Integration**: Seamless integration v·ªõi model cache system
8. **Download System**: Multiple download options v·ªõi timestamp naming

### 7.3 Best Practices ƒê∆∞·ª£c √Åp D·ª•ng

- **Memory Safety**: Context managers v√† garbage collection
- **Error Handling**: Comprehensive try-catch blocks
- **User Experience**: Progress indicators v√† real-time feedback
- **Code Organization**: Modular design v·ªõi clear separation of concerns
- **Performance Optimization**: Memory limits v√† cleanup strategies
- **Professional Output**: High-quality visualizations v·ªõi consistent formatting
- **Cache Management**: Intelligent caching v·ªõi compatibility scoring
- **Thread Safety**: Thread-safe operations v·ªõi locking mechanisms

Step 5 th·ªÉ hi·ªán m·ªôt c√°ch ti·∫øp c·∫≠n chuy√™n nghi·ªáp v√† to√†n di·ªán trong vi·ªác t·∫°o ra c√°c visualizations c√≥ √Ω nghƒ©a v√† d·ªÖ hi·ªÉu cho vi·ªác gi·∫£i th√≠ch m√¥ h√¨nh ML, gi√∫p ng∆∞·ªùi d√πng hi·ªÉu s√¢u v·ªÅ c√°ch c√°c m√¥ h√¨nh ƒë∆∞a ra quy·∫øt ƒë·ªãnh.

---

*Step 5 Visualization Methodology Documentation*
*Comprehensive Machine Learning Platform*
*C·∫≠p nh·∫≠t: 2025-01-27*
