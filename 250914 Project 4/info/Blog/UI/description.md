# üìä AIO Classifier Workflow Screenshots

## 1. Dataset Selection (Step 1/5)
![Step 1](Step 1.jpg)
- Giao di·ªán cho ph√©p ng∆∞·ªùi d√πng ch·ªçn t·∫≠p d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c m·∫´u ho·∫∑c t·∫£i l√™n.
- V√≠ d·ª•: Dataset `Heart_disease_cleveland_new.csv` ƒë∆∞·ª£c ch·ªçn.
- Hi·ªÉn th·ªã preview 5 d√≤ng ƒë·∫ßu ti√™n c·ªßa d·ªØ li·ªáu, g·ªìm c√°c c·ªôt: `age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target`.

---

## 2. Data Processing & Preprocessing (Step 2/5)
![Step2-1](Step2-1.jpg)
![Step2-2](Step2-2.jpg)
- Cho ph√©p x·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu v√†o, l·ª±a ch·ªçn input features v√† label column (`target`).
- H·ªá th·ªëng t·ª± ƒë·ªông nh·∫≠n di·ªán ki·ªÉu d·ªØ li·ªáu: 14 c·ªôt numeric, kh√¥ng c√≥ missing values.
- C√≥ 13 input features v√† 2 nh√£n ph√¢n lo·∫°i (`target`).

---

## 3. Model Configuration & Optimization (Step 3/5)
![Step 3](Step 3.jpg)
- C·∫•u h√¨nh hu·∫•n luy·ªán m√¥ h√¨nh k·∫øt h·ª£p v·ªõi **Optuna** ƒë·ªÉ t·ªëi ∆∞u hyperparameters.
- Ng∆∞·ªùi d√πng c√≥ th·ªÉ ch·ªçn s·ªë l∆∞·ª£ng trials (v√≠ d·ª•: 50) v√† th·ªùi gian t·ªëi ƒëa.
- H·ªó tr·ª£ nhi·ªÅu m√¥ h√¨nh: `random_forest, xgboost, lightgbm, catboost, adaboost, gradient_boosting, decision_tree, logistic_regression, svm, knn, naive_bayes`.

---

## 4. Training Execution & Monitoring (Step 4/5)
![Step 4](Step 4.jpg)
![Step 4-2](Step 4 -2.jpg)
- Cho ph√©p c·∫•u h√¨nh chia t·∫≠p d·ªØ li·ªáu: Train (80%), Validation (10%), Test (10%).
- Sau khi ch·∫°y hu·∫•n luy·ªán, k·∫øt qu·∫£ hi·ªÉn th·ªã:
  - ‚úÖ 39 m√¥ h√¨nh ƒë∆∞·ª£c train th√†nh c√¥ng.
  - üéØ Best Accuracy: **0.9355**
  - ‚è±Ô∏è Avg Training Time: 3.15s
- B·∫£ng chi ti·∫øt: hi·ªÉn th·ªã c√°c metric (validation_accuracy, test_accuracy, f1_score, precision, recall, training_time) cho t·ª´ng m√¥ h√¨nh.

---

## 5. Results Analysis: SHAP & Confusion Matrix (Step 5/5)
### 5.1 SHAP Analysis
![Step5-1](Step5-1.jpg)
![Step5-2](Step5-2.jpg)
- H·ªá th·ªëng ph√¢n t√≠ch SHAP ƒë·ªÉ gi·∫£i th√≠ch ·∫£nh h∆∞·ªüng c·ªßa t·ª´ng feature l√™n k·∫øt qu·∫£ m√¥ h√¨nh.
- C√°c lo·∫°i plot h·ªó tr·ª£: Summary, Bar, Dependence, Waterfall.
- V√≠ d·ª•: V·ªõi m√¥ h√¨nh Decision Tree, c√°c feature quan tr·ªçng nh·∫•t g·ªìm: `thal, ca, cp, oldpeak, age`.

### 5.2 Confusion Matrix
![Step5-3](Step5-3.jpg)
- Hi·ªÉn th·ªã Confusion Matrix ƒë·ªÉ ƒë√°nh gi√° hi·ªáu qu·∫£ ph√¢n lo·∫°i.
- C√≥ th·ªÉ ch·ªçn normalization (`true` ho·∫∑c `false`).
- V√≠ d·ª•: Confusion Matrix normalized cho m√¥ h√¨nh `adaboost`.

---
