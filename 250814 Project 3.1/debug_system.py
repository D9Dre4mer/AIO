"""
Debug ToÃ n Bá»™ Há»‡ Thá»‘ng - Kiá»ƒm tra tÃ­nh á»•n Ä‘á»‹nh vÃ  hoáº¡t Ä‘á»™ng
"""

import traceback
from sklearn.datasets import make_classification


def debug_imports():
    """Debug viá»‡c import cÃ¡c modules"""
    print("ğŸ” Debug Imports...")
    
    try:
        # Test import kiáº¿n trÃºc má»›i
        print("  ğŸ“¦ Testing New Architecture Imports...")
        from models.register_models import register_all_models
        print("    âœ… models.register_models")
        
        from models.new_model_trainer import NewModelTrainer
        print("    âœ… models.new_model_trainer")
        
        from models.utils.validation_manager import validation_manager
        print("    âœ… models.utils.validation_manager")
        
        from models.utils.model_factory import model_factory
        print("    âœ… models.utils.model_factory")
        
        from models.base.metrics import ModelMetrics
        print("    âœ… models.base.metrics")
        
        print("  âœ… New Architecture imports successful")
        
    except Exception as e:
        print(f"  âŒ New Architecture import error: {e}")
        traceback.print_exc()
        return False
    
    try:
        # Test import kiáº¿n trÃºc cÅ©
        print("  ğŸ“¦ Testing Legacy Architecture Imports...")
        from models import ModelTrainer
        print("    âœ… models.ModelTrainer")
        print("  âœ… Legacy Architecture imports successful")
        
    except Exception as e:
        print(f"  âŒ Legacy Architecture import error: {e}")
        traceback.print_exc()
        return False
    
    return True


def debug_model_registration():
    """Debug viá»‡c Ä‘Äƒng kÃ½ models"""
    print("\nğŸ” Debug Model Registration...")
    
    try:
        from models.register_models import register_all_models
        register_all_models()
        print("  âœ… Models registered successfully")
        
        from models.utils.model_factory import model_factory
        available_models = model_factory.get_available_models()
        print(f"  ğŸ“Š Available models: {available_models}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Model registration error: {e}")
        traceback.print_exc()
        return False


def debug_data_splitting():
    """Debug viá»‡c chia dá»¯ liá»‡u"""
    print("\nğŸ” Debug Data Splitting...")
    
    try:
        # Táº¡o dá»¯ liá»‡u máº«u
        X, y = make_classification(n_samples=200, n_features=10, 
                                 n_classes=2, random_state=42)
        print(f"  ğŸ“Š Data created: {X.shape}, {y.shape}")
        
        # Test validation manager
        from models.utils.validation_manager import validation_manager
        
        # Test split data
        X_train, X_val, X_test, y_train, y_val, y_test = \
            validation_manager.split_data(X, y)
        
        print(f"  âœ‚ï¸ Split successful:")
        print(f"    Train: {X_train.shape}")
        print(f"    Val:   {X_val.shape}")
        print(f"    Test:  {X_test.shape}")
        
        # Test split info
        split_info = validation_manager.get_split_info(X, y)
        print(f"  ğŸ“ˆ Split info: {split_info}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Data splitting error: {e}")
        traceback.print_exc()
        return False


def debug_single_model():
    """Debug viá»‡c train single model"""
    print("\nğŸ” Debug Single Model Training...")
    
    try:
        # Táº¡o dá»¯ liá»‡u
        X, y = make_classification(n_samples=100, n_features=5, 
                                 n_classes=2, random_state=42)
        
        # Test vá»›i kiáº¿n trÃºc má»›i
        from models.new_model_trainer import NewModelTrainer
        trainer = NewModelTrainer(cv_folds=3)
        
        # Test KNN model
        result = trainer.train_validate_test_model('knn', X, y)
        print(f"  âœ… KNN training successful: {len(result)} values returned")
        
        # Test cross-validation
        cv_result = trainer.cross_validate_model('knn', X, y, ['accuracy'])
        print(f"  âœ… KNN CV successful: {len(cv_result['fold_results'])} folds")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Single model error: {e}")
        traceback.print_exc()
        return False


def debug_all_models():
    """Debug viá»‡c train táº¥t cáº£ models"""
    print("\nğŸ” Debug All Models Training...")
    
    try:
        # Táº¡o dá»¯ liá»‡u
        X, y = make_classification(n_samples=150, n_features=8, 
                                 n_classes=2, random_state=42)
        
        # Test vá»›i kiáº¿n trÃºc má»›i
        from models.new_model_trainer import NewModelTrainer
        trainer = NewModelTrainer(cv_folds=3)
        
        # Test táº¥t cáº£ models
        results = trainer.train_validate_test_all_models(X, y)
        print(f"  âœ… All models training successful: {len(results)} models")
        
        # Test cross-validation cho táº¥t cáº£
        cv_results = trainer.cross_validate_all_models(X, y, ['accuracy'])
        print(f"  âœ… All models CV successful: {len(cv_results)} models")
        
        # Test comparison
        trainer.print_cv_comparison(cv_results)
        
        return True
        
    except Exception as e:
        print(f"  âŒ All models error: {e}")
        traceback.print_exc()
        return False


def debug_legacy_compatibility():
    """Debug tÃ­nh tÆ°Æ¡ng thÃ­ch vá»›i kiáº¿n trÃºc cÅ©"""
    print("\nğŸ” Debug Legacy Compatibility...")
    
    try:
        # Táº¡o dá»¯ liá»‡u
        X, y = make_classification(n_samples=100, n_features=5, 
                                 n_classes=2, random_state=42)
        
        # Test vá»›i kiáº¿n trÃºc cÅ©
        from models import ModelTrainer
        legacy_trainer = ModelTrainer()
        
        # Test single model
        y_pred, accuracy, metrics = legacy_trainer.train_and_test_model('knn', X, y)
        print(f"  âœ… Legacy KNN successful: Acc={accuracy:.4f}")
        
        # Test all models
        results = legacy_trainer.train_and_test_all_models(X, y)
        print(f"  âœ… Legacy all models successful: {len(results)} models")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Legacy compatibility error: {e}")
        traceback.print_exc()
        return False


def debug_unified_system():
    """Debug há»‡ thá»‘ng thá»‘ng nháº¥t"""
    print("\nğŸ” Debug Unified System...")
    
    try:
        # Import unified system
        from unified_system import UnifiedSystem
        
        # Táº¡o dá»¯ liá»‡u
        X, y = make_classification(n_samples=100, n_features=5, 
                                 n_classes=2, random_state=42)
        
        # Test kiáº¿n trÃºc má»›i
        print("  ğŸš€ Testing New Architecture...")
        system = UnifiedSystem(use_new_architecture=True, cv_folds=3)
        
        # Test single model
        result = system.train_and_test_model('knn', X, y)
        print(f"    âœ… Single model: {len(result)} values")
        
        # Test cross-validation
        cv_result = system.cross_validate_model('knn', X, y, ['accuracy'])
        print(f"    âœ… CV: {len(cv_result['fold_results'])} folds")
        
        # Test kiáº¿n trÃºc cÅ©
        print("  ğŸ”§ Testing Legacy Architecture...")
        system.switch_architecture(False)
        
        # Test single model
        result = system.train_and_test_model('knn', X, y)
        print(f"    âœ… Single model: {len(result)} values")
        
        # Test all models
        results = system.train_and_test_all_models(X, y)
        print(f"    âœ… All models: {len(results)} models")
        
        # Test system status
        status = system.get_system_status()
        print(f"  ğŸ“Š System status: {status}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Unified system error: {e}")
        traceback.print_exc()
        return False


def main():
    """Main debug function"""
    print("ğŸ› DEBUG TOÃ€N Bá»˜ Há»† THá»NG")
    print("=" * 50)
    
    tests = [
        ("Imports", debug_imports),
        ("Model Registration", debug_model_registration),
        ("Data Splitting", debug_data_splitting),
        ("Single Model", debug_single_model),
        ("All Models", debug_all_models),
        ("Legacy Compatibility", debug_legacy_compatibility),
        ("Unified System", debug_unified_system)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            print(f"\nğŸ§ª Running: {test_name}")
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ Test {test_name} failed: {e}")
            results[test_name] = False
    
    # Summary
    print("\n" + "=" * 50)
    print("ğŸ“Š DEBUG SUMMARY")
    print("=" * 50)
    
    passed = sum(results.values())
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {test_name:20s}: {status}")
    
    print(f"\nğŸ¯ Overall: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ Táº¥t cáº£ tests Ä‘á»u PASS! Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh.")
    else:
        print("âš ï¸ Má»™t sá»‘ tests FAIL. Cáº§n kiá»ƒm tra vÃ  sá»­a lá»—i.")
    
    return passed == total


if __name__ == "__main__":
    main()
