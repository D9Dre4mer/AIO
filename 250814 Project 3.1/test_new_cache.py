"""
Test New Cache with Confusion Matrix Data
Ch·∫°y training ƒë·ªÉ t·∫°o cache m·ªõi v·ªõi d·ªØ li·ªáu confusion matrix
"""

import os
import sys
import pandas as pd
import numpy as np

# Add current directory to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_new_cache():
    """Test t·∫°o cache m·ªõi v·ªõi d·ªØ li·ªáu confusion matrix"""
    print("üöÄ Test t·∫°o cache m·ªõi v·ªõi d·ªØ li·ªáu confusion matrix")
    print("=" * 60)
    
    try:
        from training_pipeline import StreamlitTrainingPipeline
        
        # T·∫°o pipeline
        pipeline = StreamlitTrainingPipeline()
        
        # T·∫°o d·ªØ li·ªáu test ƒë∆°n gi·∫£n
        print("üìä T·∫°o d·ªØ li·ªáu test...")
        np.random.seed(42)
        
        # T·∫°o 100 samples v·ªõi 5 classes
        n_samples = 100
        n_classes = 5
        
        # T·∫°o text data
        texts = [f"Sample text {i} for class {i % n_classes}" for i in range(n_samples)]
        
        # T·∫°o labels
        labels = [i % n_classes for i in range(n_samples)]
        
        # T·∫°o DataFrame
        df = pd.DataFrame({
            'text': texts,
            'label': labels
        })
        
        print(f"‚úÖ T·∫°o DataFrame: {df.shape}")
        print(f"   Text column: {df['text'].iloc[0][:50]}...")
        print(f"   Labels: {sorted(df['label'].unique())}")
        
        # T·∫°o step data
        step1_data = {
            'sampling_config': {
                'num_samples': 100,
                'sampling_strategy': 'random'
            }
        }
        
        step2_data = {
            'text_column': 'text',
            'label_column': 'label',
            'text_cleaning': True,
            'category_mapping': True,
            'data_validation': True,
            'memory_optimization': True
        }
        
        step3_data = {
            'data_split': {
                'test': 20,
                'validation': 10
            },
            'cross_validation': {
                'cv_folds': 3,
                'random_state': 42
            },
            'selected_models': ['K-Nearest Neighbors', 'Decision Tree'],
            'selected_vectorization': ['BoW', 'TF-IDF']
        }
        
        print("‚öôÔ∏è  Step data:")
        print(f"   Models: {step3_data['selected_models']}")
        print(f"   Vectorization: {step3_data['selected_vectorization']}")
        
        # Ch·∫°y training
        print("\nüöÄ B·∫Øt ƒë·∫ßu training...")
        result = pipeline.execute_training(df, step1_data, step2_data, step3_data)
        
        if result.get('status') == 'success':
            print("‚úÖ Training th√†nh c√¥ng!")
            print(f"   Successful combinations: {result.get('successful_combinations', 0)}/{result.get('total_combinations', 0)}")
            print(f"   From cache: {result.get('from_cache', False)}")
            
            # Ki·ªÉm tra cache m·ªõi
            print("\nüîç Ki·ªÉm tra cache m·ªõi...")
            cached_results = pipeline.get_cached_results(step1_data, step2_data, step3_data)
            
            if cached_results:
                print("‚úÖ Cache m·ªõi ƒë∆∞·ª£c t·∫°o!")
                
                # Ki·ªÉm tra d·ªØ li·ªáu confusion matrix
                if 'comprehensive_results' in cached_results:
                    comp_results = cached_results['comprehensive_results']
                    print(f"   Comprehensive results: {len(comp_results)} items")
                    
                    # Ki·ªÉm tra t·ª´ng result
                    for result_item in comp_results:
                        if result_item.get('status') == 'success':
                            model_name = result_item.get('model_name', 'N/A')
                            embedding_name = result_item.get('embedding_name', 'N/A')
                            
                            # Ki·ªÉm tra d·ªØ li·ªáu confusion matrix
                            confusion_matrix_data = []
                            if 'predictions' in result_item:
                                confusion_matrix_data.append("predictions")
                            if 'true_labels' in result_item:
                                confusion_matrix_data.append("true_labels")
                            if 'label_mapping' in result_item:
                                confusion_matrix_data.append("label_mapping")
                            
                            if confusion_matrix_data:
                                print(f"      ‚úÖ {model_name} + {embedding_name}: {', '.join(confusion_matrix_data)}")
                            else:
                                print(f"      ‚ùå {model_name} + {embedding_name}: Thi·∫øu d·ªØ li·ªáu")
                
                # Test v·∫Ω confusion matrix t·ª´ cache
                print("\nüé® Test v·∫Ω confusion matrix t·ª´ cache...")
                success = pipeline.plot_confusion_matrices_from_cache(cached_results)
                
                if success:
                    print("‚úÖ V·∫Ω confusion matrix t·ª´ cache th√†nh c√¥ng!")
                    return True
                else:
                    print("‚ùå V·∫Ω confusion matrix t·ª´ cache th·∫•t b·∫°i!")
                    return False
            else:
                print("‚ùå Kh√¥ng t√¨m th·∫•y cache m·ªõi")
                return False
        else:
            print(f"‚ùå Training th·∫•t b·∫°i: {result.get('message', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_new_cache()
    
    if success:
        print("\nüéâ TEST TH√ÄNH C√îNG!")
        print("‚úÖ Cache m·ªõi c√≥ ƒë·ªß d·ªØ li·ªáu confusion matrix")
        print("‚úÖ C√≥ th·ªÉ v·∫Ω confusion matrix t·ª´ cache")
    else:
        print("\nüí• TEST TH·∫§T B·∫†I!")
        print("‚ùå Cache kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu")
